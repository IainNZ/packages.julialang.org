>>> 'Pkg.add("Tokenize")' log
INFO: Installing Tokenize v0.4.2
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of Tokenize
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("Tokenize")' log
Julia Version 0.6.2
Commit d386e40c17 (2017-12-13 18:08 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-143-generic #192-Ubuntu SMP Tue Feb 27 10:45:36 UTC 2018 x86_64 x86_64
Memory: 2.939197540283203 GB (882.26171875 MB free)
Uptime: 86181.0 sec
Load Avg:  0.9970703125  0.9853515625  0.95458984375
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3499 MHz    5307690 s       4592 s     324307 s    1762805 s         84 s
#2  3499 MHz    1259236 s       1180 s     136184 s    7024653 s          1 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.9.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
6 required packages:
 - Conda                         0.7.1
 - JSON                          0.17.2
 - PyCall                        1.15.0
 - PyPlot                        2.5.0
 - RDatasets                     0.4.0
 - Tokenize                      0.4.2
28 additional packages:
 - BinDeps                       0.8.7
 - BinaryProvider                0.3.0
 - CSV                           0.2.4
 - CategoricalArrays             0.3.9
 - CodecZlib                     0.4.3
 - ColorTypes                    0.6.7
 - Colors                        0.8.2
 - Compat                        0.63.0
 - DataFrames                    0.11.5
 - DataStreams                   0.3.4
 - DataStructures                0.7.4
 - FileIO                        0.7.0
 - FixedPointNumbers             0.4.6
 - LaTeXStrings                  0.3.0
 - MacroTools                    0.4.0
 - Missings                      0.2.9
 - Mocking                       0.5.2
 - NamedTuples                   4.0.0
 - Nullables                     0.0.5
 - RData                         0.4.0
 - Reexport                      0.1.0
 - SHA                           0.5.7
 - SortingAlgorithms             0.2.0
 - StatsBase                     0.21.0
 - TimeZones                     0.6.5
 - TranscodingStreams            0.5.2
 - URIParser                     0.3.1
 - WeakRefStrings                0.4.4
INFO: Testing Tokenize
Lexed 10 files in 0.2041 seconds with a total of 380900 tokens with 0 errors
Test Summary: | Pass  Total
lex yourself  |    1      1
Test Summary: | Pass  Total
lexer         |  509    509
INFO: Tokenize tests passed

>>> End of log
