>>> 'Pkg.add("Tokenize")' log
INFO: Installing Tokenize v0.4.2
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of Tokenize
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("Tokenize")' log
Julia Version 0.6.2
Commit d386e40c17 (2017-12-13 18:08 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-143-generic #192-Ubuntu SMP Tue Feb 27 10:45:36 UTC 2018 x86_64 x86_64
Memory: 2.939197540283203 GB (986.140625 MB free)
Uptime: 87770.0 sec
Load Avg:  0.98681640625  0.9736328125  0.95458984375
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    5401497 s       1377 s     338606 s    1795208 s         71 s
#2  3500 MHz    1398448 s       5664 s     141760 s    7040960 s          2 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.9.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
6 required packages:
 - Conda                         0.7.1
 - JSON                          0.17.2
 - PyCall                        1.16.0
 - PyPlot                        2.5.0
 - RDatasets                     0.4.0
 - Tokenize                      0.4.2
29 additional packages:
 - BinDeps                       0.8.8
 - BinaryProvider                0.3.0
 - CSV                           0.2.4
 - CategoricalArrays             0.3.9
 - CodecZlib                     0.4.3
 - ColorTypes                    0.6.7
 - Colors                        0.8.2
 - Compat                        0.64.0
 - DataFrames                    0.11.6
 - DataStreams                   0.3.4
 - DataStructures                0.8.1
 - FileIO                        0.7.0
 - FixedPointNumbers             0.4.6
 - LaTeXStrings                  0.3.0
 - MacroTools                    0.4.0
 - Missings                      0.2.9
 - Mocking                       0.5.2
 - NamedTuples                   4.0.0
 - Nullables                     0.0.5
 - RData                         0.4.0
 - Reexport                      0.1.0
 - SHA                           0.5.7
 - SortingAlgorithms             0.2.1
 - StatsBase                     0.21.0
 - TimeZones                     0.6.5
 - TranscodingStreams            0.5.2
 - URIParser                     0.3.1
 - VersionParsing                1.1.0
 - WeakRefStrings                0.4.5
INFO: Testing Tokenize
Lexed 10 files in 0.2797 seconds with a total of 380900 tokens with 0 errors
Test Summary: | Pass  Total
lex yourself  |    1      1
Test Summary: | Pass  Total
lexer         |  509    509
INFO: Tokenize tests passed

>>> End of log
