>>> 'Pkg.add("TensorDecompositions")' log
INFO: Cloning cache of TensorDecompositions from git://github.com/yunjhongwu/TensorDecompositions.jl.git
INFO: Installing ArrayViews v0.6.4
INFO: Installing Distributions v0.9.0
INFO: Installing FactCheck v0.4.3
INFO: Installing PDMats v0.4.1
INFO: Installing ProgressMeter v0.3.1
INFO: Installing StatsBase v0.8.1
INFO: Installing StatsFuns v0.2.2
INFO: Installing TensorDecompositions v0.1.0
INFO: Installing TensorOperations v0.4.1
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of TensorDecompositions
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("TensorDecompositions")' log
Julia Version 0.4.5
Commit 2ac304d (2016-03-18 00:58 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
INFO: Testing TensorDecompositions
Utilities
  > _row_unfold()
  > _col_unfold()
  > tensorcontractmatrices()
8 facts verified.
HO-SVD
  > no residuals calculation
  4.315689 seconds (4.47 M allocations: 207.813 MB, 1.36% gc time)
  > core reconstruction and residuals
  0.181022 seconds (93.40 k allocations: 4.935 MB)
  > core dimension equal to the original dimension
WARNING: Adjusting nev from 10 to 9
WARNING: Adjusting nev from 20 to 19
  0.062416 seconds (44.30 k allocations: 2.560 MB)
    Failure :: (line:-1) :: core dimension equal to the original dimension :: fact was false
      Expression: size(factors.core) --> (10,20,5)
        Expected: (10,20,5)
        Occurred: (9,19,5)
    Failure :: (line:-1) :: core dimension equal to the original dimension :: fact was false
      Expression: rel_residue(factors) --> less_than(1.0e-5)
        Expected: 0.8704432384222641 < 1.0e-5
Out of 8 total facts:
  Verified: 6
  Failed:   2
CANDECOMP
  > Incorrect method
INFO: Initializing factor matrices...
INFO: Applying CANDECOMP ALdS method...
  > ALS (Alternating least squares)
INFO: Initializing factor matrices...
INFO: Applying CANDECOMP ALS method...
WARNING: Maximum number 100 of iterations exceeded.
  1.050319 seconds (404.50 k allocations: 48.845 MB, 1.12% gc time)
  > SGSD (Simultaneous generalized Schur decomposition)
INFO: Initializing factor matrices...
INFO: Applying CANDECOMP SGSD method...
INFO: Algorithm converged after 4 iterations.
  1.722024 seconds (912.21 k allocations: 44.242 MB, 0.45% gc time)
10 facts verified.
SS-HOPM
  > Dense representation
INFO: Algorithm converged after 28 iterations.
  0.673240 seconds (1.07 M allocations: 53.180 MB, 1.67% gc time)
  > Sparse representation
INFO: Algorithm converged after 12 iterations.
  0.142162 seconds (897.31 k allocations: 31.940 MB, 7.67% gc time)
4 facts verified.
Non-negative CANDECOMP
INFO: Algorithm converged after 9 iterations.
  0.320781 seconds (309.43 k allocations: 16.670 MB, 1.27% gc time)
  Failure :: (line:-1) :: fact was false
    Expression: rel_residue(factors) --> less_than(0.05)
      Expected: 0.1132559388930732 < 0.05
Out of 4 total facts:
  Verified: 3
  Failed:   1
Tensor-CUR
  > Small case
    > slab axis: 1
  3.658685 seconds (3.48 M allocations: 169.639 MB, 1.46% gc time)
    > slab axis: 2
  0.341119 seconds (209.08 k allocations: 12.819 MB)
    > slab axis: 3
  0.120145 seconds (62.81 k allocations: 5.267 MB, 5.59% gc time)
  > Large case without reconstruction
  0.037296 seconds (11.55 k allocations: 6.789 MB)
13 facts verified.
PARAFAC2
WARNING: Maximum number 100 of iterations exceeded.
  0.613320 seconds (465.51 k allocations: 25.496 MB, 1.22% gc time)
5 facts verified.
Sparse (semi-)nonnegative Tucker decomposition
  > nonnegative decomposition
INFO: Using High-Order SVD to get initial decomposition...
INFO: Precomputing input tensor unfoldings...
INFO: |tensor|=68.00166877985491
INFO: Rescaling initial decomposition...
INFO: Initial residue=1913.1534109780941
WARNING: 1: residue increase at redo step
WARNING: 1: residue increase at redo step
[1GAlternating proximal gradient iterations  0%|           |  ETA: 0:09:14[K[1GAlternating proximal gradient iterations  5%|â–ˆ          |  ETA: 0:00:24[K[1GAlternating proximal gradient iterations  9%|â–ˆ          |  ETA: 0:00:14[K[1GAlternating proximal gradient iterations 13%|â–ˆ          |  ETA: 0:00:10[K[1GAlternating proximal gradient iterations 16%|â–ˆâ–ˆ         |  ETA: 0:00:08[K[1GAlternating proximal gradient iterations 20%|â–ˆâ–ˆ         |  ETA: 0:00:07[K[1GAlternating proximal gradient iterations 24%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:06[K[1GAlternating proximal gradient iterations 28%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:05[K[1GAlternating proximal gradient iterations 30%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:05[K[1GAlternating proximal gradient iterations 33%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 37%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 40%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[KINFO: Relative error below 0.0001 3 times in a row
INFO: spnntucker() converged in 965 iteration(s), 2 redo steps
[1GAlternating proximal gradient iterations100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:04[K
  7.149260 seconds (13.49 M allocations: 2.255 GB, 4.70% gc time)
    Failure :: (line:-1) :: nonnegative decomposition :: fact was false
      Expression: rel_residue(tucker_spnn) --> less_than(0.05)
        Expected: 0.051855314624193675 < 0.05
INFO: Relative error of decomposition : 0.051855314624193675
  > semi-nonnegative decomposition
INFO: Using High-Order SVD to get initial decomposition...
INFO: Precomputing input tensor unfoldings...
INFO: |tensor|=115.92978180598605
INFO: Rescaling initial decomposition...
INFO: Initial residue=5553.874285269915
WARNING: 1: residue increase at redo step
WARNING: 1: residue increase at redo step
[1GAlternating proximal gradient iterations  2%|           |  ETA: 0:00:06[K[1GAlternating proximal gradient iterations  4%|           |  ETA: 0:00:05[K[1GAlternating proximal gradient iterations  6%|â–ˆ          |  ETA: 0:00:05[K[1GAlternating proximal gradient iterations  8%|â–ˆ          |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 11%|â–ˆ          |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 13%|â–ˆ          |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 15%|â–ˆâ–ˆ         |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 18%|â–ˆâ–ˆ         |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 20%|â–ˆâ–ˆ         |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 22%|â–ˆâ–ˆ         |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 25%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 29%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 31%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 34%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 36%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 38%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 40%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  ETA: 0:00:00[K[1GMaximal number of iterations reached, might be not an optimal solution[K
INFO: Final relative error 0.06531835014697364
[1GAlternating proximal gradient iterations100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:04[K
  3.749025 seconds (5.84 M allocations: 1.956 GB, 6.78% gc time)
INFO: Relative error of decomposition : 0.01253262547900655
Out of 2 total facts:
  Verified: 1
  Failed:   1
INFO: TensorDecompositions tests passed

>>> End of log
