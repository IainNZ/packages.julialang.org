>>> 'Pkg.add("Mocha")' log
INFO: Cloning cache of Logging from git://github.com/kmsquire/Logging.jl.git
INFO: Cloning cache of Mocha from git://github.com/pluskid/Mocha.jl.git
INFO: Installing BinDeps v0.3.21
INFO: Installing Blosc v0.1.5
INFO: Installing Docile v0.5.23
INFO: Installing FileIO v0.0.6
INFO: Installing HDF5 v0.6.1
INFO: Installing JLD v0.6.0
INFO: Installing Logging v0.2.0
INFO: Installing Mocha v0.1.2
INFO: Installing SHA v0.1.2
INFO: Installing URIParser v0.1.3
INFO: Building Blosc
INFO: Building HDF5
INFO: Building Mocha
Running `g++ -fPIC -Wall -O3 -shared -fopenmp -o libmochaext.so im2col.cpp pooling.cpp`
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of Mocha
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("Mocha")' log
Julia Version 0.4.5
Commit 2ac304d (2016-03-18 00:58 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
INFO: Testing Mocha
WARNING: Method definition info(Any...) in module Base at util.jl:334 overwritten in module Logging at /home/vagrant/.julia/v0.4/Logging/src/Logging.jl:61.
WARNING: Method definition warn(Any...) in module Base at util.jl:364 overwritten in module Logging at /home/vagrant/.julia/v0.4/Logging/src/Logging.jl:61.
Configuring Mocha...
 * CUDA       disabled by default
 * Native Ext disabled by default
Mocha configured, continue loading module...
26-May 15:23:44:INFO:root:Recompiling stale cache file /home/vagrant/.julia/lib/v0.4/HDF5.ji for module HDF5.
26-May 15:23:51:INFO:root:Recompiling stale cache file /home/vagrant/.julia/lib/v0.4/JLD.ji for module JLD.
DefaultBackend = Mocha.CPUBackend
-- Testing simple Adam solver call
26-May 15:24:02:INFO:root:Constructing net TEST on Mocha.CPUBackend...
26-May 15:24:02:INFO:root:Topological sorting 4 layers...
26-May 15:24:02:INFO:root:Setup layers...
26-May 15:24:03:INFO:root:Network constructed!
26-May 15:24:03:DEBUG:root:#DEBUG Checking network topology for back-propagation
26-May 15:24:04:DEBUG:root:Init network TEST
26-May 15:24:04:DEBUG:root:Init parameter weight for layer ip1
26-May 15:24:04:DEBUG:root:Init parameter bias for layer ip1
26-May 15:24:04:DEBUG:root:Init parameter weight for layer ip2
26-May 15:24:04:DEBUG:root:Init parameter bias for layer ip2
26-May 15:24:04:DEBUG:root:#DEBUG Initializing coffee breaks
26-May 15:24:04:DEBUG:root:#DEBUG Entering solver loop
26-May 15:24:04:DEBUG:root:Destroying network TEST
-- Testing simple SGD solver call
26-May 15:24:05:INFO:root:Constructing net TEST on Mocha.CPUBackend...
26-May 15:24:05:INFO:root:Topological sorting 4 layers...
26-May 15:24:05:INFO:root:Setup layers...
26-May 15:24:05:INFO:root:Network constructed!
26-May 15:24:05:DEBUG:root:#DEBUG Checking network topology for back-propagation
26-May 15:24:05:DEBUG:root:Init network TEST
26-May 15:24:05:DEBUG:root:Init parameter weight for layer ip1
26-May 15:24:05:DEBUG:root:Init parameter bias for layer ip1
26-May 15:24:05:DEBUG:root:Init parameter weight for layer ip2
26-May 15:24:05:DEBUG:root:Init parameter bias for layer ip2
26-May 15:24:05:DEBUG:root:#DEBUG Initializing coffee breaks
26-May 15:24:05:DEBUG:root:#DEBUG Entering solver loop
26-May 15:24:05:DEBUG:root:Destroying network TEST
-- Testing network topology with duplicated blobs
26-May 15:24:05:INFO:root:Constructing net net on Mocha.CPUBackend...
26-May 15:24:05:INFO:root:Topological sorting 1 layers...
26-May 15:24:05:INFO:root:Constructing net net on Mocha.CPUBackend...
26-May 15:24:05:INFO:root:Topological sorting 2 layers...
-- Testing network topology with missing blobs
26-May 15:24:05:INFO:root:Constructing net net on Mocha.CPUBackend...
26-May 15:24:05:INFO:root:Topological sorting 1 layers...
-- Testing network topology with circular dependency
26-May 15:24:05:INFO:root:Constructing net net on Mocha.CPUBackend...
26-May 15:24:05:INFO:root:Topological sorting 2 layers...
-- Testing network topology with multiple back-propagate path
    > Good blob sharing
26-May 15:24:05:INFO:root:Constructing net net on Mocha.CPUBackend...
26-May 15:24:05:INFO:root:Topological sorting 5 layers...
26-May 15:24:05:INFO:root:Setup layers...
26-May 15:24:05:INFO:root:Network constructed!
26-May 15:24:05:DEBUG:root:Destroying network net
    > Bad blob sharing
26-May 15:24:05:INFO:root:Constructing net net on Mocha.CPUBackend...
26-May 15:24:05:INFO:root:Topological sorting 6 layers...
26-May 15:24:05:INFO:root:Setup layers...
26-May 15:24:06:INFO:root:Network constructed!
-- Testing network topology with dangling blob
    > Good case
26-May 15:24:06:INFO:root:Constructing net net on Mocha.CPUBackend...
26-May 15:24:06:INFO:root:Topological sorting 4 layers...
26-May 15:24:06:INFO:root:Setup layers...
26-May 15:24:06:INFO:root:Network constructed!
26-May 15:24:06:DEBUG:root:Destroying network net
    > Bad case
26-May 15:24:06:INFO:root:Constructing net net on Mocha.CPUBackend...
26-May 15:24:06:INFO:root:Topological sorting 4 layers...
26-May 15:24:06:INFO:root:Setup layers...
26-May 15:24:06:INFO:root:Network constructed!
26-May 15:24:06:DEBUG:root:Destroying network net
    > Good case 2
26-May 15:24:07:INFO:root:Constructing net net on Mocha.CPUBackend...
26-May 15:24:07:INFO:root:Topological sorting 5 layers...
26-May 15:24:07:INFO:root:Setup layers...
26-May 15:24:07:INFO:root:Network constructed!
26-May 15:24:07:DEBUG:root:Destroying network net
    > Bad case 2
26-May 15:24:07:INFO:root:Constructing net net on Mocha.CPUBackend...
26-May 15:24:07:INFO:root:Topological sorting 6 layers...
26-May 15:24:07:INFO:root:Setup layers...
26-May 15:24:07:INFO:root:Network constructed!
26-May 15:24:07:DEBUG:root:Destroying network net
-- Testing gradients on simple network (example for gradient checking code)
26-May 15:24:07:INFO:root:Constructing net TEST on Mocha.CPUBackend...
26-May 15:24:07:INFO:root:Topological sorting 4 layers...
26-May 15:24:07:INFO:root:Setup layers...
26-May 15:24:07:INFO:root:Network constructed!
-- Testing simple reference counting...
-- Testing glob Utilities
-- Testing RawBLAS{Float32} Utilities
-- Testing RawBLAS{Float64} Utilities
-- Testing blob reshape on Mocha.CPUBackend{Float32}...
-- Testing blob reshape on Mocha.CPUBackend{Float64}...
-- Testing ReLU neuron on Mocha.CPUBackend{Float32}...
    > Forward
    > Backward
-- Testing ReLU neuron on Mocha.CPUBackend{Float64}...
    > Forward
    > Backward
-- Testing Sigmoid neuron on Mocha.CPUBackend{Float32}...
    > Forward
    > Backward
-- Testing Sigmoid neuron on Mocha.CPUBackend{Float64}...
    > Forward
    > Backward
-- Testing Tanh neuron on Mocha.CPUBackend{Float32}...
    > Forward
    > Backward
-- Testing Tanh neuron on Mocha.CPUBackend{Float64}...
    > Forward
    > Backward
-- Testing Exponential neuron on Mocha.CPUBackend{Float32}...
    > Forward
    > Backward
-- Testing Exponential neuron on Mocha.CPUBackend{Float64}...
    > Forward
    > Backward
-- Testing L2 regularizer on Mocha.CPUBackend{Float32}...
-- Testing L2 regularizer on Mocha.CPUBackend{Float64}...
-- Testing L1 regularizer on Mocha.CPUBackend{Float32}...
-- Testing L1 regularizer on Mocha.CPUBackend{Float64}...
-- Testing L2 constraint on Mocha.CPUBackend{Float32}...
-- Testing L2 constraint on Mocha.CPUBackend{Float64}...
-- Testing DataTransformers on Mocha.CPUBackend{Float32}...
    > SubMean
    > Scale
-- Testing DataTransformers on Mocha.CPUBackend{Float64}...
    > SubMean
    > Scale
-- Testing TiedInnerProductLayer on Mocha.CPUBackend{Float32}...
    > Setup
26-May 15:24:15:INFO:root:Constructing net test-tied-ip on Mocha.CPUBackend...
26-May 15:24:15:INFO:root:Topological sorting 3 layers...
26-May 15:24:15:INFO:root:Setup layers...
26-May 15:24:15:INFO:root:Network constructed!
26-May 15:24:15:DEBUG:root:Init network test-tied-ip
26-May 15:24:15:DEBUG:root:Init parameter weight for layer ip1
26-May 15:24:15:DEBUG:root:Init parameter bias for layer ip1
26-May 15:24:15:DEBUG:root:Init parameter bias for layer ip2
    > Forward
    > Backward
26-May 15:24:16:DEBUG:root:Destroying network test-tied-ip
-- Testing TiedInnerProductLayer on Mocha.CPUBackend{Float64}...
    > Setup
26-May 15:24:16:INFO:root:Constructing net test-tied-ip on Mocha.CPUBackend...
26-May 15:24:16:INFO:root:Topological sorting 3 layers...
26-May 15:24:16:INFO:root:Setup layers...
26-May 15:24:16:INFO:root:Network constructed!
26-May 15:24:16:DEBUG:root:Init network test-tied-ip
26-May 15:24:16:DEBUG:root:Init parameter weight for layer ip1
26-May 15:24:16:DEBUG:root:Init parameter bias for layer ip1
26-May 15:24:16:DEBUG:root:Init parameter bias for layer ip2
    > Forward
    > Backward
26-May 15:24:16:DEBUG:root:Destroying network test-tied-ip
-- Testing SquareLossLayer on Mocha.CPUBackend{Float32}...
    > (6,8)
-- Testing SquareLossLayer on Mocha.CPUBackend{Float64}...
    > (10,10)
-- Testing SplitLayer on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
    > Backward
-- Testing SplitLayer on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float64} ...
    > (9,9) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float64} ...
    > (9,8,10,7) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float64} ...
    > (6,7,11,6,8) (operate on dimension 3)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float64} (with weights)...
    > (7,8) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float64} (with weights)...
    > (10,11,8,8) (operate on dimension 3)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float64} (with weights)...
    > (6,6,9,6,10) (operate on dimension 4)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float32} ...
    > (8,11) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float32} ...
    > (6,11,8,8) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float32} ...
    > (9,7,7,9,10) (operate on dimension 3)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float32} (with weights)...
    > (8,7) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float32} (with weights)...
    > (10,6,7,11) (operate on dimension 3)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float32} (with weights)...
    > (9,7,7,8,6) (operate on dimension 4)
    > Forward
    > Backward
-- Testing SoftmaxLayer on Mocha.CPUBackend{Float64}...
    > 2-dimensional input, normalize along dimension 1
    > Forward
    > Backward
-- Testing SoftmaxLayer on Mocha.CPUBackend{Float64}...
    > 4-dimensional input, normalize along dimension 1
    > Forward
    > Backward
-- Testing SoftmaxLayer on Mocha.CPUBackend{Float64}...
    > 5-dimensional input, normalize along dimension 3
    > Forward
    > Backward
-- Testing SoftmaxLayer on Mocha.CPUBackend{Float32}...
    > 2-dimensional input, normalize along dimension 1
    > Forward
    > Backward
-- Testing SoftmaxLayer on Mocha.CPUBackend{Float32}...
    > 4-dimensional input, normalize along dimension 2
    > Forward
    > Backward
-- Testing SoftmaxLayer on Mocha.CPUBackend{Float32}...
    > 5-dimensional input, normalize along dimension 2
    > Forward
    > Backward
-- Testing SoftlabelSoftmaxLossLayer on Mocha.CPUBackend{Float64}...
    > (9,6) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftlabelSoftmaxLossLayer on Mocha.CPUBackend{Float64}...
    > (10,7,7,8) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftlabelSoftmaxLossLayer on Mocha.CPUBackend{Float64}...
    > (10,10,6,7,10) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftlabelSoftmaxLossLayer on Mocha.CPUBackend{Float32}...
    > (9,9) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftlabelSoftmaxLossLayer on Mocha.CPUBackend{Float32}...
    > (8,9,6,9) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftlabelSoftmaxLossLayer on Mocha.CPUBackend{Float32}...
    > (6,6,11,9,6) (operate on dimension 4)
    > Forward
    > Backward
-- Testing convolution layer with shared param on Mocha.CPUBackend{Float64}...
26-May 15:24:31:INFO:root:Constructing net test-shared-params on Mocha.CPUBackend...
26-May 15:24:31:INFO:root:Topological sorting 5 layers...
26-May 15:24:31:INFO:root:Setup layers...
26-May 15:24:31:DEBUG:root:ConvolutionLayer(conv2): sharing filters and bias
26-May 15:24:31:INFO:root:Network constructed!
26-May 15:24:31:DEBUG:root:Init network test-shared-params
26-May 15:24:31:DEBUG:root:Init parameter filter for layer conv1
26-May 15:24:31:DEBUG:root:Init parameter bias for layer conv1
26-May 15:24:32:DEBUG:root:Destroying network test-shared-params
-- Testing inner-product layer with shared param on Mocha.CPUBackend{Float64}...
26-May 15:24:32:INFO:root:Constructing net test-shared-params on Mocha.CPUBackend...
26-May 15:24:32:INFO:root:Topological sorting 5 layers...
26-May 15:24:32:INFO:root:Setup layers...
26-May 15:24:32:DEBUG:root:InnerProductLayer(ip2): sharing weights and bias
26-May 15:24:32:INFO:root:Network constructed!
26-May 15:24:32:DEBUG:root:Init network test-shared-params
26-May 15:24:32:DEBUG:root:Init parameter weight for layer ip1
26-May 15:24:32:DEBUG:root:Init parameter bias for layer ip1
26-May 15:24:32:DEBUG:root:Destroying network test-shared-params
-- Testing convolution layer with shared param on Mocha.CPUBackend{Float32}...
26-May 15:24:32:INFO:root:Constructing net test-shared-params on Mocha.CPUBackend...
26-May 15:24:32:INFO:root:Topological sorting 5 layers...
26-May 15:24:32:INFO:root:Setup layers...
26-May 15:24:32:DEBUG:root:ConvolutionLayer(conv2): sharing filters and bias
26-May 15:24:32:INFO:root:Network constructed!
26-May 15:24:32:DEBUG:root:Init network test-shared-params
26-May 15:24:32:DEBUG:root:Init parameter filter for layer conv1
26-May 15:24:32:DEBUG:root:Init parameter bias for layer conv1
26-May 15:24:32:DEBUG:root:Destroying network test-shared-params
-- Testing inner-product layer with shared param on Mocha.CPUBackend{Float32}...
26-May 15:24:32:INFO:root:Constructing net test-shared-params on Mocha.CPUBackend...
26-May 15:24:32:INFO:root:Topological sorting 5 layers...
26-May 15:24:32:INFO:root:Setup layers...
26-May 15:24:32:DEBUG:root:InnerProductLayer(ip2): sharing weights and bias
26-May 15:24:32:INFO:root:Network constructed!
26-May 15:24:32:DEBUG:root:Init network test-shared-params
26-May 15:24:32:DEBUG:root:Init parameter weight for layer ip1
26-May 15:24:32:DEBUG:root:Init parameter bias for layer ip1
26-May 15:24:32:DEBUG:root:Destroying network test-shared-params
-- Testing ReshapeLayer on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
    > Backward
-- Testing ReshapeLayer on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
    > Backward
-- Testing RandomNormal Layer on Mocha.CPUBackend{Float32}...
    > Random output 1[3]
-- Testing RandomNormal Layer on Mocha.CPUBackend{Float64}...
    > Random output 3[2,2,3]
-- Testing RandomMask on Mocha.CPUBackend{Float64}
    > 3 input blobs with tensor dims [3,1,4]
    > Setup
    > Forward
    > Backward
-- Testing RandomMask on Mocha.CPUBackend{Float32}
    > 3 input blobs with tensor dims [5,4,3]
    > Setup
    > Forward
    > Backward
-- Testing PowerLayer on Mocha.CPUBackend{Float32}...
    > scale=0.24, shift=0.38, power=2, tensor_dim=4
    > scale=0, shift=0.7, power=5, tensor_dim=4
    > scale=0.01, shift=0.26, power=2, tensor_dim=5
    > scale=0.74, shift=0, power=3, tensor_dim=6
    > scale=0.66, shift=0.11, power=4, tensor_dim=3
    > scale=0.46, shift=0.58, power=0, tensor_dim=6
    > scale=0.32, shift=0.03, power=1, tensor_dim=3
    > scale=0.89, shift=0.56, power=-1, tensor_dim=5
-- Testing PowerLayer on Mocha.CPUBackend{Float64}...
    > scale=0.53, shift=0.68, power=2, tensor_dim=4
    > scale=0, shift=0.81, power=6, tensor_dim=2
    > scale=0.32, shift=0.6, power=2, tensor_dim=4
    > scale=0.65, shift=0, power=3, tensor_dim=3
    > scale=0.07, shift=0.72, power=4, tensor_dim=6
    > scale=0.19, shift=0.25, power=0, tensor_dim=1
    > scale=0.04, shift=0.27, power=1, tensor_dim=5
    > scale=0.12, shift=0.28, power=-1, tensor_dim=5
-- Testing Pooling(Mocha.Pooling.Max)  on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Mean)  on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Max) with padding on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Mean) with padding on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Max)  on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Mean)  on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Max) with padding on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Mean) with padding on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
    > Backward
-- Testing MultinomialLogisticLossLayer{equal,local} on Mocha.CPUBackend{Float64}...
    > [6,8] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{equal,local} on Mocha.CPUBackend{Float64}...
    > [7,10,7,7] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{equal,local} on Mocha.CPUBackend{Float64}...
    > [8,11,11,8,9] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{local,local} on Mocha.CPUBackend{Float64}...
    > [8,6] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{local,local} on Mocha.CPUBackend{Float64}...
    > [8,9,6,10] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{local,local} on Mocha.CPUBackend{Float64}...
    > [11,11,11,8,8] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{global,global} on Mocha.CPUBackend{Float64}...
    > [9,11] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{global,global} on Mocha.CPUBackend{Float64}...
    > [10,11,8,6] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{global,global} on Mocha.CPUBackend{Float64}...
    > [9,9,8,11,9] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{global,local} on Mocha.CPUBackend{Float64}...
    > [7,8] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{global,local} on Mocha.CPUBackend{Float64}...
    > [11,9,6,6] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{global,local} on Mocha.CPUBackend{Float64}...
    > [10,8,10,6,7] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{no,no} on Mocha.CPUBackend{Float64}...
    > [9,6] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{no,no} on Mocha.CPUBackend{Float64}...
    > [8,11,9,10] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{no,no} on Mocha.CPUBackend{Float64}...
    > [10,6,10,11,11] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{equal,local} on Mocha.CPUBackend{Float32}...
    > [7,10] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{equal,local} on Mocha.CPUBackend{Float32}...
    > [8,8,10,7] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{equal,local} on Mocha.CPUBackend{Float32}...
    > [9,10,10,7,7] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{local,local} on Mocha.CPUBackend{Float32}...
    > [7,7] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{local,local} on Mocha.CPUBackend{Float32}...
    > [8,8,10,9] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{local,local} on Mocha.CPUBackend{Float32}...
    > [9,8,8,10,8] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{global,global} on Mocha.CPUBackend{Float32}...
    > [7,10] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{global,global} on Mocha.CPUBackend{Float32}...
    > [10,11,6,6] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{global,global} on Mocha.CPUBackend{Float32}...
    > [10,9,11,8,6] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{global,local} on Mocha.CPUBackend{Float32}...
    > [8,9] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{global,local} on Mocha.CPUBackend{Float32}...
    > [7,10,10,11] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{global,local} on Mocha.CPUBackend{Float32}...
    > [7,11,8,6,9] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{no,no} on Mocha.CPUBackend{Float32}...
    > [6,10] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{no,no} on Mocha.CPUBackend{Float32}...
    > [8,10,6,7] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{no,no} on Mocha.CPUBackend{Float32}...
    > [8,8,7,10,10] (operate on dimension 1)
-- Testing Memory Output Layer on Mocha.CPUBackend{Float32}...
    > (2,5)
-- Testing Memory Output Layer on Mocha.CPUBackend{Float64}...
    > (6,8,8)
-- Testing Memory Data Layer on Mocha.CPUBackend{Float32}...
    > (4,2,1,5,1,1)
-- Testing Memory Data Layer on Mocha.CPUBackend{Float64}...
    > (3,6,4)
-- Testing LRN(Mocha.LRNMode.AcrossChannel) on Mocha.CPUBackend{Float32}...
    > Setup with dims (11,11,8,8)
    > Forward
    > Backward
-- Testing LRN(Mocha.LRNMode.WithinChannel) on Mocha.CPUBackend{Float32}...
    > Setup with dims (7,10,8,11)
    > Forward
    > Backward
-- Testing LRN(Mocha.LRNMode.AcrossChannel) on Mocha.CPUBackend{Float64}...
    > Setup with dims (11,9,7,11)
    > Forward
    > Backward
-- Testing LRN(Mocha.LRNMode.WithinChannel) on Mocha.CPUBackend{Float64}...
    > Setup with dims (7,7,11,10)
    > Forward
    > Backward
-- Testing InplaceLayer on Mocha.CPUBackend{Float64}...
    > Setup
26-May 15:24:59:INFO:root:Constructing net test-inplace on Mocha.CPUBackend...
26-May 15:24:59:INFO:root:Topological sorting 5 layers...
26-May 15:24:59:INFO:root:Setup layers...
26-May 15:24:59:INFO:root:Network constructed!
26-May 15:24:59:DEBUG:root:Init network test-inplace
26-May 15:24:59:DEBUG:root:Init parameter weight for layer ip1
26-May 15:24:59:DEBUG:root:Init parameter bias for layer ip1
26-May 15:24:59:DEBUG:root:Init parameter weight for layer ip2
26-May 15:24:59:DEBUG:root:Init parameter bias for layer ip2
    > Forward
    > Backward
26-May 15:24:59:DEBUG:root:Destroying network test-inplace
-- Testing InplaceLayer on Mocha.CPUBackend{Float32}...
    > Setup
26-May 15:24:59:INFO:root:Constructing net test-inplace on Mocha.CPUBackend...
26-May 15:24:59:INFO:root:Topological sorting 5 layers...
26-May 15:24:59:INFO:root:Setup layers...
26-May 15:24:59:INFO:root:Network constructed!
26-May 15:24:59:DEBUG:root:Init network test-inplace
26-May 15:24:59:DEBUG:root:Init parameter weight for layer ip1
26-May 15:24:59:DEBUG:root:Init parameter bias for layer ip1
26-May 15:24:59:DEBUG:root:Init parameter weight for layer ip2
26-May 15:24:59:DEBUG:root:Init parameter bias for layer ip2
    > Forward
    > Backward
26-May 15:25:00:DEBUG:root:Destroying network test-inplace
-- Testing InnerProductLayer on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
    > Backward
-- Testing InnerProductLayer on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
    > Backward
-- Testing Index2OnehotLayer on Mocha.CPUBackend{Float32}...
    > 2-dimensional input, expanding along dimension 1
-- Testing Index2OnehotLayer on Mocha.CPUBackend{Float32}...
    > 4-dimensional input, expanding along dimension 2
-- Testing Index2OnehotLayer on Mocha.CPUBackend{Float32}...
    > 5-dimensional input, expanding along dimension 2
-- Testing Index2OnehotLayer on Mocha.CPUBackend{Float64}...
    > 2-dimensional input, expanding along dimension 1
-- Testing Index2OnehotLayer on Mocha.CPUBackend{Float64}...
    > 4-dimensional input, expanding along dimension 1
-- Testing Index2OnehotLayer on Mocha.CPUBackend{Float64}...
    > 5-dimensional input, expanding along dimension 1
-- Testing IdentityLayer on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
-- Testing IdentityLayer on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
-- Testing HingeLossLayer on Mocha.CPUBackend{Float32}...
    > (6,11,7,8)
-- Testing HingeLossLayer on Mocha.CPUBackend{Float64}...
    > (11,7,7,11)
-- Testing HDF5 Output Layer on Mocha.CPUBackend{Float32}...
    > (5,7)
26-May 15:25:02:WARNING:root:HDF5OutputLayer: output file '/tmp/Mocha-23922-H3zC4z4w3BV2oW700hsAYGSiUNBeNGq1.hdf5' already exists, overwriting
-- Testing HDF5 Output Layer on Mocha.CPUBackend{Float64}...
    > (2,2,8,8,1)
26-May 15:25:03:WARNING:root:HDF5OutputLayer: output file '/tmp/Mocha-23922-IM6F8auDpyT1IKaiocejF3gihog2umMr.hdf5' already exists, overwriting
-- Testing  HDF5 Data Layer on Mocha.CPUBackend{Float32}...
    > (6,7,1)
-- Testing (Async) HDF5 Data Layer on Mocha.CPUBackend{Float32}...
    > (6,1,1,4,5)
26-May 15:25:06:INFO:root:AsyncHDF5DataLayer: Stopping IO task...
26-May 15:25:06:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...
-- Testing  HDF5 Data Layer on Mocha.CPUBackend{Float64}...
    > (3,8)
-- Testing (Async) HDF5 Data Layer on Mocha.CPUBackend{Float64}...
    > (3,6,3,2,4)
26-May 15:25:07:INFO:root:AsyncHDF5DataLayer: Stopping IO task...
26-May 15:25:07:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...
-- Testing  HDF5 Data Layer (shuffle,n=6,b=4) on Mocha.CPUBackend{Float32}...
-- Testing (Async) HDF5 Data Layer (shuffle,n=6,b=4) on Mocha.CPUBackend{Float32}...
26-May 15:25:07:INFO:root:AsyncHDF5DataLayer: Stopping IO task...
26-May 15:25:07:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...
-- Testing  HDF5 Data Layer (shuffle,n=4,b=6) on Mocha.CPUBackend{Float32}...
-- Testing (Async) HDF5 Data Layer (shuffle,n=4,b=6) on Mocha.CPUBackend{Float32}...
26-May 15:25:07:INFO:root:AsyncHDF5DataLayer: Stopping IO task...
26-May 15:25:07:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...
-- Testing  HDF5 Data Layer (shuffle,n=6,b=4) on Mocha.CPUBackend{Float64}...
-- Testing (Async) HDF5 Data Layer (shuffle,n=6,b=4) on Mocha.CPUBackend{Float64}...
26-May 15:25:08:INFO:root:AsyncHDF5DataLayer: Stopping IO task...
26-May 15:25:08:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...
-- Testing  HDF5 Data Layer (shuffle,n=4,b=6) on Mocha.CPUBackend{Float64}...
-- Testing (Async) HDF5 Data Layer (shuffle,n=4,b=6) on Mocha.CPUBackend{Float64}...
26-May 15:25:08:INFO:root:AsyncHDF5DataLayer: Stopping IO task...
26-May 15:25:08:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...
-- Testing GaussianKLLossLayer on Mocha.CPUBackend{Float32}...
    > (11,9,6,11,11)
-- Testing GaussianKLLossLayer on Mocha.CPUBackend{Float64}...
    > (11,8,10,6)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Add()} on Mocha.CPUBackend{Float32}...
    > (8,1,7,2)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Subtract()} on Mocha.CPUBackend{Float32}...
    > (3,6,4,5,8)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Multiply()} on Mocha.CPUBackend{Float32}...
    > (1,)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Divide()} on Mocha.CPUBackend{Float32}...
    > (8,4,4)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Add()} on Mocha.CPUBackend{Float64}...
    > (2,1,7,5,1,4)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Subtract()} on Mocha.CPUBackend{Float64}...
    > (7,2,8,6)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Multiply()} on Mocha.CPUBackend{Float64}...
    > (2,6)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Divide()} on Mocha.CPUBackend{Float64}...
    > (3,5,8,7,5)
-- Testing Dropout on Mocha.CPUBackend{Float64}...
    > (4,5,3,5,2)
    > Setup
    > Forward
    > Backward
-- Testing Dropout on Mocha.CPUBackend{Float32}...
    > (5,)
    > Setup
    > Forward
    > Backward
-- Testing CropLayer on Mocha.CPUBackend{Float64} ...
    > Setup
    > Forward
-- Testing CropLayer on Mocha.CPUBackend{Float64} with mirror...
    > Setup
    > Forward
-- Testing CropLayer{rnd} on Mocha.CPUBackend{Float64} ...
    > Setup
    > Forward
-- Testing CropLayer{rnd} on Mocha.CPUBackend{Float64} with mirror...
    > Setup
    > Forward
-- Testing CropLayer on Mocha.CPUBackend{Float32} ...
    > Setup
    > Forward
-- Testing CropLayer on Mocha.CPUBackend{Float32} with mirror...
    > Setup
    > Forward
-- Testing CropLayer{rnd} on Mocha.CPUBackend{Float32} ...
    > Setup
    > Forward
-- Testing CropLayer{rnd} on Mocha.CPUBackend{Float32} with mirror...
    > Setup
    > Forward
-- Testing Convolution(frozen=true) on Mocha.CPUBackend{Float64} filter=(3,4)...
    > Setup
    > Forward
    > Backward
-- Testing Convolution(frozen=false) on Mocha.CPUBackend{Float64} filter=(3,4)...
    > Setup
    > Forward
    > Backward
maximum(abs(grad_filter_exp - grad_filter_got)) = 3.410605131648481e-12
eps = 1.0e-5
-- Testing Convolution(frozen=true) on Mocha.CPUBackend{Float64} filter=(1,1)...
    > Setup
    > Forward
    > Backward
-- Testing Convolution(frozen=false) on Mocha.CPUBackend{Float64} filter=(1,1)...
    > Setup
    > Forward
    > Backward
maximum(abs(grad_filter_exp - grad_filter_got)) = 7.275957614183426e-12
eps = 1.0e-5
-- Testing Convolution(frozen=true) on Mocha.CPUBackend{Float32} filter=(3,4)...
    > Setup
    > Forward
    > Backward
-- Testing Convolution(frozen=false) on Mocha.CPUBackend{Float32} filter=(3,4)...
    > Setup
    > Forward
    > Backward
maximum(abs(grad_filter_exp - grad_filter_got)) = 0.0017089844f0
eps = 0.01
-- Testing Convolution(frozen=true) on Mocha.CPUBackend{Float32} filter=(1,1)...
    > Setup
    > Forward
    > Backward
-- Testing Convolution(frozen=false) on Mocha.CPUBackend{Float32} filter=(1,1)...
    > Setup
    > Forward
    > Backward
maximum(abs(grad_filter_exp - grad_filter_got)) = 0.0036621094f0
eps = 0.01
-- Testing ConcatLayer(dim=1) on Mocha.CPUBackend{Float64}...
    > 4-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=2) on Mocha.CPUBackend{Float64}...
    > 3-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=3) on Mocha.CPUBackend{Float64}...
    > 3-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=4) on Mocha.CPUBackend{Float64}...
    > 4-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=5) on Mocha.CPUBackend{Float64}...
    > 7-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=1) on Mocha.CPUBackend{Float32}...
    > 2-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=2) on Mocha.CPUBackend{Float32}...
    > 6-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=3) on Mocha.CPUBackend{Float32}...
    > 3-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=4) on Mocha.CPUBackend{Float32}...
    > 6-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=5) on Mocha.CPUBackend{Float32}...
    > 5-dimensional tensor
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 1 for 2-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 2 for 3-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 1 for 4-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 2 for 5-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 5 for 6-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 1 for 2-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 2 for 3-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 3 for 4-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 1 for 5-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 1 for 6-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 1 for 2-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 1 for 3-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 2 for 4-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 2 for 5-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 1 for 6-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 1 for 2-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 2 for 3-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 1 for 4-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 4 for 5-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 1 for 6-D tensors)
    > Forward
    > Backward
-- Testing BinaryCrossEntropyLossLayer on Mocha.CPUBackend{Float32}...
    > [3,6]
-- Testing BinaryCrossEntropyLossLayer on Mocha.CPUBackend{Float32}...
    > [4,7,7,7]
-- Testing BinaryCrossEntropyLossLayer on Mocha.CPUBackend{Float32}...
    > [2,7,5,4,2]
-- Testing BinaryCrossEntropyLossLayer on Mocha.CPUBackend{Float64}...
    > [2,3]
-- Testing BinaryCrossEntropyLossLayer on Mocha.CPUBackend{Float64}...
    > [7,7,6,3]
-- Testing BinaryCrossEntropyLossLayer on Mocha.CPUBackend{Float64}...
    > [4,7,5,3,5]
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float32}...
    > (7,11)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float32}...
    > (7,7)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float32}...
    > (7,7,11,10)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float32}...
    > (6,9,7,8)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float32}...
    > (6,11,8,7,7)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float32}...
    > (10,9,6,8,8)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float64}...
    > (6,8)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float64}...
    > (11,11)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float64}...
    > (10,9,9,8)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float64}...
    > (6,7,7,9)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float64}...
    > (10,11,10,11,7)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float64}...
    > (11,9,6,10,6)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing ArgmaxLayer on Mocha.CPUBackend{Float64}...
    > 2-dimensional tensor
    > Setup
    > Forward
-- Testing ArgmaxLayer on Mocha.CPUBackend{Float64}...
    > 4-dimensional tensor
    > Setup
    > Forward
-- Testing ArgmaxLayer on Mocha.CPUBackend{Float64}...
    > 5-dimensional tensor
    > Setup
    > Forward
-- Testing ArgmaxLayer on Mocha.CPUBackend{Float32}...
    > 2-dimensional tensor
    > Setup
    > Forward
-- Testing ArgmaxLayer on Mocha.CPUBackend{Float32}...
    > 4-dimensional tensor
    > Setup
    > Forward
-- Testing ArgmaxLayer on Mocha.CPUBackend{Float32}...
    > 5-dimensional tensor
    > Setup
    > Forward
-- Testing AccuracyLayer on Mocha.CPUBackend{Float32}...
    > (11,8) (operate on dimension 1)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing AccuracyLayer on Mocha.CPUBackend{Float32}...
    > (9,6,7,10) (operate on dimension 2)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing AccuracyLayer on Mocha.CPUBackend{Float32}...
    > (8,7,10,8,10) (operate on dimension 1)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing AccuracyLayer on Mocha.CPUBackend{Float64}...
    > (6,7) (operate on dimension 1)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing AccuracyLayer on Mocha.CPUBackend{Float64}...
    > (6,8,9,9) (operate on dimension 1)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing AccuracyLayer on Mocha.CPUBackend{Float64}...
    > (11,7,7,8,10) (operate on dimension 3)
    > Forward
    > Forward Again
    > Forward Again and Again
INFO: Mocha tests passed

>>> End of log
