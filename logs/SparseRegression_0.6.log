>>> 'Pkg.add("SparseRegression")' log
INFO: Cloning cache of SparseRegression from https://github.com/joshday/SparseRegression.jl.git
INFO: Installing LearnBase v0.1.6
INFO: Installing LearningStrategies v0.3.0
INFO: Installing LossFunctions v0.2.0
INFO: Installing PenaltyFunctions v0.0.2
INFO: Installing RecipesBase v0.2.3
INFO: Installing SparseRegression v0.0.1
INFO: Installing SweepOperator v0.1.0
INFO: Package database updated

>>> 'Pkg.test("SparseRegression")' log
Julia Version 0.6.2
Commit d386e40c17 (2017-12-13 18:08 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-143-generic #192-Ubuntu SMP Tue Feb 27 10:45:36 UTC 2018 x86_64 x86_64
Memory: 2.939197540283203 GB (1450.75390625 MB free)
Uptime: 64761.0 sec
Load Avg:  0.92529296875  0.9541015625  0.951171875
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3498 MHz    3905281 s       5233 s     257259 s    1429422 s         59 s
#2  3498 MHz    1100266 s       1867 s     111952 s    5137333 s          1 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.9.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
6 required packages:
 - Conda                         0.7.1
 - JSON                          0.17.2
 - PyCall                        1.15.0
 - PyPlot                        2.5.0
 - RDatasets                     0.4.0
 - SparseRegression              0.0.1
34 additional packages:
 - BinDeps                       0.8.8
 - BinaryProvider                0.3.0
 - CSV                           0.2.4
 - CategoricalArrays             0.3.9
 - CodecZlib                     0.4.3
 - ColorTypes                    0.6.7
 - Colors                        0.8.2
 - Compat                        0.63.0
 - DataFrames                    0.11.6
 - DataStreams                   0.3.4
 - DataStructures                0.8.1
 - FileIO                        0.7.0
 - FixedPointNumbers             0.4.6
 - LaTeXStrings                  0.3.0
 - LearnBase                     0.1.6
 - LearningStrategies            0.3.0
 - LossFunctions                 0.2.0
 - MacroTools                    0.4.0
 - Missings                      0.2.9
 - Mocking                       0.5.2
 - NamedTuples                   4.0.0
 - Nullables                     0.0.5
 - PenaltyFunctions              0.0.2
 - RData                         0.4.0
 - RecipesBase                   0.2.3
 - Reexport                      0.1.0
 - SHA                           0.5.7
 - SortingAlgorithms             0.2.1
 - StatsBase                     0.21.0
 - SweepOperator                 0.1.0
 - TimeZones                     0.6.5
 - TranscodingStreams            0.5.2
 - URIParser                     0.3.1
 - WeakRefStrings                0.4.4
INFO: Testing SparseRegression
█ SModel
  > β        : [0.0 0.0 0.0 0.0 0.0]
  > λ factor : [0.1 0.1 0.1 0.1 0.1]
  > Loss     : 0.5 * (L2DistLoss)
  > Penalty  : L2Penalty
  > Data
    - x : 1000×5 Array{Float64,2}
    - y : 1000-element Array{Float64,1}
    - w : Void

INFO: SparseRegression.ProxGrad
  > L2DistLoss
  > 0.5 * (L2DistLoss)
  > HuberLoss with $\alpha$ = 2.0
  > QuantileLoss with $\tau$ = 0.7
  > LogitMarginLoss
  > DWDMarginLoss with q = 2.0
  > L2HingeLoss
  > ExpLoss

INFO: SparseRegression.Fista
  > L2DistLoss
  > 0.5 * (L2DistLoss)
  > HuberLoss with $\alpha$ = 2.0
  > QuantileLoss with $\tau$ = 0.7
  > LogitMarginLoss
  > DWDMarginLoss with q = 2.0
  > L2HingeLoss
  > ExpLoss

INFO: SparseRegression.AdaptiveProxGrad
  > L2DistLoss
  > 0.5 * (L2DistLoss)
  > HuberLoss with $\alpha$ = 2.0
  > QuantileLoss with $\tau$ = 0.7
  > LogitMarginLoss
  > DWDMarginLoss with q = 2.0
  > L2HingeLoss
  > ExpLoss

INFO: SparseRegression.GradientDescent
  > L2DistLoss
  > 0.5 * (L2DistLoss)
  > HuberLoss with $\alpha$ = 2.0
  > QuantileLoss with $\tau$ = 0.7
  > LogitMarginLoss
  > DWDMarginLoss with q = 2.0
  > L2HingeLoss
  > ExpLoss

Test Summary: | Pass  Total
Sanity Check  |  272    272
Test Summary:     | Pass  Total
Linear Regression |    5      5
Test Summary: | Pass  Total
SModel        |    2      2
INFO: SparseRegression tests passed

>>> End of log
