>>> 'Pkg.add("SALSA")' log
INFO: Cloning cache of SALSA from git://github.com/jumutc/SALSA.jl.git
INFO: Installing ArrayViews v0.6.4
INFO: Installing BinDeps v0.4.7
INFO: Installing Blosc v0.2.1
INFO: Installing BufferedStreams v0.3.3
INFO: Installing Calculus v0.2.2
INFO: Installing Clustering v0.7.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.11.1
INFO: Installing HDF5 v0.7.3
INFO: Installing Iterators v0.3.1
INFO: Installing LegacyStrings v0.2.2
INFO: Installing Libz v0.2.4
INFO: Installing MAT v0.3.2
INFO: Installing MLBase v0.6.1
INFO: Installing NearestNeighbors v0.0.5
INFO: Installing PDMats v0.6.0
INFO: Installing ProgressMeter v0.3.4
INFO: Installing Reexport v0.0.3
INFO: Installing Rmath v0.1.7
INFO: Installing SALSA v0.1.0
INFO: Installing SHA v0.3.3
INFO: Installing StatsBase v0.12.0
INFO: Installing StatsFuns v0.4.0
INFO: Installing URIParser v0.1.8
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of SALSA
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("SALSA")' log
Julia Version 0.4.7
Commit ae26b25 (2016-09-18 16:17 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-121-generic #170-Ubuntu SMP Wed Jun 14 09:04:33 UTC 2017 x86_64 x86_64
Memory: 2.9392738342285156 GB (403.44140625 MB free)
Uptime: 34254.0 sec
Load Avg:  1.11865234375  1.03076171875  0.97607421875
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3501 MHz    1657952 s       4321 s     125235 s    1303500 s         61 s
#2  3501 MHz    1171408 s       2237 s     107968 s    2038436 s          1 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.4
2 required packages:
 - JSON                          0.9.1
 - SALSA                         0.1.0
24 additional packages:
 - ArrayViews                    0.6.4
 - BinDeps                       0.4.7
 - Blosc                         0.2.1
 - BufferedStreams               0.3.3
 - Calculus                      0.2.2
 - Clustering                    0.7.0
 - Compat                        0.26.0
 - Distances                     0.3.2
 - Distributions                 0.11.1
 - HDF5                          0.7.3
 - Iterators                     0.3.1
 - LegacyStrings                 0.2.2
 - Libz                          0.2.4
 - MAT                           0.3.2
 - MLBase                        0.6.1
 - NearestNeighbors              0.0.5
 - PDMats                        0.6.0
 - ProgressMeter                 0.3.4
 - Reexport                      0.0.3
 - Rmath                         0.1.7
 - SHA                           0.3.3
 - StatsBase                     0.12.0
 - StatsFuns                     0.4.0
 - URIParser                     0.1.8
INFO: Testing SALSA
Running tests:
* unit/test_loss_derivative.jl
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/SALSA/src/support/data_wrapper.jl:19
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/SALSA/src/support/data_wrapper.jl:19
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/SALSA/src/support/data_wrapper.jl:26
WARNING: New definition 
    dot(#T<:Base.SparseMatrix.AbstractSparseArray, #T<:Base.SparseMatrix.AbstractSparseArray) at /home/vagrant/.julia/v0.4/SALSA/src/support/definitions.jl:27
is ambiguous with: 
    dot(AbstractArray{T<:Any, 1}, AbstractArray{T<:Any, 1}) at linalg/generic.jl:292.
To fix, define 
    dot(_<:Base.SparseMatrix.AbstractSparseArray{T<:Any, Ti<:Any, 1}, _<:Base.SparseMatrix.AbstractSparseArray{T<:Any, Ti<:Any, 1})
before the new definition.
WARNING: New definition 
    kernel_matrix(SALSA.Kernel, SALSA.DelimitedFile, Any) at /home/vagrant/.julia/v0.4/SALSA/src/kernels/kernels.jl:31
is ambiguous with: 
    kernel_matrix(SALSA.Kernel, Any, Base.SubArray) at /home/vagrant/.julia/v0.4/SALSA/src/kernels/kernels.jl:29.
To fix, define 
    kernel_matrix(SALSA.Kernel, SALSA.DelimitedFile, Base.SubArray)
before the new definition.
WARNING: New definition 
    hinge_loss(#T<:Base.SparseMatrix.AbstractSparseArray, Any, Any) at /home/vagrant/.julia/v0.4/SALSA/src/loss_derivative.jl:63
is ambiguous with: 
    hinge_loss(Any, #T<:Number, Any) at /home/vagrant/.julia/v0.4/SALSA/src/loss_derivative.jl:61.
To fix, define 
    hinge_loss(_<:Any, _<:Any, Any)
before the new definition.
WARNING: New definition 
    squared_hinge_loss(#T<:Base.SparseMatrix.AbstractSparseArray, Any, Any, Any) at /home/vagrant/.julia/v0.4/SALSA/src/loss_derivative.jl:78
is ambiguous with: 
    squared_hinge_loss(Any, #T<:Number, Any, Any) at /home/vagrant/.julia/v0.4/SALSA/src/loss_derivative.jl:76.
To fix, define 
    squared_hinge_loss(_<:Any, _<:Any, Any, Any)
before the new definition.
WARNING: New definition 
    logistic_loss(#T<:Base.SparseMatrix.AbstractSparseArray, Any, Any) at /home/vagrant/.julia/v0.4/SALSA/src/loss_derivative.jl:100
is ambiguous with: 
    logistic_loss(Any, #T<:Number, Any) at /home/vagrant/.julia/v0.4/SALSA/src/loss_derivative.jl:98.
To fix, define 
    logistic_loss(_<:Any, _<:Any, Any)
before the new definition.
WARNING: New definition 
    logistic_loss(#T<:Base.SparseMatrix.AbstractSparseArray, Any, Any, Any) at /home/vagrant/.julia/v0.4/SALSA/src/loss_derivative.jl:100
is ambiguous with: 
    logistic_loss(Any, #T<:Number, Any, Any) at /home/vagrant/.julia/v0.4/SALSA/src/loss_derivative.jl:98.
To fix, define 
    logistic_loss(_<:Any, _<:Any, Any, Any)
before the new definition.
WARNING: New definition 
    least_squares_loss(#T<:Base.SparseMatrix.AbstractSparseArray, Any, Any) at /home/vagrant/.julia/v0.4/SALSA/src/loss_derivative.jl:105
is ambiguous with: 
    least_squares_loss(Any, #T<:Number, Any) at /home/vagrant/.julia/v0.4/SALSA/src/loss_derivative.jl:104.
To fix, define 
    least_squares_loss(_<:Any, _<:Any, Any)
before the new definition.


  ____    _    _     ____    _       [31m_ [0m_   | Software Lab for Advanced Machine Learning
 / ___|  / \  | |   / ___|  / \     [31m([31m_[31m) [0m|  | with Stochastic Algorithms in Julia
 \___ \ / _ \ | |   \___ \ / _ \    | | |  |
  ___) / ___ \| |___ ___) / ___ \ [32m_ [0m| | |  | Docs & license: http://salsajl.readthedocs.org
 |____/_/   \_\_____|____/_/   \_[32m([32m_[32m)[0m/ |_|  | CI builds: http://travis-ci.org/jumutc/SALSA.jl
                                  |__/     | Version: 0.1.0

* unit/test_pegasos.jl
* unit/test_wrapper.jl
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/SALSA/test/unit/test_wrapper.jl:3
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/SALSA/test/unit/test_wrapper.jl:3
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/SALSA/test/unit/test_wrapper.jl:3
* unit/test_sparse.jl
* unit/test_show.jl
* functional/qa_tables/test_qa.jl
* functional/test_wrapper.jl
* functional/regression/test_fsinc.jl
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:00:20[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:16[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:14[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:13[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:13[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:10[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:09[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:08[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:06[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:04[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:02[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:01[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:19[K
CSA results: optimal mean squared error = 0.005
[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:17[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:15[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:13[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:08[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:07[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:06[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:05[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:03[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:02[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:20[K
CSA results: optimal mean squared error = 0.026
* functional/clustering/test_clustering.jl
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:03:04[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:04[K
DS results: optimal mean silhouette = 0.501
* functional/classification/test_linear.jl
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:00:44[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:39[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:37[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:36[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:34[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:30[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:27[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:24[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:23[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:20[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:18[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:16[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:14[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:10[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:08[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:06[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:04[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:02[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:39[K
CSA results: optimal misclassification rate = 0.136
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:00:56[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:49[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:46[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:40[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:37[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:33[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:31[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:29[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:27[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:25[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:23[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:20[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:18[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:15[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:10[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:07[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:05[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:03[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:51[K
CSA results: optimal misclassification rate = 0.132
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:21[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:03[K
DS results: optimal misclassification rate = 0.160
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:01:00[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:01[K
DS results: optimal AUC (area under curve) = 0.934
DS results: optimal misclassification rate = 0.136
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:00:52[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:01[K
DS results: optimal misclassification rate = 0.144
DS results: optimal misclassification rate = 0.176
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:15[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:03[K
DS results: optimal weighted combination of: error/sparsity = 0.315
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:58[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:04[K
DS results: optimal weighted combination of: error/sparsity = 0.318
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:03:31[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:04[K
DS results: optimal weighted combination of: error/sparsity = 0.222
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:59[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:04[K
DS results: optimal weighted combination of: error/sparsity = 0.318
* functional/classification/test_sparse.jl
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:01:03[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:59[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:52[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:50[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:47[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:43[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:39[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:35[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:33[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:30[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:27[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:23[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:20[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:17[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:14[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:09[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:06[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:03[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:59[K
CSA results: optimal misclassification rate = 0.132
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:00:51[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:52[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:43[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:39[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:37[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:35[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:33[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:31[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:29[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:27[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:25[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:22[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:20[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:16[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:14[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:08[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:05[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:03[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:55[K
CSA results: optimal misclassification rate = 0.132
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:01:07[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:01[K
DS results: optimal AUC (area under curve) = 0.935
DS results: optimal misclassification rate = 0.136
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:00:59[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:01[K
DS results: optimal misclassification rate = 0.148
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:01:43[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:02[K
DS results: optimal misclassification rate = 0.160
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:03:51[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:05[K
DS results: optimal weighted combination of: error/sparsity = 0.315
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:06:05[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:07[K
DS results: optimal weighted combination of: error/sparsity = 0.232
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:38[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:03[K
DS results: optimal weighted combination of: error/sparsity = 0.222
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:04:22[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:05[K
DS results: optimal weighted combination of: error/sparsity = 0.312
* functional/classification/test_multiclass.jl
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:02:47[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:02:12[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:01:55[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:01:54[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:01:51[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:01:44[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:01:34[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:01:28[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:01:21[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:01:14[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:01:07[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:59[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:50[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:41[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:33[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:27[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:20[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:13[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:07[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:02:11[K
CSA results: optimal misclassification rate = 0.382
* functional/classification/test_nonlinear.jl
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:01:09[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:01:06[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:01:00[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:56[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:52[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:48[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:44[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:39[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:34[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:30[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:26[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:23[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:19[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:16[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:13[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:08[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:05[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:03[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:52[K
CSA results: optimal misclassification rate = 0.152
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:01[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:02[K
DS results: optimal misclassification rate = 0.172
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:01:02[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:01[K
DS results: optimal misclassification rate = 0.148
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:06:19[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:08[K
DS results: optimal weighted combination of: error/sparsity = 0.166
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:08:17[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:10[K
DS results: optimal weighted combination of: error/sparsity = 0.190
INFO: SALSA tests passed

>>> End of log
