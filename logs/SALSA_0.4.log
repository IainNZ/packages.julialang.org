>>> 'Pkg.add("SALSA")' log
INFO: Cloning cache of SALSA from git://github.com/jumutc/SALSA.jl.git
INFO: Installing ArrayViews v0.6.4
INFO: Installing BinDeps v0.3.21
INFO: Installing Blosc v0.1.5
INFO: Installing Clustering v0.5.0
INFO: Installing Distributions v0.9.0
INFO: Installing HDF5 v0.6.1
INFO: Installing Iterators v0.1.9
INFO: Installing MAT v0.2.14
INFO: Installing MLBase v0.5.2
INFO: Installing PDMats v0.4.1
INFO: Installing ProgressMeter v0.3.1
INFO: Installing Reexport v0.0.3
INFO: Installing SALSA v0.0.5
INFO: Installing SHA v0.1.2
INFO: Installing StatsBase v0.8.1
INFO: Installing StatsFuns v0.2.2
INFO: Installing URIParser v0.1.3
INFO: Installing Zlib v0.1.12
INFO: Building Blosc
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of SALSA
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("SALSA")' log
Julia Version 0.4.5
Commit 2ac304d (2016-03-18 00:58 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
INFO: Testing SALSA
Running tests:
* unit/test_loss_derivative.jl
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/MLBase/src/modeltune.jl:5
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/MLBase/src/modeltune.jl:5
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/MLBase/src/modeltune.jl:5
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.4/MLBase/src/deprecated/datapre.jl:104
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.4/MLBase/src/deprecated/datapre.jl:105
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.4/MLBase/src/deprecated/datapre.jl:163
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.4/MLBase/src/deprecated/datapre.jl:163
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.4/MLBase/src/deprecated/datapre.jl:163
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/SALSA/src/support/data_wrapper.jl:19
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/SALSA/src/support/data_wrapper.jl:19
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/SALSA/src/support/data_wrapper.jl:26
WARNING: New definition 
    kernel_matrix(SALSA.Kernel, SALSA.DelimitedFile, Any) at /home/vagrant/.julia/v0.4/SALSA/src/kernels/kernels.jl:31
is ambiguous with: 
    kernel_matrix(SALSA.Kernel, Any, Base.SubArray) at /home/vagrant/.julia/v0.4/SALSA/src/kernels/kernels.jl:29.
To fix, define 
    kernel_matrix(SALSA.Kernel, SALSA.DelimitedFile, Base.SubArray)
before the new definition.


  ____    _    _     ____    _       [31m_ [0m_   | Software Lab for Advanced Machine Learning
 / ___|  / \  | |   / ___|  / \     [31m([31m_[31m) [0m|  | and Stochastic Algorithms in Julia
 \___ \ / _ \ | |   \___ \ / _ \    | | |  |
  ___) / ___ \| |___ ___) / ___ \ [32m_ [0m| | |  | Documentation: http://salsajl.readthedocs.org
 |____/_/   \_\_____|____/_/   \_[32m([32m_[32m)[0m/ |_|  | CI builds: http://travis-ci.org/jumutc/SALSA.jl
                                  |__/     | Version: 0.0.5

* unit/test_pegasos.jl
* unit/test_wrapper.jl
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/SALSA/test/unit/test_wrapper.jl:3
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/SALSA/test/unit/test_wrapper.jl:3
WARNING: Base.String is deprecated, use AbstractString instead.
  likely near /home/vagrant/.julia/v0.4/SALSA/test/unit/test_wrapper.jl:3
* unit/test_sparse.jl
* unit/test_show.jl
* functional/qa_tables/test_qa.jl
* functional/test_wrapper.jl
INFO: Recompiling stale cache file /home/vagrant/.julia/lib/v0.4/HDF5.ji for module HDF5.
INFO: Recompiling stale cache file /home/vagrant/.julia/lib/v0.4/MAT.ji for module MAT.
* functional/regression/test_fsinc.jl
[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:09[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:07[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:06[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:04[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:03[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:13[K
CSA results: optimal mean squared error = 0.005
[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:15[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:13[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:10[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:08[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:06[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:05[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:03[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:02[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:16[K
CSA results: optimal mean squared error = 0.026
* functional/clustering/test_clustering.jl
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:15[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:03[K
DS results: optimal mean silhouette = 0.501
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:34:19[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:42[K
DS results: optimal mean silhouette = 0.285
* functional/classification/test_linear.jl
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:00:28[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:27[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:26[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:26[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:24[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:19[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:18[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:16[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:15[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:13[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:10[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:09[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:06[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:04[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:03[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:01[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:28[K
CSA results: optimal misclassification rate = 0.136
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:00:44[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:33[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:28[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:25[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:24[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:23[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:20[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:19[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:17[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:16[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:14[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:09[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:08[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:06[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:05[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:03[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:02[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:33[K
CSA results: optimal misclassification rate = 0.132
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:01:21[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:02[K
DS results: optimal misclassification rate = 0.160
DS results: optimal AUC (area under curve) = 0.934
DS results: optimal misclassification rate = 0.136
DS results: optimal misclassification rate = 0.144
DS results: optimal misclassification rate = 0.176
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:01:05[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:01[K
DS results: optimal weighted combination of: error/sparsity = 0.315
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:01:31[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:02[K
DS results: optimal weighted combination of: error/sparsity = 0.318
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:27[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:03[K
DS results: optimal weighted combination of: error/sparsity = 0.222
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:49[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:03[K
DS results: optimal weighted combination of: error/sparsity = 0.318
* functional/classification/test_sparse.jl
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:00:35[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:41[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:40[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:36[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:32[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:30[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:28[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:25[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:24[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:22[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:20[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:18[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:16[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:13[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:09[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:07[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:05[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:02[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:45[K
CSA results: optimal misclassification rate = 0.132
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:00:37[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:39[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:36[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:32[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:32[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:31[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:29[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:27[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:25[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:23[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:21[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:18[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:16[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:14[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:09[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:07[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:05[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:02[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:45[K
CSA results: optimal misclassification rate = 0.132
DS results: optimal AUC (area under curve) = 0.935
DS results: optimal misclassification rate = 0.136
DS results: optimal misclassification rate = 0.148
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:01:17[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:02[K
DS results: optimal misclassification rate = 0.152
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:28[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:03[K
DS results: optimal weighted combination of: error/sparsity = 0.315
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:06:18[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:08[K
DS results: optimal weighted combination of: error/sparsity = 0.232
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:55[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:04[K
DS results: optimal weighted combination of: error/sparsity = 0.222
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:56[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:04[K
DS results: optimal weighted combination of: error/sparsity = 0.312
* functional/classification/test_multiclass.jl
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:01:37[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:01:44[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:01:37[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:01:28[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:01:24[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:01:13[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:01:06[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:01:00[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:54[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:49[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:46[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:40[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:34[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:29[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:24[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:19[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:14[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:09[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:05[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:01:32[K
CSA results: optimal misclassification rate = 0.382
* functional/classification/test_nonlinear.jl
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:00:45[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:41[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:40[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:38[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:35[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:31[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:29[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:27[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:25[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:23[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:20[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:17[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:15[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:13[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:08[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:06[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:04[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:02[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:41[K
CSA results: optimal misclassification rate = 0.152
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:01:49[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:02[K
DS results: optimal misclassification rate = 0.172
DS results: optimal misclassification rate = 0.148
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:03:17[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:04[K
DS results: optimal weighted combination of: error/sparsity = 0.166
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:06:12[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:08[K
DS results: optimal weighted combination of: error/sparsity = 0.190
INFO: SALSA tests passed

>>> End of log
