>>> 'Pkg.add("Spark")' log
INFO: Cloning cache of JavaCall from https://github.com/JuliaInterop/JavaCall.jl.git
INFO: Cloning cache of Spark from https://github.com/dfdx/Spark.jl.git
INFO: Installing Iterators v0.3.1
INFO: Installing JavaCall v0.4.4
INFO: Installing Spark v0.1.0
INFO: Building Spark
================================[ ERROR: Spark ]================================

LoadError: Cannot find maven. Is it installed?
while loading /home/vagrant/.julia/v0.6/Spark/deps/build.jl, in expression starting on line 5

================================================================================

================================[ BUILD ERRORS ]================================

WARNING: Spark had build errors.

 - packages with build errors remain installed in /home/vagrant/.julia/v0.6
 - build the package(s) and all dependencies with `Pkg.build("Spark")`
 - build a single package by running its `deps/build.jl` script

================================================================================
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of Spark
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("Spark")' log
Julia Version 0.6.0-rc1.0
Commit 6bdb395 (2017-05-07 00:00 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64
Memory: 2.9392738342285156 GB (829.0234375 MB free)
Uptime: 59015.0 sec
Load Avg:  1.04150390625  1.025390625  0.9931640625
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3499 MHz    3787631 s       7015 s     160055 s     952169 s         42 s
#2  3499 MHz     723478 s         76 s      78826 s    4998755 s          1 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.9.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
2 required packages:
 - JSON                          0.11.0
 - Spark                         0.1.0
3 additional packages:
 - Compat                        0.24.0
 - Iterators                     0.3.1
 - JavaCall                      0.4.4
INFO: Testing Spark
WARNING: Array{T}(::Type{T}, m::Int) is deprecated, use Array{T}(m) instead.
Stacktrace:
 [1] depwarn(::String, ::Symbol) at ./deprecated.jl:64
 [2] Array(::Type{String}, ::Int64) at ./deprecated.jl:51
 [3] include_from_node1(::String) at ./loading.jl:552
 [4] include(::String) at ./sysimg.jl:14
 [5] include_from_node1(::String) at ./loading.jl:552
 [6] eval(::Module, ::Any) at ./boot.jl:235
 [7] _require(::Symbol) at ./loading.jl:466
 [8] require(::Symbol) at ./loading.jl:386
 [9] include_from_node1(::String) at ./loading.jl:552
 [10] include(::String) at ./sysimg.jl:14
 [11] include_from_node1(::String) at ./loading.jl:552
 [12] eval(::Module, ::Any) at ./boot.jl:235
 [13] _require(::Symbol) at ./loading.jl:466
 [14] require(::Symbol) at ./loading.jl:386
 [15] include_from_node1(::String) at ./loading.jl:552
 [16] include(::String) at ./sysimg.jl:14
 [17] process_options(::Base.JLOptions) at ./client.jl:305
 [18] _start() at ./client.jl:371
while loading /home/vagrant/.julia/v0.6/JavaCall/src/jvm.jl, in expression starting on line 124
WARNING: Array{T}(::Type{T}, m::Int) is deprecated, use Array{T}(m) instead.
Stacktrace:
 [1] depwarn(::String, ::Symbol) at ./deprecated.jl:64
 [2] Array(::Type{String}, ::Int64) at ./deprecated.jl:51
 [3] include_from_node1(::String) at ./loading.jl:552
 [4] include(::String) at ./sysimg.jl:14
 [5] include_from_node1(::String) at ./loading.jl:552
 [6] eval(::Module, ::Any) at ./boot.jl:235
 [7] _require(::Symbol) at ./loading.jl:466
 [8] require(::Symbol) at ./loading.jl:386
 [9] include_from_node1(::String) at ./loading.jl:552
 [10] include(::String) at ./sysimg.jl:14
 [11] include_from_node1(::String) at ./loading.jl:552
 [12] eval(::Module, ::Any) at ./boot.jl:235
 [13] _require(::Symbol) at ./loading.jl:466
 [14] require(::Symbol) at ./loading.jl:386
 [15] include_from_node1(::String) at ./loading.jl:552
 [16] include(::String) at ./sysimg.jl:14
 [17] process_options(::Base.JLOptions) at ./client.jl:305
 [18] _start() at ./client.jl:371
while loading /home/vagrant/.julia/v0.6/JavaCall/src/jvm.jl, in expression starting on line 125
ERROR: LoadError: LoadError: LoadError: LoadError: LoadError: invalid return type or argument type in ccall
Stacktrace:
 [1] include_from_node1(::String) at ./loading.jl:552
 [2] include(::String) at ./sysimg.jl:14
 [3] include_from_node1(::String) at ./loading.jl:552
 [4] eval(::Module, ::Any) at ./boot.jl:235
 [5] _require(::Symbol) at ./loading.jl:466
 [6] require(::Symbol) at ./loading.jl:386
 [7] include_from_node1(::String) at ./loading.jl:552
 [8] include(::String) at ./sysimg.jl:14
 [9] include_from_node1(::String) at ./loading.jl:552
while loading /home/vagrant/.julia/v0.6/JavaCall/src/jvm.jl, in expression starting on line 161
while loading /home/vagrant/.julia/v0.6/JavaCall/src/JavaCall.jl, in expression starting on line 32
while loading /home/vagrant/.julia/v0.6/Spark/src/core.jl, in expression starting on line 2
while loading /home/vagrant/.julia/v0.6/Spark/src/Spark.jl, in expression starting on line 18
while loading /home/vagrant/.julia/v0.6/Spark/test/runtests.jl, in expression starting on line 1
================================[ ERROR: Spark ]================================

failed process: Process(`/home/vagrant/julia/bin/julia -Cx86-64 -J/home/vagrant/julia/lib/julia/sys.so --compile=yes --depwarn=yes --check-bounds=yes --code-coverage=none --color=no --compilecache=yes /home/vagrant/.julia/v0.6/Spark/test/runtests.jl`, ProcessExited(1)) [1]

================================================================================
ERROR: Spark had test errors

>>> End of log
