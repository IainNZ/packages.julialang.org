>>> 'Pkg.add("Spark")' log
INFO: Cloning cache of JavaCall from https://github.com/JuliaInterop/JavaCall.jl.git
INFO: Cloning cache of Spark from https://github.com/dfdx/Spark.jl.git
INFO: Installing DataStructures v0.7.2
INFO: Installing JavaCall v0.5.2
INFO: Installing Spark v0.2.0
INFO: Building Spark
================================[ ERROR: Spark ]================================

LoadError: Cannot find maven. Is it installed?
while loading /home/vagrant/.julia/v0.6/Spark/deps/build.jl, in expression starting on line 7

================================================================================

================================[ BUILD ERRORS ]================================

WARNING: Spark had build errors.

 - packages with build errors remain installed in /home/vagrant/.julia/v0.6
 - build the package(s) and all dependencies with `Pkg.build("Spark")`
 - build a single package by running its `deps/build.jl` script

================================================================================
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of Spark
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("Spark")' log
Julia Version 0.6.1
Commit 0d7248e2ff (2017-10-24 22:15 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64
Memory: 2.93927001953125 GB (1528.50390625 MB free)
Uptime: 82171.0 sec
Load Avg:  1.02783203125  1.02490234375  1.0029296875
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    5485097 s       7050 s     225309 s    1218724 s         60 s
#2  3500 MHz    1258707 s         83 s     113962 s    6702282 s          0 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.9.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
2 required packages:
 - JSON                          0.16.1
 - Spark                         0.2.0
3 additional packages:
 - Compat                        0.37.0
 - DataStructures                0.7.2
 - JavaCall                      0.5.2
INFO: Testing Spark
Loaded /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so
ERROR: LoadError: LoadError: Class Not Found org/apache/spark/SparkConf
Stacktrace:
 [1] _metaclass(::Symbol) at /home/vagrant/.julia/v0.6/JavaCall/src/core.jl:238
 [2] metaclass(::Symbol) at /home/vagrant/.julia/v0.6/JavaCall/src/core.jl:244
 [3] jnew(::Symbol, ::Tuple{}) at /home/vagrant/.julia/v0.6/JavaCall/src/core.jl:124
 [4] Spark.SparkConf(::Dict{Any,Any}) at /home/vagrant/.julia/v0.6/Spark/src/config.jl:12
 [5] Spark.SparkConf() at /home/vagrant/.julia/v0.6/Spark/src/config.jl:7
 [6] include_from_node1(::String) at ./loading.jl:576
 [7] include(::String) at ./sysimg.jl:14
 [8] include_from_node1(::String) at ./loading.jl:576
 [9] include(::String) at ./sysimg.jl:14
 [10] process_options(::Base.JLOptions) at ./client.jl:305
 [11] _start() at ./client.jl:371
while loading /home/vagrant/.julia/v0.6/Spark/test/basic.jl, in expression starting on line 4
while loading /home/vagrant/.julia/v0.6/Spark/test/runtests.jl, in expression starting on line 7
================================[ ERROR: Spark ]================================

failed process: Process(`/home/vagrant/julia/bin/julia -Cx86-64 -J/home/vagrant/julia/lib/julia/sys.so --compile=yes --depwarn=yes --check-bounds=yes --code-coverage=none --color=no --compilecache=yes /home/vagrant/.julia/v0.6/Spark/test/runtests.jl`, ProcessExited(1)) [1]

================================================================================
ERROR: Spark had test errors

>>> End of log
