>>> 'Pkg.add("Spark")' log
INFO: Cloning cache of JavaCall from https://github.com/JuliaInterop/JavaCall.jl.git
INFO: Cloning cache of Spark from https://github.com/dfdx/Spark.jl.git
INFO: Installing JavaCall v0.5.2
INFO: Installing Spark v0.3.0
INFO: Building Spark
================================[ ERROR: Spark ]================================

LoadError: Cannot find maven. Is it installed?
while loading /home/vagrant/.julia/v0.6/Spark/deps/build.jl, in expression starting on line 7

================================================================================

================================[ BUILD ERRORS ]================================

WARNING: Spark had build errors.

 - packages with build errors remain installed in /home/vagrant/.julia/v0.6
 - build the package(s) and all dependencies with `Pkg.build("Spark")`
 - build a single package by running its `deps/build.jl` script

================================================================================
INFO: Package database updated

>>> 'Pkg.test("Spark")' log
Julia Version 0.6.2
Commit d386e40c17 (2017-12-13 18:08 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-143-generic #192-Ubuntu SMP Tue Feb 27 10:45:36 UTC 2018 x86_64 x86_64
Memory: 2.939197540283203 GB (1483.453125 MB free)
Uptime: 67873.0 sec
Load Avg:  0.9970703125  0.9853515625  0.95458984375
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    4070392 s       6845 s     274127 s    1465154 s         56 s
#2  3500 MHz    1132002 s         49 s     106965 s    5418951 s          1 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.9.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
6 required packages:
 - Conda                         0.7.1
 - JSON                          0.17.2
 - PyCall                        1.15.0
 - PyPlot                        2.5.0
 - RDatasets                     0.4.0
 - Spark                         0.3.0
29 additional packages:
 - BinDeps                       0.8.7
 - BinaryProvider                0.3.0
 - CSV                           0.2.4
 - CategoricalArrays             0.3.9
 - CodecZlib                     0.4.3
 - ColorTypes                    0.6.7
 - Colors                        0.8.2
 - Compat                        0.63.0
 - DataFrames                    0.11.6
 - DataStreams                   0.3.4
 - DataStructures                0.7.4
 - FileIO                        0.7.0
 - FixedPointNumbers             0.4.6
 - JavaCall                      0.5.2
 - LaTeXStrings                  0.3.0
 - MacroTools                    0.4.0
 - Missings                      0.2.9
 - Mocking                       0.5.2
 - NamedTuples                   4.0.0
 - Nullables                     0.0.5
 - RData                         0.4.0
 - Reexport                      0.1.0
 - SHA                           0.5.7
 - SortingAlgorithms             0.2.1
 - StatsBase                     0.21.0
 - TimeZones                     0.6.5
 - TranscodingStreams            0.5.2
 - URIParser                     0.3.1
 - WeakRefStrings                0.4.4
INFO: Testing Spark
Loaded /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so
ERROR: LoadError: LoadError: Class Not Found org/apache/spark/SparkConf
Stacktrace:
 [1] _metaclass(::Symbol) at /home/vagrant/.julia/v0.6/JavaCall/src/core.jl:238
 [2] metaclass(::Symbol) at /home/vagrant/.julia/v0.6/JavaCall/src/core.jl:244
 [3] jnew(::Symbol, ::Tuple{}) at /home/vagrant/.julia/v0.6/JavaCall/src/core.jl:124
 [4] Spark.SparkConf(::Dict{Any,Any}) at /home/vagrant/.julia/v0.6/Spark/src/config.jl:12
 [5] Spark.SparkConf() at /home/vagrant/.julia/v0.6/Spark/src/config.jl:7
 [6] include_from_node1(::String) at ./loading.jl:576
 [7] include(::String) at ./sysimg.jl:14
 [8] include_from_node1(::String) at ./loading.jl:576
 [9] include(::String) at ./sysimg.jl:14
 [10] process_options(::Base.JLOptions) at ./client.jl:305
 [11] _start() at ./client.jl:371
while loading /home/vagrant/.julia/v0.6/Spark/test/basic.jl, in expression starting on line 4
while loading /home/vagrant/.julia/v0.6/Spark/test/runtests.jl, in expression starting on line 7
================================[ ERROR: Spark ]================================

failed process: Process(`/home/vagrant/julia/bin/julia -Cx86-64 -J/home/vagrant/julia/lib/julia/sys.so --compile=yes --depwarn=yes --check-bounds=yes --code-coverage=none --color=no --compilecache=yes /home/vagrant/.julia/v0.6/Spark/test/runtests.jl`, ProcessExited(1)) [1]

================================================================================
ERROR: Spark had test errors

>>> End of log
