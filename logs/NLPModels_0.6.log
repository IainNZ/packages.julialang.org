>>> 'Pkg.add("NLPModels")' log
INFO: Cloning cache of NLPModels from https://github.com/JuliaSmoothOptimizers/NLPModels.jl.git
INFO: Installing LinearOperators v0.3.0
INFO: Installing NLPModels v0.2.0
INFO: Package database updated
INFO: METADATA is out-of-date — you may not have the latest version of NLPModels
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("NLPModels")' log
Julia Version 0.6.0
Commit 9036443 (2017-06-19 13:05 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-125-generic #174-Ubuntu SMP Mon Jul 10 18:51:24 UTC 2017 x86_64 x86_64
Memory: 2.9392738342285156 GB (1108.48046875 MB free)
Uptime: 27304.0 sec
Load Avg:  0.9970703125  0.9853515625  1.1064453125
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    1744736 s       7260 s      82821 s     469832 s         25 s
#2  3500 MHz     430418 s        710 s      45395 s    2207370 s          0 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.9.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
2 required packages:
 - JSON                          0.13.0
 - NLPModels                     0.2.0
2 additional packages:
 - Compat                        0.29.0
 - LinearOperators               0.3.0
INFO: Computing test dependencies for NLPModels...
INFO: Installing BinDeps v0.7.0
INFO: Installing Calculus v0.2.2
INFO: Installing CommonSubexpressions v0.0.1
INFO: Installing DataStructures v0.6.1
INFO: Installing DiffBase v0.2.0
INFO: Installing ForwardDiff v0.5.0
INFO: Installing Ipopt v0.2.6
INFO: Installing JuMP v0.18.0
INFO: Installing MathProgBase v0.6.4
INFO: Installing NaNMath v0.2.6
INFO: Installing RealInterface v0.0.3
INFO: Installing ReverseDiffSparse v0.8.0
INFO: Installing SHA v0.5.0
INFO: Installing SpecialFunctions v0.3.0
INFO: Installing StaticArrays v0.6.1
INFO: Installing URIParser v0.2.0
INFO: Building Ipopt
INFO: Testing NLPModels

WARNING: deprecated syntax "function .*(...)".
Use "function Base.broadcast(::typeof(*), ...)" instead.

WARNING: deprecated syntax "function .*(...)".
Use "function Base.broadcast(::typeof(*), ...)" instead.

WARNING: deprecated syntax "function .+(...)".
Use "function Base.broadcast(::typeof(+), ...)" instead.

WARNING: deprecated syntax "function .+(...)".
Use "function Base.broadcast(::typeof(+), ...)" instead.

WARNING: deprecated syntax "function .-(...)".
Use "function Base.broadcast(::typeof(-), ...)" instead.

WARNING: deprecated syntax "function .-(...)".
Use "function Base.broadcast(::typeof(-), ...)" instead.
Testing printing of nlp.meta
Minimization problem Unconstrained example
nvar = 10, ncon = 0 (0 linear)
lvar = -1.0   -1.0   -1.0   -1.0  ⋯  -Inf
uvar = 1.0   1.0   1.0   Inf  ⋯  4.0
lcon = ∅
ucon = ∅
x0 = 0.0   0.0   0.0   0.0  ⋯  0.0
y0 = ∅
nnzh = 100
nnzj = 0
Minimization problem Constrained example
nvar = 10, ncon = 3 (0 linear)
lvar = -Inf   -Inf   -Inf   -Inf  ⋯  -Inf
uvar = Inf   Inf   Inf   Inf  ⋯  Inf
lcon = 0.0   0.0   -Inf
ucon = Inf   0.0   0.0
x0 = 0.0   0.0   0.0   0.0  ⋯  0.0
y0 = 0.0   0.0   0.0
nnzh = 100
nnzj = 30
nonlinear constraints: 1   2   3
Checking slack formulation of genrose	✓
Checking slack formulation of hs5	✓
Checking slack formulation of hs6	✓
Checking slack formulation of hs10    	✓
Checking slack formulation of hs11    	✓
Checking slack formulation of hs14    	✓
Checking slack formulation of hs15    	✓
Checking LBFGS formulation of hs10    	✓
Checking LSR1 formulation of hs10    	✓
Checking LBFGS formulation of hs11    	✓
Checking LSR1 formulation of hs11    	✓
Checking LBFGS formulation of hs14    	✓
Checking LSR1 formulation of hs14    	✓
Checking LBFGS formulation of hs15    	✓
Checking LSR1 formulation of hs15    	✓
For tests to pass, all models must have been written identically.
Constraints, if any, must have been declared in the same order.
                        	Consistency   Derivative Check   Slack variant
Checking problem brownden            ✓               ✓                  -
Checking problem hs5                 ✓               ✓                  -
Checking problem hs6                 ✓               ✓                  -
Checking problem hs10                ✓               ✓                  ✓
Checking problem hs11                ✓               ✓                  ✓
Checking problem hs14                ✓               ✓                  ✓
Minimization problem Generic
nvar = 2, ncon = 1 (0 linear)
Minimization problem Generic
nvar = 2, ncon = 1 (0 linear)
lvar = -1.0   -1.0
uvar = 1.0   1.0
lcon = 0.0
ucon = 0.0
x0 = 1.0   1.0
y0 = 0.0
nnzh = 4
nnzj = 2
nonlinear constraints: 1

******************************************************************************
This program contains Ipopt, a library for large-scale nonlinear optimization.
 Ipopt is released as open source code under the Eclipse Public License (EPL).
         For more information visit http://projects.coin-or.org/Ipopt
******************************************************************************

This is Ipopt version 3.12.1, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Number of nonzeros in equality constraint Jacobian...:        2
Number of nonzeros in inequality constraint Jacobian.:        0
Number of nonzeros in Lagrangian Hessian.............:        2

Total number of variables............................:        2
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        2
                     variables with only upper bounds:        0
Total number of equality constraints.................:        1
Total number of inequality constraints...............:        0
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  1.9602000e+00 9.80e-01 0.00e+00  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0
   1  5.0000000e-01 0.00e+00 3.83e+01  -1.0 4.90e-01    -  2.47e-02 1.00e+00f  1
   2  5.0000000e-01 0.00e+00 7.94e-15  -1.0 0.00e+00    -  1.00e+00 1.00e+00   0
   3  5.0000000e-01 0.00e+00 5.55e-17  -2.5 0.00e+00    -  1.00e+00 1.00e+00   0
   4  5.0000000e-01 0.00e+00 2.82e-17  -3.8 0.00e+00    -  1.00e+00 1.00e+00   0
   5  5.0000000e-01 0.00e+00 1.02e-16  -5.7 3.39e-21    -  1.00e+00 1.00e+00T  0
   6  5.0000000e-01 0.00e+00 1.09e-17  -8.6 0.00e+00    -  1.00e+00 1.00e+00T  0

Number of Iterations....: 6

                                   (scaled)                 (unscaled)
Objective...............:   5.0000000000000000e-01    5.0000000000000000e-01
Dual infeasibility......:   1.0851339087274842e-17    1.0851339087274842e-17
Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00
Complementarity.........:   2.5059035596800845e-09    2.5059035596800845e-09
Overall NLP error.......:   2.5059035596800845e-09    2.5059035596800845e-09


Number of objective function evaluations             = 7
Number of objective gradient evaluations             = 7
Number of equality constraint evaluations            = 7
Number of inequality constraint evaluations          = 0
Number of equality constraint Jacobian evaluations   = 7
Number of inequality constraint Jacobian evaluations = 0
Number of Lagrangian Hessian evaluations             = 6
Total CPU secs in IPOPT (w/o function evaluations)   =      0.333
Total CPU secs in NLP function evaluations           =      0.060

EXIT: Optimal Solution Found.
INFO: NLPModels tests passed
INFO: Removing BinDeps v0.7.0
INFO: Removing Calculus v0.2.2
INFO: Removing CommonSubexpressions v0.0.1
INFO: Removing DataStructures v0.6.1
INFO: Removing DiffBase v0.2.0
INFO: Removing ForwardDiff v0.5.0
INFO: Removing Ipopt v0.2.6
INFO: Removing JuMP v0.18.0
INFO: Removing MathProgBase v0.6.4
INFO: Removing NaNMath v0.2.6
INFO: Removing RealInterface v0.0.3
INFO: Removing ReverseDiffSparse v0.8.0
INFO: Removing SHA v0.5.0
INFO: Removing SpecialFunctions v0.3.0
INFO: Removing StaticArrays v0.6.1
INFO: Removing URIParser v0.2.0

>>> End of log
