>>> 'Pkg.add("Tokenize")' log
INFO: Installing Tokenize v0.2.0
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of Tokenize
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("Tokenize")' log
Julia Version 0.5.2
Commit f4c6c9d (2017-05-06 16:34 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64
Memory: 2.93927001953125 GB (1212.03515625 MB free)
Uptime: 60636.0 sec
Load Avg:  1.00830078125  1.01708984375  1.03466796875
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    3799830 s       5750 s     412640 s    1195764 s        108 s
#2  3500 MHz    1185709 s       1720 s     177374 s    4555587 s          1 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.5
2 required packages:
 - JSON                          0.14.0
 - Tokenize                      0.2.0
1 additional packages:
 - Compat                        0.41.0
INFO: Testing Tokenize
Lexed 10 files in 0.0000 seconds with a total of 10 tokens with 0 errors
Test Summary: | Pass  Total
  lex yourself |    1      1
Test Summary: | Pass  Total
  tokens      |   18     18
Test Summary:    | Pass  Total
  tokenize unicode |   48     48
Test Summary:                  | Pass  Total
  tokenize complex piece of code |  132    132
Test Summary: | Pass  Total
  issue 5, '..' |    1      1
Test Summary: | Pass  Total
  issue 17, >> |    1      1
Test Summary:        | Pass  Total
  test added operators |   10     10
Test Summary: | Pass  Total
  infix       |    4      4
Test Summary:                  | Pass  Total
  tokenizing true/false literals |    4      4
Test Summary:                                                  | Pass  Total
  tokenizing juxtaposed numbers and dotted operators/identifiers |    8      8
Test Summary:               | Pass  Total
  lexing anon functions '->'  |    1      1
Test Summary: | Pass  Total
  comments    |    1      1
Test Summary: | Pass  Total
  primes      |   10     10
Test Summary: | Pass  Total
  keywords    |   36     36
Test Summary:   | Pass  Total
  issue in PR #45 |    1      1
Test Summary: | Pass  Total
  errors      |    5      5
Test Summary: | Pass  Total
  xor_eq      |    1      1
Test Summary: | Pass  Total
  lex binary  |    1      1
Test Summary: | Pass  Total
  show        |    1      1
Test Summary: | Pass  Total
  interpolation |    7      7
Test Summary: | Pass  Total
  inferred    |    1      1
Test Summary:                                     | Pass  Total
  modifying function names (!) followed by operator |    3      3
Test Summary: | Pass  Total
  lex integers |    7      7
Test Summary:             | Pass  Total
  floats with trailing `.`  |   16     16
Test Summary: | Pass  Total
  lex octal   |    1      1
Test Summary:                       | Pass  Total
  lex float/bin/hex/oct w underscores |    8      8
Test Summary:   | Pass  Total
  floating points |   14     14
Test Summary: | Pass  Total
  1e1         |    2      2
Test Summary: | Pass  Total
  jl06types   |    7      7
Test Summary: | Pass  Total
  CMDs        |    5      5
Test Summary: | Pass  Total
  where       |    1      1
Test Summary: | Pass  Total
  IO position |    1      1
Test Summary:              | Pass  Total
  complicated interpolations |    6      6
INFO: Tokenize tests passed

>>> End of log
