>>> 'Pkg.add("ScikitLearn")' log
INFO: Cloning cache of ScikitLearn from https://github.com/cstjean/ScikitLearn.jl.git
INFO: Cloning cache of ScikitLearnBase from https://github.com/cstjean/ScikitLearnBase.jl.git
INFO: Installing Conda v0.8.1
INFO: Installing Parameters v0.9.0
INFO: Installing PyCall v1.17.1
INFO: Installing ScikitLearn v0.4.0
INFO: Installing ScikitLearnBase v0.3.0
INFO: Installing VersionParsing v1.1.1
INFO: Building Conda
INFO: Building PyCall
Info: Using the Python distribution in the Conda package by default.
To use a different Python version, set ENV["PYTHON"]="pythoncommand" and re-run Pkg.build("PyCall").
Solving environment: ...working... done

# All requested packages already installed.

Info: PyCall is using /home/vagrant/.julia/v0.6/Conda/deps/usr/bin/python (Python 2.7.15) at /home/vagrant/.julia/v0.6/Conda/deps/usr/bin/python, libpython = /home/vagrant/.julia/v0.6/Conda/deps/usr/lib/libpython2.7
Info: /home/vagrant/.julia/v0.6/PyCall/deps/deps.jl has not changed
Info: /home/vagrant/.julia/v0.6/PyCall/deps/PYTHON has not changed
INFO: Building CodecZlib
INFO: Package database updated

>>> 'Pkg.test("ScikitLearn")' log
Julia Version 0.6.3
Commit d55cadc350 (2018-05-28 20:20 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-143-generic #192-Ubuntu SMP Tue Feb 27 10:45:36 UTC 2018 x86_64 x86_64
Memory: 2.939197540283203 GB (1110.65625 MB free)
Uptime: 43759.0 sec
Load Avg:  0.9970703125  0.984375  1.03955078125
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3499 MHz    2662298 s        127 s     211467 s     850777 s         10 s
#2  3499 MHz     578533 s       5011 s      73956 s    3635577 s          0 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.9.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
6 required packages:
 - Cairo                         0.5.2
 - Colors                        0.8.2
 - Distributions                 0.15.0
 - JSON                          0.17.2
 - POMDPModels                   0.2.2
 - ScikitLearn                   0.4.0
65 additional packages:
 - AbstractTrees                 0.1.0
 - AssetRegistry                 0.0.1
 - AutoHashEquals                0.2.0
 - BinDeps                       0.8.8
 - BinaryProvider                0.3.2
 - Blink                         0.6.2
 - CPUTime                       0.0.5
 - Calculus                      0.4.0
 - CategoricalArrays             0.3.10
 - CodecZlib                     0.4.3
 - ColorTypes                    0.6.7
 - Compat                        0.69.0
 - Conda                         0.8.1
 - D3Trees                       0.2.0
 - DataFrames                    0.11.6
 - DataStreams                   0.3.6
 - DataStructures                0.8.3
 - DiscreteValueIteration        0.0.0-             master (unregistered)
 - FixedPointNumbers             0.4.6
 - Graphics                      0.3.0
 - Hiccup                        0.1.1
 - HttpCommon                    0.4.0
 - HttpParser                    0.3.1
 - HttpServer                    0.3.1
 - Iterators                     0.3.1
 - LaTeXStrings                  1.0.0
 - Lazy                          0.12.1
 - LightXML                      0.6.0
 - MCTS                          0.0.0-             master (unregistered)
 - MacroTools                    0.4.1
 - MbedTLS                       0.5.11
 - Missings                      0.2.9
 - Mustache                      0.3.2
 - Mux                           0.3.0
 - NaNMath                       0.3.1
 - NamedTuples                   4.0.2
 - Nullables                     0.0.5
 - PDMats                        0.8.0
 - POMDPToolbox                  0.2.7
 - POMDPXFiles                   0.0.0-             master (unregistered)
 - POMDPs                        0.6.7
 - Parameters                    0.9.0
 - Pidfile                       1.0.0
 - ProgressMeter                 0.5.5
 - PyCall                        1.17.1
 - QMDP                          0.0.0-             master (unregistered)
 - QuadGK                        0.2.1
 - Reexport                      0.1.0
 - Requires                      0.4.4
 - Rmath                         0.3.3
 - SARSOP                        0.0.0-             master (unregistered)
 - SHA                           0.5.7
 - ScikitLearnBase               0.3.0
 - SortingAlgorithms             0.2.1
 - SpecialFunctions              0.5.0
 - StaticArrays                  0.7.1
 - StatsBase                     0.23.0
 - StatsFuns                     0.6.0
 - TabularTDLearning             0.0.0-             master (unregistered)
 - TikzPictures                  1.2.0
 - TranscodingStreams            0.5.2
 - URIParser                     0.3.1
 - VersionParsing                1.1.1
 - WeakRefStrings                0.4.7
 - WebSockets                    0.5.0
INFO: Computing test dependencies for ScikitLearn...
INFO: Cloning cache of DecisionTree from https://github.com/bensadeghi/DecisionTree.jl.git
INFO: Cloning cache of GaussianMixtures from https://github.com/davidavdav/GaussianMixtures.jl.git
INFO: Cloning cache of GaussianProcesses from https://github.com/STOR-i/GaussianProcesses.jl.git
INFO: Installing Blosc v0.5.0
INFO: Installing CMakeWrapper v0.1.0
INFO: Installing CSV v0.2.5
INFO: Installing Clustering v0.9.1
INFO: Installing CommonSubexpressions v0.1.0
INFO: Installing DecisionTree v0.6.5
INFO: Installing DiffEqDiffTools v0.4.1
INFO: Installing DiffResults v0.0.3
INFO: Installing DiffRules v0.0.5
INFO: Installing Distances v0.6.0
INFO: Installing FastGaussQuadrature v0.3.0
INFO: Installing FileIO v0.9.1
INFO: Installing ForwardDiff v0.7.5
INFO: Installing GaussianMixtures v0.2.0
INFO: Installing GaussianProcesses v0.6.0
INFO: Installing HDF5 v0.9.2
INFO: Installing InternedStrings v0.6.2
INFO: Installing JLD v0.8.3
INFO: Installing LegacyStrings v0.3.0
INFO: Installing LineSearches v6.0.2
INFO: Installing Logging v0.3.1
INFO: Installing Mocking v0.5.3
INFO: Installing NBInclude v1.2.0
INFO: Installing NLSolversBase v6.1.1
INFO: Installing NearestNeighbors v0.3.0
INFO: Installing Optim v0.15.1
INFO: Installing PositiveFactorizations v0.1.0
INFO: Installing PyPlot v2.5.0
INFO: Installing RData v0.4.0
INFO: Installing RDatasets v0.4.0
INFO: Installing RecipesBase v0.3.1
INFO: Installing TimeZones v0.7.2
INFO: Building CMakeWrapper
INFO: Building Blosc
INFO: Building CodecZlib
INFO: Building SpecialFunctions
INFO: Building Rmath
INFO: Building HDF5
INFO: Building Conda
INFO: Building PyCall
Info: Using the Python distribution in the Conda package by default.
To use a different Python version, set ENV["PYTHON"]="pythoncommand" and re-run Pkg.build("PyCall").
Solving environment: ...working... done

# All requested packages already installed.

Info: PyCall is using /home/vagrant/.julia/v0.6/Conda/deps/usr/bin/python (Python 2.7.15) at /home/vagrant/.julia/v0.6/Conda/deps/usr/bin/python, libpython = /home/vagrant/.julia/v0.6/Conda/deps/usr/lib/libpython2.7
Info: /home/vagrant/.julia/v0.6/PyCall/deps/deps.jl has not changed
Info: /home/vagrant/.julia/v0.6/PyCall/deps/PYTHON has not changed
INFO: Building TimeZones
Info: Extracting tzdata archive
africa
antarctica
asia
australasia
europe
northamerica
southamerica
Info: Converting tz source files into TimeZone data
Info: Successfully built TimeZones
INFO: Testing ScikitLearn
Info: Installing sklearn via the Conda scikit-learn package...
Solving environment: ...working... done
scikit-learn-0.19.1  | 12.6 MB |            |   0% scikit-learn-0.19.1  | 12.6 MB |            |   0% scikit-learn-0.19.1  | 12.6 MB | 2          |   3% scikit-learn-0.19.1  | 12.6 MB | #          |  11% scikit-learn-0.19.1  | 12.6 MB | #8         |  19% scikit-learn-0.19.1  | 12.6 MB | ##7        |  27% scikit-learn-0.19.1  | 12.6 MB | ###5       |  35% scikit-learn-0.19.1  | 12.6 MB | ####3      |  43% scikit-learn-0.19.1  | 12.6 MB | #####1     |  52% scikit-learn-0.19.1  | 12.6 MB | #####9     |  60% scikit-learn-0.19.1  | 12.6 MB | ######8    |  68% scikit-learn-0.19.1  | 12.6 MB | #######5   |  76% scikit-learn-0.19.1  | 12.6 MB | ########2  |  82% scikit-learn-0.19.1  | 12.6 MB | ########6  |  87% scikit-learn-0.19.1  | 12.6 MB | #########  |  90% scikit-learn-0.19.1  | 12.6 MB | #########3 |  93% scikit-learn-0.19.1  | 12.6 MB | #########6 |  96% scikit-learn-0.19.1  | 12.6 MB | #########8 |  98% scikit-learn-0.19.1  | 12.6 MB | ########## | 100% 

## Package Plan ##

  environment location: /home/vagrant/.julia/v0.6/Conda/deps/usr

  added / updated specs: 
    - scikit-learn


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    scikit-learn-0.19.1        |py27_blas_openblas_201        12.6 MB  conda-forge

The following NEW packages will be INSTALLED:

    scikit-learn: 0.19.1-py27_blas_openblas_201 conda-forge [blas_openblas]


Downloading and Extracting Packages
Preparing transaction: ...working... done
Verifying transaction: ...working... done
Executing transaction: ...working... done
WARNING: redefining constant SVC
WARNING: redefining constant f_classif
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: Method definition unix2zdt(Real) in module TimeZones at /home/vagrant/.julia/v0.6/TimeZones/src/conversions.jl:122 overwritten in module RData at /home/vagrant/.julia/v0.6/RData/src/convert.jl:201.
WARNING: Method definition unix2zdt(Real) in module TimeZones at /home/vagrant/.julia/v0.6/TimeZones/src/conversions.jl:122 overwritten in module RData at /home/vagrant/.julia/v0.6/RData/src/convert.jl:201.
WARNING: redefining constant LogisticRegression
WARNING: redefining constant StandardScaler
Testing ../examples/Classifier_Comparison.ipynb
WARNING: No working GUI backend found for matplotlib
Testing ../examples/Classifier_Comparison_Julia.ipynb
WARNING: replacing module Testing
Testing ../examples/Clustering_Comparison.ipynb
WARNING: replacing module Testing
/home/vagrant/.julia/v0.6/Conda/deps/usr/lib/python2.7/site-packages/sklearn/manifold/spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.
  warnings.warn("Graph is not fully connected, spectral embedding"
/home/vagrant/.julia/v0.6/Conda/deps/usr/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:193: UserWarning: the number of connected components of the connectivity matrix is 2 > 1. Completing it to avoid stopping the tree early.
  affinity='euclidean')
/home/vagrant/.julia/v0.6/Conda/deps/usr/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:426: UserWarning: the number of connected components of the connectivity matrix is 2 > 1. Completing it to avoid stopping the tree early.
  affinity=affinity)
/home/vagrant/.julia/v0.6/Conda/deps/usr/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:193: UserWarning: the number of connected components of the connectivity matrix is 3 > 1. Completing it to avoid stopping the tree early.
  affinity='euclidean')
/home/vagrant/.julia/v0.6/Conda/deps/usr/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:426: UserWarning: the number of connected components of the connectivity matrix is 3 > 1. Completing it to avoid stopping the tree early.
  affinity=affinity)
Testing ../examples/Cross_Validated_Predictions.ipynb
WARNING: replacing module Testing
Testing ../examples/Decision_Tree_Regression.ipynb
WARNING: replacing module Testing
Testing ../examples/Decision_Tree_Regression_Julia.ipynb
WARNING: replacing module Testing
Testing ../examples/Density_Estimation.ipynb
WARNING: replacing module Testing
Testing ../examples/Feature_Stacker.ipynb
WARNING: replacing module Testing
Fitting 3 folds for each of 18 candidates, totalling 54 fits
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=1
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=1, score=0.96078  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=1
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=1, score=0.90196  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=1
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=1, score=0.97917  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=1
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=1, score=0.94118  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=1
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=1, score=0.92157  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=1
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=1, score=0.97917  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=1
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=1, score=0.96078  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=1
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=1, score=0.92157  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=1
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=1, score=0.97917  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=1
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=1, score=0.96078  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=1
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=1, score=0.92157  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=1
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=1, score=0.97917  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=1
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=1, score=0.96078  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=1
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=1, score=0.92157  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=1
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=1, score=1.00000  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=1
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=1, score=0.98039  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=1
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=1, score=0.90196  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=1
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=1, score=1.00000  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=2
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=2, score=0.96078  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=2
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=2, score=0.90196  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=2
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=2, score=0.97917  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=2
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=2, score=0.98039  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=2
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=2, score=0.94118  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=2
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=2, score=0.97917  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=2
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=2, score=0.98039  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=2
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=2, score=0.94118  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=2
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=2, score=0.97917  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=2
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=2, score=0.98039  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=2
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=2, score=0.94118  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=2
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=2, score=0.97917  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=2
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=2, score=1.00000  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=2
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=2, score=0.96078  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=2
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=2, score=0.97917  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=2
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=2, score=0.98039  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=2
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=2, score=0.92157  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=2
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=2, score=1.00000  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=3
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=3, score=0.98039  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=3
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=3, score=0.94118  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=3
[CV] svm__C=0.1, features__univ_select__k=1, features__pca__n_components=3, score=0.97917  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=3
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=3, score=1.00000  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=3
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=3, score=0.94118  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=3
[CV] svm__C=1.0, features__univ_select__k=1, features__pca__n_components=3, score=0.97917  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=3
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=3, score=1.00000  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=3
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=3, score=0.92157  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=3
[CV] svm__C=10.0, features__univ_select__k=1, features__pca__n_components=3, score=1.00000  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=3
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=3, score=0.98039  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=3
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=3, score=0.94118  -  0.0s
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=3
[CV] svm__C=0.1, features__univ_select__k=2, features__pca__n_components=3, score=0.97917  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=3
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=3, score=1.00000  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=3
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=3, score=0.96078  -  0.0s
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=3
[CV] svm__C=1.0, features__univ_select__k=2, features__pca__n_components=3, score=0.97917  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=3
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=3, score=1.00000  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=3
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=3, score=0.92157  -  0.0s
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=3
[CV] svm__C=10.0, features__univ_select__k=2, features__pca__n_components=3, score=1.00000  -  0.0s
ScikitLearn.Skcore.Pipeline(Tuple{Any,Any}[("features", ScikitLearn.Skcore.FeatureUnion(Tuple{Any,Any}[("pca", PyObject PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,
  svd_solver='auto', tol=0.0, whiten=False)), ("univ_select", PyObject SelectKBest(k=2, score_func=<function f_classif at 0x7f21b050d758>))], 1, nothing)), ("svm", PyObject SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False))], Any[ScikitLearn.Skcore.FeatureUnion(Tuple{Any,Any}[("pca", PyObject PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,
  svd_solver='auto', tol=0.0, whiten=False)), ("univ_select", PyObject SelectKBest(k=2, score_func=<function f_classif at 0x7f21b050d758>))], 1, nothing), PyObject SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)])Testing ../examples/Gaussian_Processes_Julia.ipynb
WARNING: replacing module Testing
(get_params(best_gp))[:logNoise] = 2.6
(get_params(best_gp))[:k_lσ] = 4.8
Testing ../examples/Outlier_Detection.ipynb
WARNING: replacing module Testing
Testing ../examples/Pipeline_PCA_Logistic.ipynb
WARNING: replacing module Testing
Testing ../examples/Plot_Kmeans_Digits.ipynb
WARNING: replacing module Testing
n_digits: 10, 	 n_samples 1797, 	 n_features 64
____________________________________________________________________________
init    time  inertia    homo   compl  v-meas     ARI AMI  silhouette
k-means++   0.19s    69536   0.593   0.639   0.615   0.461   0.588    0.125
   random   0.23s    69541   0.599   0.644   0.621   0.467   0.595    0.142
PCA-based   0.04s    70804   0.671   0.698   0.684   0.561   0.668    0.120
____________________________________________________________________________Testing ../examples/Randomized_Search.ipynb
WARNING: replacing module Testing
RandomizedSearchCV took 6.85 seconds for 20 candidates, parameter settings.
Model with rank:1
Mean validation score: 0.927 (std: 0.012)
Parameters: Dict{Symbol,Any}(Pair{Symbol,Any}(:bootstrap, false),Pair{Symbol,Any}(:max_features, 6),Pair{Symbol,Any}(:min_samples_split, 7),Pair{Symbol,Any}(:min_samples_leaf, 4),Pair{Symbol,Any}(:criterion, "gini"),Pair{Symbol,Any}(:max_depth, nothing))

Model with rank:2
Mean validation score: 0.922 (std: 0.007)
Parameters: Dict{Symbol,Any}(Pair{Symbol,Any}(:bootstrap, false),Pair{Symbol,Any}(:max_features, 4),Pair{Symbol,Any}(:min_samples_split, 8),Pair{Symbol,Any}(:min_samples_leaf, 6),Pair{Symbol,Any}(:criterion, "entropy"),Pair{Symbol,Any}(:max_depth, nothing))

Model with rank:3
Mean validation score: 0.916 (std: 0.023)
Parameters: Dict{Symbol,Any}(Pair{Symbol,Any}(:bootstrap, false),Pair{Symbol,Any}(:max_features, 10),Pair{Symbol,Any}(:min_samples_split, 8),Pair{Symbol,Any}(:min_samples_leaf, 8),Pair{Symbol,Any}(:criterion, "gini"),Pair{Symbol,Any}(:max_depth, nothing))

GridSearchCV took 64.49 seconds for 216 candidate parameter settings.
Model with rank:1
Mean validation score: 0.933 (std: 0.009)
Parameters: Dict{Symbol,Any}(Pair{Symbol,Any}(:bootstrap, false),Pair{Symbol,Any}(:max_features, 10),Pair{Symbol,Any}(:min_samples_split, 3),Pair{Symbol,Any}(:min_samples_leaf, 1),Pair{Symbol,Any}(:criterion, "entropy"),Pair{Symbol,Any}(:max_depth, nothing))

Model with rank:2
Mean validation score: 0.932 (std: 0.014)
Parameters: Dict{Symbol,Any}(Pair{Symbol,Any}(:bootstrap, false),Pair{Symbol,Any}(:max_features, 10),Pair{Symbol,Any}(:min_samples_split, 2),Pair{Symbol,Any}(:min_samples_leaf, 3),Pair{Symbol,Any}(:criterion, "entropy"),Pair{Symbol,Any}(:max_depth, nothing))

Model with rank:3
Mean validation score: 0.932 (std: 0.014)
Parameters: Dict{Symbol,Any}(Pair{Symbol,Any}(:bootstrap, false),Pair{Symbol,Any}(:max_features, 10),Pair{Symbol,Any}(:min_samples_split, 3),Pair{Symbol,Any}(:min_samples_leaf, 3),Pair{Symbol,Any}(:criterion, "entropy"),Pair{Symbol,Any}(:max_depth, nothing))

(predict(random_search, X))[1:10] = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
(predict_proba(random_search, X))[1:10] = [1.0, 0.0, 0.02, 0.0, 0.144167, 0.0, 0.0125, 0.0, 0.0, 0.0]
score(random_search, X, y) = 0.9994435169727324
Testing ../examples/RBM.ipynb
WARNING: replacing module Testing
Logistic regression using RBM features:
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       174
          1       0.94      0.95      0.94       184
          2       0.96      0.98      0.97       166
          3       0.96      0.88      0.92       194
          4       0.96      0.95      0.96       186
          5       0.90      0.92      0.91       181
          6       0.99      0.97      0.98       207
          7       0.94      0.98      0.96       154
          8       0.89      0.90      0.89       182
          9       0.90      0.92      0.91       169

avg / total       0.94      0.94      0.94      1797

Logistic regression using raw pixel features:
             precision    recall  f1-score   support

          0       0.86      0.94      0.90       174
          1       0.55      0.53      0.54       184
          2       0.79      0.86      0.82       166
          3       0.78      0.73      0.75       194
          4       0.86      0.83      0.85       186
          5       0.79      0.77      0.78       181
          6       0.89      0.89      0.89       207
          7       0.85      0.93      0.89       154
          8       0.65      0.60      0.63       182
          9       0.71      0.72      0.72       169

avg / total       0.77      0.78      0.78      1797

Testing ../examples/Text_Feature_Extraction.ipynb
WARNING: replacing module Testing
Loading 20 newsgroups dataset for categories:String["alt.atheism", "talk.religion.misc"]Downloading 20news dataset. This may take a few minutes.
Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)
857 documents
2 categories

Performing grid search...
pipeline:String["vect", "tfidf", "clf"]
parameters:
Dict{String,Any}(Pair{String,Any}("vect__max_df", (0.5, 0.75, 1.0)),Pair{String,Any}("clf__penalty", ("l2", "elasticnet")),Pair{String,Any}("clf__alpha", (1.0e-5, 1.0e-6)),Pair{String,Any}("vect__ngram_range", ((1, 1), (1, 2))))
Fitting 3 folds for each of 24 candidates, totalling 72 fits
/home/vagrant/.julia/v0.6/Conda/deps/usr/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  "and default tol will be 1e-3." % type(self), FutureWarning)
done in 11.689s
Best score: 0.840
Best parameters set:
	vect__max_df: 0.5
	clf__penalty: elasticnet
	clf__alpha: 1.0e-5
	vect__ngram_range: (1, 2)
Testing ../examples/Two_Class_Adaboost.ipynb
WARNING: replacing module Testing
/home/vagrant/.julia/v0.6/Conda/deps/usr/lib/python2.7/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.
  warnings.warn(message, mplDeprecation, stacklevel=1)
Testing ../examples/Underfitting_vs_Overfitting.ipynb
WARNING: replacing module Testing
Test Summary:    | Pass  Total
ScikitLearnTests |  105    105
[BernoulliRBM] Iteration 1, pseudo-likelihood = -25.54, time = 0.18s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -23.94, time = 0.29s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -22.98, time = 0.26s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -21.98, time = 0.25s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -21.48, time = 0.25s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -21.06, time = 0.25s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -20.93, time = 0.25s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -20.49, time = 0.25s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -20.27, time = 0.25s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -20.18, time = 0.25s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -20.02, time = 0.25s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -19.73, time = 0.24s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -19.86, time = 0.25s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -19.64, time = 0.25s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -19.61, time = 0.25s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -19.40, time = 0.27s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -19.19, time = 0.28s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -19.16, time = 0.28s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -19.13, time = 0.28s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -19.08, time = 0.29s
INFO: ScikitLearn tests passed
INFO: Removing Blosc v0.5.0
INFO: Removing CMakeWrapper v0.1.0
INFO: Removing CSV v0.2.5
INFO: Removing Clustering v0.9.1
INFO: Removing CommonSubexpressions v0.1.0
INFO: Removing DecisionTree v0.6.5
INFO: Removing DiffEqDiffTools v0.4.1
INFO: Removing DiffResults v0.0.3
INFO: Removing DiffRules v0.0.5
INFO: Removing Distances v0.6.0
INFO: Removing FastGaussQuadrature v0.3.0
INFO: Removing FileIO v0.9.1
INFO: Removing ForwardDiff v0.7.5
INFO: Removing GaussianMixtures v0.2.0
INFO: Removing GaussianProcesses v0.6.0
INFO: Removing HDF5 v0.9.2
INFO: Removing InternedStrings v0.6.2
INFO: Removing JLD v0.8.3
INFO: Removing LegacyStrings v0.3.0
INFO: Removing LineSearches v6.0.2
INFO: Removing Logging v0.3.1
INFO: Removing Mocking v0.5.3
INFO: Removing NBInclude v1.2.0
INFO: Removing NLSolversBase v6.1.1
INFO: Removing NearestNeighbors v0.3.0
INFO: Removing Optim v0.15.1
INFO: Removing PositiveFactorizations v0.1.0
INFO: Removing PyPlot v2.5.0
INFO: Removing RData v0.4.0
INFO: Removing RDatasets v0.4.0
INFO: Removing RecipesBase v0.3.1
INFO: Removing TimeZones v0.7.2

>>> End of log
