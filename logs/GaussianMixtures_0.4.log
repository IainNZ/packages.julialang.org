>>> 'Pkg.add("GaussianMixtures")' log
INFO: Installing BinDeps v0.4.7
INFO: Installing Blosc v0.2.1
INFO: Installing Calculus v0.2.2
INFO: Installing Clustering v0.7.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.11.1
INFO: Installing FileIO v0.2.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.7.3
INFO: Installing JLD v0.6.11
INFO: Installing LegacyStrings v0.2.2
INFO: Installing NearestNeighbors v0.0.5
INFO: Installing PDMats v0.6.0
INFO: Installing Rmath v0.1.7
INFO: Installing SHA v0.3.3
INFO: Installing ScikitLearnBase v0.2.2
INFO: Installing StatsBase v0.12.0
INFO: Installing StatsFuns v0.4.0
INFO: Installing URIParser v0.1.8
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.4.7
Commit ae26b25 (2016-09-18 16:17 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-128-generic #177-Ubuntu SMP Tue Aug 8 11:40:23 UTC 2017 x86_64 x86_64
Memory: 2.9392738342285156 GB (714.86328125 MB free)
Uptime: 34308.0 sec
Load Avg:  0.98974609375  0.96875  1.01318359375
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3499 MHz    1600530 s       6180 s     123052 s    1392085 s         48 s
#2  3499 MHz    1172917 s         43 s     110836 s    2013144 s          0 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.4
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.9.1
19 additional packages:
 - BinDeps                       0.4.7
 - Blosc                         0.2.1
 - Calculus                      0.2.2
 - Clustering                    0.7.0
 - Compat                        0.26.0
 - Distances                     0.3.2
 - Distributions                 0.11.1
 - FileIO                        0.2.2
 - HDF5                          0.7.3
 - JLD                           0.6.11
 - LegacyStrings                 0.2.2
 - NearestNeighbors              0.0.5
 - PDMats                        0.6.0
 - Rmath                         0.1.7
 - SHA                           0.3.3
 - ScikitLearnBase               0.2.2
 - StatsBase                     0.12.0
 - StatsFuns                     0.4.0
 - URIParser                     0.1.8
INFO: Testing GaussianMixtures
INFO: Testing Data
(100000,-2.5652928969911956e6,[91160.3843258903,8839.615674109695],
[-5011.8818502240865 8023.023034735403 12779.249152099397
 5487.42910096981 -8521.192693007979 -12390.982721654607],

[
[88521.57297164667 3787.347041712796 5708.035584021425
 3787.347041712796 84987.53494384667 -9425.591225288083
 5708.035584021425 -9425.591225288083 77980.90939504918],

[11854.566176895674 -3836.2538203420245 -5589.009809784393
 -3836.2538203420245 14995.056377759436 8926.563092211509
 -5589.009809784393 8926.563092211509 21800.41402619317]])
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.299519e+03
      1       9.843596e+02      -3.151592e+02 |        7
      2       8.954902e+02      -8.886945e+01 |        2
      3       8.936603e+02      -1.829846e+00 |        0
      4       8.936603e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 893.6603456802013)
INFO: K-means with 272 data points using 4 iterations
11.3 data points per parameter
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
INFO: EM with 272 data points 0 iterations avll -2.077847
5.8 data points per parameter
INFO: iteration 1, lowerbound -3.904394
INFO: iteration 2, lowerbound -3.779810
INFO: iteration 3, lowerbound -3.622593
INFO: iteration 4, lowerbound -3.421332
INFO: iteration 5, lowerbound -3.211551
INFO: iteration 6, lowerbound -3.033833
INFO: iteration 7, lowerbound -2.914527
INFO: dropping number of Gaussions to 7
INFO: iteration 8, lowerbound -2.853703
INFO: dropping number of Gaussions to 5
INFO: iteration 9, lowerbound -2.819505
INFO: dropping number of Gaussions to 4
INFO: iteration 10, lowerbound -2.804655
INFO: dropping number of Gaussions to 3
INFO: iteration 11, lowerbound -2.794565
INFO: iteration 12, lowerbound -2.787925
INFO: iteration 13, lowerbound -2.783636
INFO: iteration 14, lowerbound -2.777177
INFO: iteration 15, lowerbound -2.767173
INFO: iteration 16, lowerbound -2.751552
INFO: iteration 17, lowerbound -2.727433
INFO: iteration 18, lowerbound -2.691446
INFO: iteration 19, lowerbound -2.641123
INFO: iteration 20, lowerbound -2.577714
INFO: iteration 21, lowerbound -2.508605
INFO: iteration 22, lowerbound -2.444798
INFO: iteration 23, lowerbound -2.393465
INFO: iteration 24, lowerbound -2.354827
INFO: iteration 25, lowerbound -2.326857
INFO: iteration 26, lowerbound -2.310539
INFO: iteration 27, lowerbound -2.308062
INFO: dropping number of Gaussions to 2
INFO: iteration 28, lowerbound -2.302916
INFO: iteration 29, lowerbound -2.299259
INFO: iteration 30, lowerbound -2.299256
INFO: iteration 31, lowerbound -2.299254
INFO: iteration 32, lowerbound -2.299254
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
[Sun 13 Aug 2017 01:34:25 PM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Sun 13 Aug 2017 01:34:25 PM UTC: K-means with 272 data points using 4 iterations
11.3 data points per parameter
,Sun 13 Aug 2017 01:34:27 PM UTC: EM with 272 data points 0 iterations avll -2.077847
5.8 data points per parameter
,Sun 13 Aug 2017 01:34:28 PM UTC: GMM converted to Variational GMM
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 1, lowerbound -3.904394
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 2, lowerbound -3.779810
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 3, lowerbound -3.622593
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 4, lowerbound -3.421332
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 5, lowerbound -3.211551
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 6, lowerbound -3.033833
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 7, lowerbound -2.914527
,Sun 13 Aug 2017 01:34:30 PM UTC: dropping number of Gaussions to 7
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 8, lowerbound -2.853703
,Sun 13 Aug 2017 01:34:30 PM UTC: dropping number of Gaussions to 5
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 9, lowerbound -2.819505
,Sun 13 Aug 2017 01:34:30 PM UTC: dropping number of Gaussions to 4
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 10, lowerbound -2.804655
,Sun 13 Aug 2017 01:34:30 PM UTC: dropping number of Gaussions to 3
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 11, lowerbound -2.794565
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 12, lowerbound -2.787925
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 13, lowerbound -2.783636
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 14, lowerbound -2.777177
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 15, lowerbound -2.767173
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 16, lowerbound -2.751552
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 17, lowerbound -2.727433
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 18, lowerbound -2.691446
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 19, lowerbound -2.641123
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 20, lowerbound -2.577714
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 21, lowerbound -2.508605
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 22, lowerbound -2.444798
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 23, lowerbound -2.393465
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 24, lowerbound -2.354827
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 25, lowerbound -2.326857
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 26, lowerbound -2.310539
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 27, lowerbound -2.308062
,Sun 13 Aug 2017 01:34:30 PM UTC: dropping number of Gaussions to 2
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 28, lowerbound -2.302916
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 29, lowerbound -2.299259
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 30, lowerbound -2.299256
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 31, lowerbound -2.299254
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 32, lowerbound -2.299254
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 33, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 34, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 35, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 36, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 37, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 38, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 39, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 40, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 41, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 42, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 43, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 44, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 45, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 46, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 47, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 48, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 49, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: iteration 50, lowerbound -2.299253
,Sun 13 Aug 2017 01:34:30 PM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.04509222633396,95.9549077736661]
Î² = [178.04509222633396,95.9549077736661]
m = [4.250300733267315 79.28686694432363
 2.00022925777268 53.85198717244728]
Î½ = [180.04509222633396,97.9549077736661]
W = [
[0.18404155547449408 -0.007644049042361666
 0.0 0.008581705166285312],

[0.3758763611993084 -0.008953123827399408
 0.0 0.012748664777422957]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999994
avll from stats: -1.0128705182612563
avll from llpg:  -1.012870518261257
avll direct:     -1.012870518261257
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9841194208833113
avll from llpg:  -0.9841194208833117
avll direct:     -0.9841194208833117
sum posterior: 100000.0
32x26 Array{Float64,2}:
  0.00752326   0.0404795    â€¦   0.0816182  -0.0595921    0.133555 
  0.0938058   -0.000101436      0.0809882  -0.00763317   0.0601707
  0.0671555   -0.0960805        0.0103313  -0.105921    -0.106112 
  0.189358     0.0277266       -0.0319862  -0.0707576   -0.166031 
  0.0165218    0.149688         0.0423691  -0.131204     0.0673397
 -0.0688038   -0.182042     â€¦  -0.0320388  -0.0464466    0.0783956
  0.030121     0.0309053       -0.0644328  -0.0065256   -0.198526 
  0.0750571   -0.00851893      -0.0316349   0.0616158   -0.0113237
  0.147421     0.00364266      -0.016847   -0.116535     0.0489808
  0.00246094   0.0251587       -0.0767083   0.281836    -0.0623437
  â‹®                         â‹±                            â‹®        
  0.0276602    0.0758443       -0.0570495  -0.0504425   -0.146366 
 -0.00459614  -0.0713041       -0.0773287   0.206821    -0.0770997
 -0.138614     0.060176     â€¦   0.104885   -0.16211     -0.0117828
 -0.0166822    0.235566         0.0679988  -0.0259042    0.0248329
  0.0110377    0.0663472        0.0238302   0.0169058    0.0919543
 -0.0605445    0.0957255       -0.0421974   0.0243697    0.0820437
 -0.0862878    0.0556003        0.0670856  -0.23508     -0.142054 
 -0.109066     0.195322     â€¦  -0.0149213   0.0303696    0.0921001
 -0.0767957    0.339219        -0.129073   -0.141976    -0.0204041kind diag, method split
0: avll = -1.403580542838749
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.403663
INFO: iteration 2, average log likelihood -1.403592
INFO: iteration 3, average log likelihood -1.403126
INFO: iteration 4, average log likelihood -1.397019
INFO: iteration 5, average log likelihood -1.378965
INFO: iteration 6, average log likelihood -1.371446
INFO: iteration 7, average log likelihood -1.370355
INFO: iteration 8, average log likelihood -1.369921
INFO: iteration 9, average log likelihood -1.369633
INFO: iteration 10, average log likelihood -1.369410
INFO: iteration 11, average log likelihood -1.369221
INFO: iteration 12, average log likelihood -1.369039
INFO: iteration 13, average log likelihood -1.368847
INFO: iteration 14, average log likelihood -1.368648
INFO: iteration 15, average log likelihood -1.368446
INFO: iteration 16, average log likelihood -1.368239
INFO: iteration 17, average log likelihood -1.368033
INFO: iteration 18, average log likelihood -1.367829
INFO: iteration 19, average log likelihood -1.367631
INFO: iteration 20, average log likelihood -1.367442
INFO: iteration 21, average log likelihood -1.367267
INFO: iteration 22, average log likelihood -1.367107
INFO: iteration 23, average log likelihood -1.366966
INFO: iteration 24, average log likelihood -1.366840
INFO: iteration 25, average log likelihood -1.366724
INFO: iteration 26, average log likelihood -1.366612
INFO: iteration 27, average log likelihood -1.366495
INFO: iteration 28, average log likelihood -1.366362
INFO: iteration 29, average log likelihood -1.366212
INFO: iteration 30, average log likelihood -1.366065
INFO: iteration 31, average log likelihood -1.365942
INFO: iteration 32, average log likelihood -1.365846
INFO: iteration 33, average log likelihood -1.365778
INFO: iteration 34, average log likelihood -1.365732
INFO: iteration 35, average log likelihood -1.365701
INFO: iteration 36, average log likelihood -1.365680
INFO: iteration 37, average log likelihood -1.365666
INFO: iteration 38, average log likelihood -1.365656
INFO: iteration 39, average log likelihood -1.365648
INFO: iteration 40, average log likelihood -1.365643
INFO: iteration 41, average log likelihood -1.365639
INFO: iteration 42, average log likelihood -1.365636
INFO: iteration 43, average log likelihood -1.365633
INFO: iteration 44, average log likelihood -1.365632
INFO: iteration 45, average log likelihood -1.365630
INFO: iteration 46, average log likelihood -1.365629
INFO: iteration 47, average log likelihood -1.365629
INFO: iteration 48, average log likelihood -1.365628
INFO: iteration 49, average log likelihood -1.365628
INFO: iteration 50, average log likelihood -1.365627
INFO: EM with 100000 data points 50 iterations avll -1.365627
952.4 data points per parameter
1: avll = [-1.4036628386158698,-1.403592221451071,-1.4031262199618262,-1.3970186481663727,-1.3789652623212632,-1.3714455241716421,-1.370355391513378,-1.369920979789013,-1.3696325502994877,-1.369409837740192,-1.3692210846355812,-1.3690389240642593,-1.3688468526483049,-1.3686480806805774,-1.3684458059726348,-1.3682390092539967,-1.3680328486409277,-1.3678293756495772,-1.3676308877974739,-1.3674420647537406,-1.3672668581207514,-1.3671074361591393,-1.3669658779531657,-1.3668395861951863,-1.3667235970213132,-1.366612079957325,-1.3664949978601821,-1.366362335703506,-1.3662115352766038,-1.366065129087612,-1.365941524492199,-1.3658462393687298,-1.3657781654585428,-1.3657321762952874,-1.3657014023384206,-1.3656804265094933,-1.3656658728452407,-1.3656555675657993,-1.3656481268150205,-1.3656426742633532,-1.3656386366579452,-1.365635622762576,-1.3656333576135176,-1.3656316447669796,-1.3656303423949119,-1.365629347213761,-1.3656285834049589,-1.3656279948865528,-1.3656275398759075,-1.3656271870333285]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.365732
INFO: iteration 2, average log likelihood -1.365644
INFO: iteration 3, average log likelihood -1.365317
INFO: iteration 4, average log likelihood -1.361766
INFO: iteration 5, average log likelihood -1.348416
INFO: iteration 6, average log likelihood -1.337382
INFO: iteration 7, average log likelihood -1.334152
INFO: iteration 8, average log likelihood -1.332910
INFO: iteration 9, average log likelihood -1.332126
INFO: iteration 10, average log likelihood -1.331505
INFO: iteration 11, average log likelihood -1.330892
INFO: iteration 12, average log likelihood -1.330208
INFO: iteration 13, average log likelihood -1.329361
INFO: iteration 14, average log likelihood -1.328344
INFO: iteration 15, average log likelihood -1.327313
INFO: iteration 16, average log likelihood -1.326515
INFO: iteration 17, average log likelihood -1.326024
INFO: iteration 18, average log likelihood -1.325725
INFO: iteration 19, average log likelihood -1.325511
INFO: iteration 20, average log likelihood -1.325324
INFO: iteration 21, average log likelihood -1.325131
INFO: iteration 22, average log likelihood -1.324901
INFO: iteration 23, average log likelihood -1.324566
INFO: iteration 24, average log likelihood -1.324097
INFO: iteration 25, average log likelihood -1.323507
INFO: iteration 26, average log likelihood -1.322746
INFO: iteration 27, average log likelihood -1.322020
INFO: iteration 28, average log likelihood -1.321526
INFO: iteration 29, average log likelihood -1.321165
INFO: iteration 30, average log likelihood -1.320780
INFO: iteration 31, average log likelihood -1.320312
INFO: iteration 32, average log likelihood -1.319921
INFO: iteration 33, average log likelihood -1.319699
INFO: iteration 34, average log likelihood -1.319581
INFO: iteration 35, average log likelihood -1.319513
INFO: iteration 36, average log likelihood -1.319471
INFO: iteration 37, average log likelihood -1.319444
INFO: iteration 38, average log likelihood -1.319423
INFO: iteration 39, average log likelihood -1.319408
INFO: iteration 40, average log likelihood -1.319396
INFO: iteration 41, average log likelihood -1.319386
INFO: iteration 42, average log likelihood -1.319378
INFO: iteration 43, average log likelihood -1.319372
INFO: iteration 44, average log likelihood -1.319366
INFO: iteration 45, average log likelihood -1.319361
INFO: iteration 46, average log likelihood -1.319357
INFO: iteration 47, average log likelihood -1.319353
INFO: iteration 48, average log likelihood -1.319350
INFO: iteration 49, average log likelihood -1.319347
INFO: iteration 50, average log likelihood -1.319345
INFO: EM with 100000 data points 50 iterations avll -1.319345
473.9 data points per parameter
2: avll = [-1.365731769566813,-1.3656443609436222,-1.3653168865582412,-1.3617663528599555,-1.3484160273674106,-1.3373824106691863,-1.334151550844788,-1.332909946587892,-1.3321258129237965,-1.3315052220641646,-1.330891871738254,-1.330208306852658,-1.3293606878988753,-1.3283436284244305,-1.327312946653507,-1.3265147912044817,-1.326023807464979,-1.325724623497115,-1.3255112905953723,-1.3253239824113472,-1.325131131825363,-1.3249006489779163,-1.3245655349082073,-1.3240969510077358,-1.3235073565054345,-1.3227457721898022,-1.322019895731249,-1.321525828475488,-1.3211654862436903,-1.3207803251627441,-1.3203120549883884,-1.3199212678153993,-1.3196994283324308,-1.3195806968323833,-1.3195128494121973,-1.3194713546582413,-1.3194436117633495,-1.3194234832627973,-1.319408082614667,-1.3193959550462064,-1.3193862248827402,-1.3193782763138815,-1.3193716632941197,-1.3193660695030396,-1.319361272192768,-1.3193571116575966,-1.3193534700530636,-1.3193502580831609,-1.3193474065280466,-1.3193448605840905]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.319519
INFO: iteration 2, average log likelihood -1.319338
INFO: iteration 3, average log likelihood -1.318399
INFO: iteration 4, average log likelihood -1.310299
INFO: iteration 5, average log likelihood -1.291662
INFO: iteration 6, average log likelihood -1.276249
INFO: iteration 7, average log likelihood -1.269557
INFO: iteration 8, average log likelihood -1.266169
INFO: iteration 9, average log likelihood -1.263711
INFO: iteration 10, average log likelihood -1.261609
INFO: iteration 11, average log likelihood -1.259747
INFO: iteration 12, average log likelihood -1.258246
INFO: iteration 13, average log likelihood -1.257211
INFO: iteration 14, average log likelihood -1.256567
INFO: iteration 15, average log likelihood -1.256170
INFO: iteration 16, average log likelihood -1.255920
INFO: iteration 17, average log likelihood -1.255761
INFO: iteration 18, average log likelihood -1.255658
INFO: iteration 19, average log likelihood -1.255591
INFO: iteration 20, average log likelihood -1.255544
INFO: iteration 21, average log likelihood -1.255509
INFO: iteration 22, average log likelihood -1.255479
INFO: iteration 23, average log likelihood -1.255450
INFO: iteration 24, average log likelihood -1.255420
INFO: iteration 25, average log likelihood -1.255386
INFO: iteration 26, average log likelihood -1.255348
INFO: iteration 27, average log likelihood -1.255303
INFO: iteration 28, average log likelihood -1.255248
INFO: iteration 29, average log likelihood -1.255179
INFO: iteration 30, average log likelihood -1.255094
INFO: iteration 31, average log likelihood -1.254991
INFO: iteration 32, average log likelihood -1.254870
INFO: iteration 33, average log likelihood -1.254735
INFO: iteration 34, average log likelihood -1.254590
INFO: iteration 35, average log likelihood -1.254437
INFO: iteration 36, average log likelihood -1.254277
INFO: iteration 37, average log likelihood -1.254113
INFO: iteration 38, average log likelihood -1.253955
INFO: iteration 39, average log likelihood -1.253819
INFO: iteration 40, average log likelihood -1.253720
INFO: iteration 41, average log likelihood -1.253658
INFO: iteration 42, average log likelihood -1.253623
INFO: iteration 43, average log likelihood -1.253603
INFO: iteration 44, average log likelihood -1.253592
INFO: iteration 45, average log likelihood -1.253585
INFO: iteration 46, average log likelihood -1.253581
INFO: iteration 47, average log likelihood -1.253578
INFO: iteration 48, average log likelihood -1.253575
INFO: iteration 49, average log likelihood -1.253574
INFO: iteration 50, average log likelihood -1.253573
INFO: EM with 100000 data points 50 iterations avll -1.253573
236.4 data points per parameter
3: avll = [-1.3195193528651854,-1.3193375128964284,-1.3183989373756342,-1.310298821437247,-1.2916615821426325,-1.2762494239897884,-1.2695574529820168,-1.266169334171564,-1.2637114764627966,-1.2616086628691388,-1.2597473867038838,-1.2582455435278395,-1.2572114757359063,-1.2565673207573151,-1.256170005149846,-1.2559201296511655,-1.2557606462976434,-1.255658083840284,-1.2555906219421824,-1.2555439010293339,-1.2555085532607522,-1.2554785082353694,-1.255449784193096,-1.255419660700038,-1.255386166823867,-1.255347746405806,-1.2553026356322714,-1.2552477323550353,-1.2551790259109803,-1.2550941864182732,-1.2549914576153836,-1.2548701746396036,-1.2547348232480928,-1.254589662417048,-1.254436818361665,-1.2542770961209724,-1.2541128383761795,-1.2539550477031962,-1.2538192328994093,-1.2537199421731284,-1.2536578541503334,-1.2536225609744822,-1.253603051970678,-1.253591847153715,-1.2535849702714004,-1.2535805080413127,-1.253577513075712,-1.2535754640935088,-1.253574047831625,-1.2535730643406775]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.253768
INFO: iteration 2, average log likelihood -1.253566
INFO: iteration 3, average log likelihood -1.252549
INFO: iteration 4, average log likelihood -1.238710
INFO: iteration 5, average log likelihood -1.193951
WARNING: Variances had to be floored 6
INFO: iteration 6, average log likelihood -1.163878
INFO: iteration 7, average log likelihood -1.169865
INFO: iteration 8, average log likelihood -1.158627
WARNING: Variances had to be floored 6
INFO: iteration 9, average log likelihood -1.150634
WARNING: Variances had to be floored 2
INFO: iteration 10, average log likelihood -1.162469
INFO: iteration 11, average log likelihood -1.159735
WARNING: Variances had to be floored 6
INFO: iteration 12, average log likelihood -1.149322
INFO: iteration 13, average log likelihood -1.162211
INFO: iteration 14, average log likelihood -1.153779
WARNING: Variances had to be floored 6
INFO: iteration 15, average log likelihood -1.147687
INFO: iteration 16, average log likelihood -1.161017
WARNING: Variances had to be floored 2
INFO: iteration 17, average log likelihood -1.152143
WARNING: Variances had to be floored 6
INFO: iteration 18, average log likelihood -1.152082
INFO: iteration 19, average log likelihood -1.161046
INFO: iteration 20, average log likelihood -1.151280
WARNING: Variances had to be floored 6
INFO: iteration 21, average log likelihood -1.144782
INFO: iteration 22, average log likelihood -1.158302
INFO: iteration 23, average log likelihood -1.149832
WARNING: Variances had to be floored 2 6
INFO: iteration 24, average log likelihood -1.143581
INFO: iteration 25, average log likelihood -1.163217
INFO: iteration 26, average log likelihood -1.151102
WARNING: Variances had to be floored 6
INFO: iteration 27, average log likelihood -1.144855
INFO: iteration 28, average log likelihood -1.158549
INFO: iteration 29, average log likelihood -1.150275
WARNING: Variances had to be floored 6
INFO: iteration 30, average log likelihood -1.144338
INFO: iteration 31, average log likelihood -1.157915
WARNING: Variances had to be floored 2
INFO: iteration 32, average log likelihood -1.149254
WARNING: Variances had to be floored 6
INFO: iteration 33, average log likelihood -1.149368
INFO: iteration 34, average log likelihood -1.159199
INFO: iteration 35, average log likelihood -1.150568
WARNING: Variances had to be floored 6
INFO: iteration 36, average log likelihood -1.144682
INFO: iteration 37, average log likelihood -1.158423
INFO: iteration 38, average log likelihood -1.150092
WARNING: Variances had to be floored 6
INFO: iteration 39, average log likelihood -1.144031
WARNING: Variances had to be floored 2
INFO: iteration 40, average log likelihood -1.157386
INFO: iteration 41, average log likelihood -1.155110
WARNING: Variances had to be floored 6
INFO: iteration 42, average log likelihood -1.145375
INFO: iteration 43, average log likelihood -1.158692
INFO: iteration 44, average log likelihood -1.150404
WARNING: Variances had to be floored 6
INFO: iteration 45, average log likelihood -1.144532
INFO: iteration 46, average log likelihood -1.158235
INFO: iteration 47, average log likelihood -1.149778
WARNING: Variances had to be floored 2 6
INFO: iteration 48, average log likelihood -1.143512
INFO: iteration 49, average log likelihood -1.163219
INFO: iteration 50, average log likelihood -1.151101
INFO: EM with 100000 data points 50 iterations avll -1.151101
118.1 data points per parameter
4: avll = [-1.2537680061814676,-1.253565501574187,-1.2525492452548284,-1.2387098202170421,-1.1939513278314826,-1.1638779504093937,-1.169865147430882,-1.1586271027433357,-1.1506336454829404,-1.1624690695030693,-1.159734766616581,-1.149321859769368,-1.1622108250301977,-1.1537787220527798,-1.1476871684227543,-1.1610169967513784,-1.152142809776183,-1.1520818795480687,-1.1610462863207955,-1.151280431699525,-1.1447816148524872,-1.158302365089181,-1.1498320151469372,-1.1435812590589418,-1.1632165117074038,-1.1511023664214868,-1.144855041158184,-1.1585487696586378,-1.1502750826110135,-1.1443381597771547,-1.1579151441190696,-1.1492541302224024,-1.149367857543691,-1.1591986440493591,-1.1505680503303024,-1.1446818445755795,-1.1584231615263678,-1.1500918010317487,-1.144031461296842,-1.1573861422109293,-1.1551102521105248,-1.1453748606968375,-1.1586923736075492,-1.15040413643511,-1.1445319047713438,-1.1582346855277308,-1.1497783776671877,-1.1435115013206472,-1.1632188404321981,-1.1511009434972295]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 11 12
INFO: iteration 1, average log likelihood -1.145136
WARNING: Variances had to be floored 11 12
INFO: iteration 2, average log likelihood -1.144683
WARNING: Variances had to be floored 11 12
INFO: iteration 3, average log likelihood -1.144135
WARNING: Variances had to be floored 11 12
INFO: iteration 4, average log likelihood -1.136817
WARNING: Variances had to be floored 2 4 11 12 24
INFO: iteration 5, average log likelihood -1.104016
WARNING: Variances had to be floored 3 11 12
INFO: iteration 6, average log likelihood -1.096351
WARNING: Variances had to be floored 2 4 11 12 18 24
INFO: iteration 7, average log likelihood -1.076648
WARNING: Variances had to be floored 3 11 12
INFO: iteration 8, average log likelihood -1.088443
WARNING: Variances had to be floored 2 4 11 12 24
INFO: iteration 9, average log likelihood -1.074162
WARNING: Variances had to be floored 3 11 12
INFO: iteration 10, average log likelihood -1.086534
WARNING: Variances had to be floored 2 4 11 12 18 24
INFO: iteration 11, average log likelihood -1.069294
WARNING: Variances had to be floored 3 11 12
INFO: iteration 12, average log likelihood -1.074714
WARNING: Variances had to be floored 2 4 11 12 15 24
INFO: iteration 13, average log likelihood -1.055200
WARNING: Variances had to be floored 3 11 12 18
INFO: iteration 14, average log likelihood -1.085556
WARNING: Variances had to be floored 2 11 12 24
INFO: iteration 15, average log likelihood -1.070357
WARNING: Variances had to be floored 4 11 12 18
INFO: iteration 16, average log likelihood -1.077712
WARNING: Variances had to be floored 2 3 11 12 24
INFO: iteration 17, average log likelihood -1.057895
WARNING: Variances had to be floored 4 11 12 15 18
INFO: iteration 18, average log likelihood -1.066940
WARNING: Variances had to be floored 2 3 11 12 24
INFO: iteration 19, average log likelihood -1.071765
WARNING: Variances had to be floored 11 12 18
INFO: iteration 20, average log likelihood -1.082851
WARNING: Variances had to be floored 2 4 11 12 24
INFO: iteration 21, average log likelihood -1.064369
WARNING: Variances had to be floored 3 11 12 18
INFO: iteration 22, average log likelihood -1.071423
WARNING: Variances had to be floored 2 4 11 12 15 24
INFO: iteration 23, average log likelihood -1.053114
WARNING: Variances had to be floored 3 11 12 18
INFO: iteration 24, average log likelihood -1.085351
WARNING: Variances had to be floored 2 11 12 24
INFO: iteration 25, average log likelihood -1.070114
WARNING: Variances had to be floored 4 11 12 18
INFO: iteration 26, average log likelihood -1.077488
WARNING: Variances had to be floored 2 3 11 12 18 24
INFO: iteration 27, average log likelihood -1.058266
WARNING: Variances had to be floored 4 11 12 15
INFO: iteration 28, average log likelihood -1.066515
WARNING: Variances had to be floored 2 3 11 12 18 24
INFO: iteration 29, average log likelihood -1.072089
WARNING: Variances had to be floored 11 12 18
INFO: iteration 30, average log likelihood -1.082502
WARNING: Variances had to be floored 2 4 11 12 24
INFO: iteration 31, average log likelihood -1.064137
WARNING: Variances had to be floored 3 11 12 18
INFO: iteration 32, average log likelihood -1.071922
WARNING: Variances had to be floored 2 4 11 12 15 18 24
INFO: iteration 33, average log likelihood -1.052576
WARNING: Variances had to be floored 11 12 18
INFO: iteration 34, average log likelihood -1.085668
WARNING: Variances had to be floored 2 3 11 12 24
INFO: iteration 35, average log likelihood -1.069593
WARNING: Variances had to be floored 4 11 12 18
INFO: iteration 36, average log likelihood -1.077478
WARNING: Variances had to be floored 2 11 12 18 24
INFO: iteration 37, average log likelihood -1.058530
WARNING: Variances had to be floored 3 4 11 12 15 18
INFO: iteration 38, average log likelihood -1.066136
WARNING: Variances had to be floored 2 11 12 18 24
INFO: iteration 39, average log likelihood -1.072252
WARNING: Variances had to be floored 3 11 12 18
INFO: iteration 40, average log likelihood -1.082244
WARNING: Variances had to be floored 2 4 11 12 18 24
INFO: iteration 41, average log likelihood -1.064221
WARNING: Variances had to be floored 11 12 18
INFO: iteration 42, average log likelihood -1.072009
WARNING: Variances had to be floored 2 3 4 11 12 15 18 24
INFO: iteration 43, average log likelihood -1.052447
WARNING: Variances had to be floored 11 12 18
INFO: iteration 44, average log likelihood -1.085675
WARNING: Variances had to be floored 2 3 11 12 18 24
INFO: iteration 45, average log likelihood -1.069613
WARNING: Variances had to be floored 4 11 12 18
INFO: iteration 46, average log likelihood -1.077393
WARNING: Variances had to be floored 2 11 12 18 24
INFO: iteration 47, average log likelihood -1.058555
WARNING: Variances had to be floored 3 4 11 12 15 18
INFO: iteration 48, average log likelihood -1.066133
WARNING: Variances had to be floored 2 11 12 18 24
INFO: iteration 49, average log likelihood -1.072235
WARNING: Variances had to be floored 3 11 12 18
INFO: iteration 50, average log likelihood -1.082227
INFO: EM with 100000 data points 50 iterations avll -1.082227
59.0 data points per parameter
5: avll = [-1.1451362956918305,-1.1446830229215896,-1.1441349634416411,-1.1368167253357775,-1.1040157500877137,-1.096350782589331,-1.0766478255522551,-1.0884430736870618,-1.0741617647565735,-1.0865339036605195,-1.0692935210680954,-1.07471444458018,-1.0551998080518645,-1.0855558824946727,-1.070357220506935,-1.0777120036897239,-1.0578950371240512,-1.0669400599852767,-1.0717650439311983,-1.0828513180366874,-1.0643694526613077,-1.0714234189071155,-1.053114189841058,-1.0853512755957002,-1.0701135462958988,-1.0774877646305498,-1.058266163791919,-1.0665147986684937,-1.0720890637535836,-1.0825020134814407,-1.064136633208627,-1.0719221740089295,-1.0525756351739415,-1.085668137174872,-1.069592874622284,-1.0774781016294281,-1.0585295058094542,-1.0661364055252047,-1.0722517326934335,-1.0822437646425433,-1.0642211869955716,-1.0720094321484772,-1.052447169793561,-1.085675256020646,-1.0696132949900212,-1.0773933371190976,-1.0585550903986118,-1.0661326825179984,-1.0722350313762492,-1.0822267815637387]
[-1.403580542838749,-1.4036628386158698,-1.403592221451071,-1.4031262199618262,-1.3970186481663727,-1.3789652623212632,-1.3714455241716421,-1.370355391513378,-1.369920979789013,-1.3696325502994877,-1.369409837740192,-1.3692210846355812,-1.3690389240642593,-1.3688468526483049,-1.3686480806805774,-1.3684458059726348,-1.3682390092539967,-1.3680328486409277,-1.3678293756495772,-1.3676308877974739,-1.3674420647537406,-1.3672668581207514,-1.3671074361591393,-1.3669658779531657,-1.3668395861951863,-1.3667235970213132,-1.366612079957325,-1.3664949978601821,-1.366362335703506,-1.3662115352766038,-1.366065129087612,-1.365941524492199,-1.3658462393687298,-1.3657781654585428,-1.3657321762952874,-1.3657014023384206,-1.3656804265094933,-1.3656658728452407,-1.3656555675657993,-1.3656481268150205,-1.3656426742633532,-1.3656386366579452,-1.365635622762576,-1.3656333576135176,-1.3656316447669796,-1.3656303423949119,-1.365629347213761,-1.3656285834049589,-1.3656279948865528,-1.3656275398759075,-1.3656271870333285,-1.365731769566813,-1.3656443609436222,-1.3653168865582412,-1.3617663528599555,-1.3484160273674106,-1.3373824106691863,-1.334151550844788,-1.332909946587892,-1.3321258129237965,-1.3315052220641646,-1.330891871738254,-1.330208306852658,-1.3293606878988753,-1.3283436284244305,-1.327312946653507,-1.3265147912044817,-1.326023807464979,-1.325724623497115,-1.3255112905953723,-1.3253239824113472,-1.325131131825363,-1.3249006489779163,-1.3245655349082073,-1.3240969510077358,-1.3235073565054345,-1.3227457721898022,-1.322019895731249,-1.321525828475488,-1.3211654862436903,-1.3207803251627441,-1.3203120549883884,-1.3199212678153993,-1.3196994283324308,-1.3195806968323833,-1.3195128494121973,-1.3194713546582413,-1.3194436117633495,-1.3194234832627973,-1.319408082614667,-1.3193959550462064,-1.3193862248827402,-1.3193782763138815,-1.3193716632941197,-1.3193660695030396,-1.319361272192768,-1.3193571116575966,-1.3193534700530636,-1.3193502580831609,-1.3193474065280466,-1.3193448605840905,-1.3195193528651854,-1.3193375128964284,-1.3183989373756342,-1.310298821437247,-1.2916615821426325,-1.2762494239897884,-1.2695574529820168,-1.266169334171564,-1.2637114764627966,-1.2616086628691388,-1.2597473867038838,-1.2582455435278395,-1.2572114757359063,-1.2565673207573151,-1.256170005149846,-1.2559201296511655,-1.2557606462976434,-1.255658083840284,-1.2555906219421824,-1.2555439010293339,-1.2555085532607522,-1.2554785082353694,-1.255449784193096,-1.255419660700038,-1.255386166823867,-1.255347746405806,-1.2553026356322714,-1.2552477323550353,-1.2551790259109803,-1.2550941864182732,-1.2549914576153836,-1.2548701746396036,-1.2547348232480928,-1.254589662417048,-1.254436818361665,-1.2542770961209724,-1.2541128383761795,-1.2539550477031962,-1.2538192328994093,-1.2537199421731284,-1.2536578541503334,-1.2536225609744822,-1.253603051970678,-1.253591847153715,-1.2535849702714004,-1.2535805080413127,-1.253577513075712,-1.2535754640935088,-1.253574047831625,-1.2535730643406775,-1.2537680061814676,-1.253565501574187,-1.2525492452548284,-1.2387098202170421,-1.1939513278314826,-1.1638779504093937,-1.169865147430882,-1.1586271027433357,-1.1506336454829404,-1.1624690695030693,-1.159734766616581,-1.149321859769368,-1.1622108250301977,-1.1537787220527798,-1.1476871684227543,-1.1610169967513784,-1.152142809776183,-1.1520818795480687,-1.1610462863207955,-1.151280431699525,-1.1447816148524872,-1.158302365089181,-1.1498320151469372,-1.1435812590589418,-1.1632165117074038,-1.1511023664214868,-1.144855041158184,-1.1585487696586378,-1.1502750826110135,-1.1443381597771547,-1.1579151441190696,-1.1492541302224024,-1.149367857543691,-1.1591986440493591,-1.1505680503303024,-1.1446818445755795,-1.1584231615263678,-1.1500918010317487,-1.144031461296842,-1.1573861422109293,-1.1551102521105248,-1.1453748606968375,-1.1586923736075492,-1.15040413643511,-1.1445319047713438,-1.1582346855277308,-1.1497783776671877,-1.1435115013206472,-1.1632188404321981,-1.1511009434972295,-1.1451362956918305,-1.1446830229215896,-1.1441349634416411,-1.1368167253357775,-1.1040157500877137,-1.096350782589331,-1.0766478255522551,-1.0884430736870618,-1.0741617647565735,-1.0865339036605195,-1.0692935210680954,-1.07471444458018,-1.0551998080518645,-1.0855558824946727,-1.070357220506935,-1.0777120036897239,-1.0578950371240512,-1.0669400599852767,-1.0717650439311983,-1.0828513180366874,-1.0643694526613077,-1.0714234189071155,-1.053114189841058,-1.0853512755957002,-1.0701135462958988,-1.0774877646305498,-1.058266163791919,-1.0665147986684937,-1.0720890637535836,-1.0825020134814407,-1.064136633208627,-1.0719221740089295,-1.0525756351739415,-1.085668137174872,-1.069592874622284,-1.0774781016294281,-1.0585295058094542,-1.0661364055252047,-1.0722517326934335,-1.0822437646425433,-1.0642211869955716,-1.0720094321484772,-1.052447169793561,-1.085675256020646,-1.0696132949900212,-1.0773933371190976,-1.0585550903986118,-1.0661326825179984,-1.0722350313762492,-1.0822267815637387]
32x26 Array{Float64,2}:
 -0.0724029   0.340531    0.0251503    â€¦  -0.132756    -0.00164139
 -0.0581853   0.0419816  -0.115829        -0.110149     0.0879481 
  0.0603342   0.0665534  -0.230101        -0.070495     0.118564  
  0.180403    0.0252735  -0.134267        -0.070004    -0.174578  
 -0.05589    -0.104847    0.0501333       -0.00756515   0.0683651 
  0.0347602   0.0334091   0.0686726    â€¦  -0.00265482  -0.188022  
  0.0110716   0.0542776  -0.000425118     -0.00792376   0.0781027 
  0.0950645  -0.0333949   0.0103038        0.070823     0.0351984 
 -0.0184546   0.0627716  -0.217395         0.0363047    0.122196  
  0.109804    0.0412479  -0.0710916        0.0551878    0.161111  
  â‹®                                    â‹±                â‹®         
  0.0827099   0.0389607  -0.202704        -0.140032     0.106161  
 -0.0556616  -0.242994    0.0749439        0.119554    -0.0810362 
  0.008219    0.0643171   0.0988093    â€¦   0.347285    -0.075456  
 -0.019255    0.22112    -0.00309535      -0.0427231   -0.1658    
 -0.0120236   0.240723   -0.0114832        0.0826728    0.314623  
  0.0108833   0.0535448  -0.0568181        0.157885     0.00799818
 -0.0866496   0.0600048   0.00469216      -0.0604906    0.066067  
 -0.180966   -0.138815   -0.0685747    â€¦   0.277721     0.00018346
 -0.0969552   0.0266957   0.0050334       -0.0269381    0.0430999 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 2 4 11 12 18 24
INFO: iteration 1, average log likelihood -1.064209
WARNING: Variances had to be floored 2 4 11 12 18 24
INFO: iteration 2, average log likelihood -1.056512
WARNING: Variances had to be floored 2 4 11 12 15 18 24
INFO: iteration 3, average log likelihood -1.052470
WARNING: Variances had to be floored 2 4 11 12 18 24
INFO: iteration 4, average log likelihood -1.063674
WARNING: Variances had to be floored 2 4 11 12 18 24
INFO: iteration 5, average log likelihood -1.056233
WARNING: Variances had to be floored 2 4 11 12 15 18 24
INFO: iteration 6, average log likelihood -1.052167
WARNING: Variances had to be floored 2 4 11 12 18 24
INFO: iteration 7, average log likelihood -1.061653
WARNING: Variances had to be floored 2 4 11 12 15 18 24
INFO: iteration 8, average log likelihood -1.050498
WARNING: Variances had to be floored 2 4 11 12 18 24
INFO: iteration 9, average log likelihood -1.054990
WARNING: Variances had to be floored 2 4 11 12 15 18 24
INFO: iteration 10, average log likelihood -1.047094
INFO: EM with 100000 data points 10 iterations avll -1.047094
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.927952e+05
      1       6.717002e+05      -2.210950e+05 |       32
      2       6.440337e+05      -2.766647e+04 |       32
      3       6.282846e+05      -1.574908e+04 |       32
      4       6.186272e+05      -9.657397e+03 |       32
      5       6.131870e+05      -5.440261e+03 |       32
      6       6.095587e+05      -3.628291e+03 |       32
      7       6.070214e+05      -2.537264e+03 |       32
      8       6.052559e+05      -1.765506e+03 |       32
      9       6.038688e+05      -1.387075e+03 |       32
     10       6.024902e+05      -1.378641e+03 |       32
     11       6.011644e+05      -1.325781e+03 |       32
     12       6.000561e+05      -1.108302e+03 |       32
     13       5.992796e+05      -7.765515e+02 |       32
     14       5.986598e+05      -6.197972e+02 |       32
     15       5.981741e+05      -4.856360e+02 |       32
     16       5.978348e+05      -3.393843e+02 |       32
     17       5.975955e+05      -2.392732e+02 |       32
     18       5.974203e+05      -1.751670e+02 |       32
     19       5.972615e+05      -1.588196e+02 |       32
     20       5.971010e+05      -1.604541e+02 |       32
     21       5.969482e+05      -1.528774e+02 |       32
     22       5.968032e+05      -1.449180e+02 |       32
     23       5.966980e+05      -1.052100e+02 |       31
     24       5.966098e+05      -8.826032e+01 |       31
     25       5.965289e+05      -8.085075e+01 |       31
     26       5.964812e+05      -4.767062e+01 |       32
     27       5.964571e+05      -2.410109e+01 |       32
     28       5.964428e+05      -1.435287e+01 |       31
     29       5.964324e+05      -1.034745e+01 |       25
     30       5.964275e+05      -4.941118e+00 |       23
     31       5.964257e+05      -1.763354e+00 |       18
     32       5.964248e+05      -9.297118e-01 |       19
     33       5.964240e+05      -7.873653e-01 |       17
     34       5.964233e+05      -6.812171e-01 |       13
     35       5.964230e+05      -3.851604e-01 |        4
     36       5.964229e+05      -5.539204e-02 |        4
     37       5.964226e+05      -2.560980e-01 |        8
     38       5.964223e+05      -3.406639e-01 |        8
     39       5.964220e+05      -2.620012e-01 |        5
     40       5.964220e+05      -9.467811e-02 |        2
     41       5.964219e+05      -4.898997e-02 |        2
     42       5.964219e+05      -3.650252e-02 |        0
     43       5.964219e+05       0.000000e+00 |        0
K-means converged with 43 iterations (objv = 596421.8660242688)
INFO: K-means with 32000 data points using 43 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.316671
INFO: iteration 2, average log likelihood -1.285045
INFO: iteration 3, average log likelihood -1.254585
INFO: iteration 4, average log likelihood -1.219420
INFO: iteration 5, average log likelihood -1.182996
WARNING: Variances had to be floored 10
INFO: iteration 6, average log likelihood -1.143758
INFO: iteration 7, average log likelihood -1.112297
WARNING: Variances had to be floored 8 9
INFO: iteration 8, average log likelihood -1.058868
WARNING: Variances had to be floored 19 30 31
INFO: iteration 9, average log likelihood -1.043127
WARNING: Variances had to be floored 10 26
INFO: iteration 10, average log likelihood -1.065181
WARNING: Variances had to be floored 23
INFO: iteration 11, average log likelihood -1.069996
WARNING: Variances had to be floored 9 30
INFO: iteration 12, average log likelihood -1.040975
WARNING: Variances had to be floored 8 10 19 26
INFO: iteration 13, average log likelihood -1.046341
WARNING: Variances had to be floored 25
INFO: iteration 14, average log likelihood -1.077242
WARNING: Variances had to be floored 23
INFO: iteration 15, average log likelihood -1.055221
WARNING: Variances had to be floored 8 9 30 31
INFO: iteration 16, average log likelihood -1.029265
WARNING: Variances had to be floored 10 19 26
INFO: iteration 17, average log likelihood -1.068589
INFO: iteration 18, average log likelihood -1.083242
INFO: iteration 19, average log likelihood -1.049089
WARNING: Variances had to be floored 8 9 10 19 23 30
INFO: iteration 20, average log likelihood -1.008286
WARNING: Variances had to be floored 26
INFO: iteration 21, average log likelihood -1.089673
INFO: iteration 22, average log likelihood -1.078840
WARNING: Variances had to be floored 25
INFO: iteration 23, average log likelihood -1.043842
WARNING: Variances had to be floored 9 10 23 30
INFO: iteration 24, average log likelihood -1.011537
WARNING: Variances had to be floored 4 8 19
INFO: iteration 25, average log likelihood -1.055979
INFO: iteration 26, average log likelihood -1.074722
WARNING: Variances had to be floored 25 31
INFO: iteration 27, average log likelihood -1.037320
WARNING: Variances had to be floored 8 9 10 23 30
INFO: iteration 28, average log likelihood -1.016494
WARNING: Variances had to be floored 19
INFO: iteration 29, average log likelihood -1.075805
WARNING: Variances had to be floored 4
INFO: iteration 30, average log likelihood -1.060131
WARNING: Variances had to be floored 25
INFO: iteration 31, average log likelihood -1.042465
WARNING: Variances had to be floored 9 10 19 23 30
INFO: iteration 32, average log likelihood -1.009807
WARNING: Variances had to be floored 8
INFO: iteration 33, average log likelihood -1.072349
WARNING: Variances had to be floored 4
INFO: iteration 34, average log likelihood -1.057389
WARNING: Variances had to be floored 25 26
INFO: iteration 35, average log likelihood -1.037362
WARNING: Variances had to be floored 9 10 23 30
INFO: iteration 36, average log likelihood -1.018501
WARNING: Variances had to be floored 8 19
INFO: iteration 37, average log likelihood -1.060255
WARNING: Variances had to be floored 4
INFO: iteration 38, average log likelihood -1.057668
WARNING: Variances had to be floored 10 25 26
INFO: iteration 39, average log likelihood -1.034769
WARNING: Variances had to be floored 9 23 30
INFO: iteration 40, average log likelihood -1.028480
WARNING: Variances had to be floored 8 19
INFO: iteration 41, average log likelihood -1.051553
WARNING: Variances had to be floored 4
INFO: iteration 42, average log likelihood -1.050020
WARNING: Variances had to be floored 10 25 26
INFO: iteration 43, average log likelihood -1.027815
WARNING: Variances had to be floored 9 23 30
INFO: iteration 44, average log likelihood -1.027183
WARNING: Variances had to be floored 8 19
INFO: iteration 45, average log likelihood -1.050938
WARNING: Variances had to be floored 4
INFO: iteration 46, average log likelihood -1.049684
WARNING: Variances had to be floored 10 25 26
INFO: iteration 47, average log likelihood -1.027414
WARNING: Variances had to be floored 9 23 30
INFO: iteration 48, average log likelihood -1.027016
WARNING: Variances had to be floored 8 19
INFO: iteration 49, average log likelihood -1.050843
WARNING: Variances had to be floored 4
INFO: iteration 50, average log likelihood -1.049650
INFO: EM with 100000 data points 50 iterations avll -1.049650
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.180993    -0.13855     -0.0661849   â€¦   0.293274    -0.00136276
 -0.0189542   -0.0828813    0.0866875       0.239873    -0.0786635 
  0.0245171    0.102557     0.0386211       0.140165    -0.0192909 
 -0.0164204    0.131697     0.0706357      -0.0956447   -0.0349351 
  0.0749867    0.0157037    0.0248389      -0.0499842    0.0654592 
  0.037669     0.0324481    0.0749232   â€¦  -0.00680222  -0.192172  
  0.0785471   -0.092798     0.143286       -0.0988197   -0.110158  
 -0.0767512    0.108077    -0.048361        0.0204383    0.12098   
  0.0233863    0.135361     0.0343835      -0.13066      0.0691647 
  0.117045    -0.00448008   0.0251725       0.078766    -0.0111452 
  â‹®                                     â‹±                â‹®         
 -0.0304846    0.00491714   0.0289112       0.0341162    0.0346769 
  0.00447714   0.0723544   -0.0351463       0.0204968    0.077151  
 -0.0589324    0.0475765   -0.109703    â€¦  -0.111501     0.0844823 
  0.0481001    0.0523001   -0.137218        0.0401172    0.142355  
 -0.0191237    0.239594    -0.00671839     -0.00418797   0.0491802 
 -0.0103261    0.0376497   -0.103214       -0.026549     0.126117  
  0.0480405    0.0736875   -0.171128       -0.157128     0.0987122 
  0.056639     0.171072    -0.055329    â€¦  -0.0948837   -0.0981341 
  0.0185567    0.105277    -0.156025        0.0498469    0.00199062INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 10 25 26
INFO: iteration 1, average log likelihood -1.027369
WARNING: Variances had to be floored 8 9 10 19 23 25 26 30
INFO: iteration 2, average log likelihood -0.984026
WARNING: Variances had to be floored 4 10 25 26 30
INFO: iteration 3, average log likelihood -1.011900
WARNING: Variances had to be floored 8 9 10 19 25 26 30
INFO: iteration 4, average log likelihood -0.999151
WARNING: Variances had to be floored 10 23 25 26 30
INFO: iteration 5, average log likelihood -1.013282
WARNING: Variances had to be floored 4 8 9 10 19 25 26 30
INFO: iteration 6, average log likelihood -0.988072
WARNING: Variances had to be floored 10 25 26 30
INFO: iteration 7, average log likelihood -1.022909
WARNING: Variances had to be floored 8 9 10 19 23 25 26 30
INFO: iteration 8, average log likelihood -0.991597
WARNING: Variances had to be floored 4 10 25 26 30
INFO: iteration 9, average log likelihood -1.011764
WARNING: Variances had to be floored 8 9 10 19 25 26 30
INFO: iteration 10, average log likelihood -0.999154
INFO: EM with 100000 data points 10 iterations avll -0.999154
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.0861275     0.168008   -0.0294188  â€¦   0.0726864   0.0943602  
 -0.0568635     0.0550018   0.035463       0.0763927   0.0974715  
  0.000544798  -0.102471   -0.0143046      0.116742    0.0312846  
  0.232434      0.0355678   0.0189632     -0.0438645  -0.00796759 
 -0.0384209     0.0803      0.0270775     -0.0189204  -0.139332   
 -0.0331343     0.118249   -0.0846611  â€¦  -0.0272177  -0.0388261  
  0.0219735     0.107669    0.0746859     -0.0700555  -0.0792471  
  0.00266522   -0.142285   -0.193127       0.0519268   0.0565515  
 -0.0631363    -0.105289   -0.0739951     -0.017684   -0.0996834  
  0.092717     -0.121737    0.103333      -0.134177    0.0550221  
  â‹®                                    â‹±               â‹®          
 -0.0504025    -0.0308447  -0.0270498      0.0262638   0.0631502  
 -0.1699       -0.0398969   0.0274688     -0.0761667  -0.000594284
 -0.0763677     0.121115   -0.118176   â€¦   0.100431    0.0438693  
 -0.0893735    -0.0126201   0.0794603     -0.0870526  -0.0374588  
  0.0756514     0.0368807  -0.0209797     -0.0465306  -0.123033   
 -0.237629     -0.0437256   0.0184184      0.0517024  -0.0641937  
  0.0424226     0.0305916  -0.0468209      0.161869    0.106871   
 -0.0857473    -0.045574   -0.139217   â€¦   0.0161595   0.0570766  
  0.149801      0.109826    0.167659      -0.0397337   0.066999   kind full, method split
0: avll = -1.4178040065860649
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.417822
INFO: iteration 2, average log likelihood -1.417754
INFO: iteration 3, average log likelihood -1.417700
INFO: iteration 4, average log likelihood -1.417638
INFO: iteration 5, average log likelihood -1.417564
INFO: iteration 6, average log likelihood -1.417480
INFO: iteration 7, average log likelihood -1.417391
INFO: iteration 8, average log likelihood -1.417304
INFO: iteration 9, average log likelihood -1.417227
INFO: iteration 10, average log likelihood -1.417162
INFO: iteration 11, average log likelihood -1.417105
INFO: iteration 12, average log likelihood -1.417042
INFO: iteration 13, average log likelihood -1.416952
INFO: iteration 14, average log likelihood -1.416796
INFO: iteration 15, average log likelihood -1.416510
INFO: iteration 16, average log likelihood -1.416009
INFO: iteration 17, average log likelihood -1.415241
INFO: iteration 18, average log likelihood -1.414315
INFO: iteration 19, average log likelihood -1.413503
INFO: iteration 20, average log likelihood -1.412991
INFO: iteration 21, average log likelihood -1.412738
INFO: iteration 22, average log likelihood -1.412628
INFO: iteration 23, average log likelihood -1.412582
INFO: iteration 24, average log likelihood -1.412563
INFO: iteration 25, average log likelihood -1.412555
INFO: iteration 26, average log likelihood -1.412551
INFO: iteration 27, average log likelihood -1.412550
INFO: iteration 28, average log likelihood -1.412549
INFO: iteration 29, average log likelihood -1.412548
INFO: iteration 30, average log likelihood -1.412547
INFO: iteration 31, average log likelihood -1.412547
INFO: iteration 32, average log likelihood -1.412547
INFO: iteration 33, average log likelihood -1.412547
INFO: iteration 34, average log likelihood -1.412546
INFO: iteration 35, average log likelihood -1.412546
INFO: iteration 36, average log likelihood -1.412546
INFO: iteration 37, average log likelihood -1.412546
INFO: iteration 38, average log likelihood -1.412546
INFO: iteration 39, average log likelihood -1.412546
INFO: iteration 40, average log likelihood -1.412545
INFO: iteration 41, average log likelihood -1.412545
INFO: iteration 42, average log likelihood -1.412545
INFO: iteration 43, average log likelihood -1.412545
INFO: iteration 44, average log likelihood -1.412545
INFO: iteration 45, average log likelihood -1.412545
INFO: iteration 46, average log likelihood -1.412545
INFO: iteration 47, average log likelihood -1.412545
INFO: iteration 48, average log likelihood -1.412545
INFO: iteration 49, average log likelihood -1.412545
INFO: iteration 50, average log likelihood -1.412545
INFO: EM with 100000 data points 50 iterations avll -1.412545
952.4 data points per parameter
1: avll = [-1.4178224937255675,-1.4177535808709438,-1.4176999495480704,-1.4176379252784546,-1.4175644357117472,-1.4174803101689941,-1.4173907667915921,-1.417303892743788,-1.4172268822491694,-1.4171620358326866,-1.4171046514696004,-1.417042262844244,-1.4169523816466056,-1.4167963182928924,-1.416510490503392,-1.4160091819223888,-1.415241141643434,-1.4143147187461411,-1.4135027230893065,-1.4129905108088208,-1.4127379816936554,-1.4126282879635685,-1.412582475455724,-1.4125632784076354,-1.4125550336048132,-1.4125513272029016,-1.412549528560032,-1.4125485500116786,-1.412547937516835,-1.41254749925414,-1.4125471527157354,-1.4125468613117627,-1.4125466079256404,-1.4125463838196448,-1.4125461839517637,-1.4125460049833145,-1.4125458444212442,-1.4125457002413935,-1.4125455707169843,-1.4125454543355276,-1.4125453497544522,-1.41254525577419,-1.4125451713195425,-1.4125450954253256,-1.4125450272244853,-1.4125449659378646,-1.4125449108651869,-1.412544861377035,-1.4125448169076726,-1.4125447769486008]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.412559
INFO: iteration 2, average log likelihood -1.412504
INFO: iteration 3, average log likelihood -1.412455
INFO: iteration 4, average log likelihood -1.412395
INFO: iteration 5, average log likelihood -1.412316
INFO: iteration 6, average log likelihood -1.412218
INFO: iteration 7, average log likelihood -1.412103
INFO: iteration 8, average log likelihood -1.411980
INFO: iteration 9, average log likelihood -1.411860
INFO: iteration 10, average log likelihood -1.411752
INFO: iteration 11, average log likelihood -1.411659
INFO: iteration 12, average log likelihood -1.411583
INFO: iteration 13, average log likelihood -1.411522
INFO: iteration 14, average log likelihood -1.411474
INFO: iteration 15, average log likelihood -1.411436
INFO: iteration 16, average log likelihood -1.411407
INFO: iteration 17, average log likelihood -1.411383
INFO: iteration 18, average log likelihood -1.411364
INFO: iteration 19, average log likelihood -1.411348
INFO: iteration 20, average log likelihood -1.411334
INFO: iteration 21, average log likelihood -1.411322
INFO: iteration 22, average log likelihood -1.411312
INFO: iteration 23, average log likelihood -1.411302
INFO: iteration 24, average log likelihood -1.411293
INFO: iteration 25, average log likelihood -1.411286
INFO: iteration 26, average log likelihood -1.411279
INFO: iteration 27, average log likelihood -1.411272
INFO: iteration 28, average log likelihood -1.411266
INFO: iteration 29, average log likelihood -1.411261
INFO: iteration 30, average log likelihood -1.411256
INFO: iteration 31, average log likelihood -1.411252
INFO: iteration 32, average log likelihood -1.411247
INFO: iteration 33, average log likelihood -1.411244
INFO: iteration 34, average log likelihood -1.411240
INFO: iteration 35, average log likelihood -1.411237
INFO: iteration 36, average log likelihood -1.411234
INFO: iteration 37, average log likelihood -1.411232
INFO: iteration 38, average log likelihood -1.411229
INFO: iteration 39, average log likelihood -1.411227
INFO: iteration 40, average log likelihood -1.411225
INFO: iteration 41, average log likelihood -1.411223
INFO: iteration 42, average log likelihood -1.411221
INFO: iteration 43, average log likelihood -1.411219
INFO: iteration 44, average log likelihood -1.411218
INFO: iteration 45, average log likelihood -1.411216
INFO: iteration 46, average log likelihood -1.411215
INFO: iteration 47, average log likelihood -1.411213
INFO: iteration 48, average log likelihood -1.411212
INFO: iteration 49, average log likelihood -1.411211
INFO: iteration 50, average log likelihood -1.411210
INFO: EM with 100000 data points 50 iterations avll -1.411210
473.9 data points per parameter
2: avll = [-1.412559458187422,-1.4125038148595472,-1.4124554124338062,-1.4123948147356975,-1.4123163918296628,-1.4122179396078904,-1.4121027071465047,-1.4119796004937968,-1.4118597442560303,-1.4117516647979198,-1.4116592552821356,-1.4115830032164765,-1.411521759258751,-1.4114735714070972,-1.411436033351038,-1.411406665123185,-1.4113832818422345,-1.4113641844466462,-1.4113481624329094,-1.4113343973852193,-1.4113223480694683,-1.4113116556694365,-1.4113020771594051,-1.4112934420411891,-1.4112856252732826,-1.4112785305656714,-1.4112720801179701,-1.411266208348564,-1.4112608581075294,-1.4112559784342094,-1.4112515232608847,-1.411247450675715,-1.4112437224965124,-1.411240304000423,-1.4112371637183192,-1.4112342732451062,-1.4112316070440984,-1.4112291422394936,-1.4112268583993102,-1.4112247373146287,-1.411222762781609,-1.4112209203919066,-1.4112191973356838,-1.4112175822198767,-1.4112160649030527,-1.4112146363471345,-1.4112132884855093,-1.411212014106549,-1.4112108067512812,-1.4112096606238298]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.411220
INFO: iteration 2, average log likelihood -1.411159
INFO: iteration 3, average log likelihood -1.411104
INFO: iteration 4, average log likelihood -1.411040
INFO: iteration 5, average log likelihood -1.410962
INFO: iteration 6, average log likelihood -1.410870
INFO: iteration 7, average log likelihood -1.410770
INFO: iteration 8, average log likelihood -1.410667
INFO: iteration 9, average log likelihood -1.410568
INFO: iteration 10, average log likelihood -1.410477
INFO: iteration 11, average log likelihood -1.410393
INFO: iteration 12, average log likelihood -1.410315
INFO: iteration 13, average log likelihood -1.410244
INFO: iteration 14, average log likelihood -1.410179
INFO: iteration 15, average log likelihood -1.410122
INFO: iteration 16, average log likelihood -1.410074
INFO: iteration 17, average log likelihood -1.410033
INFO: iteration 18, average log likelihood -1.410000
INFO: iteration 19, average log likelihood -1.409973
INFO: iteration 20, average log likelihood -1.409951
INFO: iteration 21, average log likelihood -1.409932
INFO: iteration 22, average log likelihood -1.409916
INFO: iteration 23, average log likelihood -1.409902
INFO: iteration 24, average log likelihood -1.409890
INFO: iteration 25, average log likelihood -1.409879
INFO: iteration 26, average log likelihood -1.409869
INFO: iteration 27, average log likelihood -1.409859
INFO: iteration 28, average log likelihood -1.409850
INFO: iteration 29, average log likelihood -1.409842
INFO: iteration 30, average log likelihood -1.409834
INFO: iteration 31, average log likelihood -1.409826
INFO: iteration 32, average log likelihood -1.409819
INFO: iteration 33, average log likelihood -1.409812
INFO: iteration 34, average log likelihood -1.409805
INFO: iteration 35, average log likelihood -1.409798
INFO: iteration 36, average log likelihood -1.409791
INFO: iteration 37, average log likelihood -1.409784
INFO: iteration 38, average log likelihood -1.409778
INFO: iteration 39, average log likelihood -1.409771
INFO: iteration 40, average log likelihood -1.409765
INFO: iteration 41, average log likelihood -1.409758
INFO: iteration 42, average log likelihood -1.409752
INFO: iteration 43, average log likelihood -1.409746
INFO: iteration 44, average log likelihood -1.409740
INFO: iteration 45, average log likelihood -1.409734
INFO: iteration 46, average log likelihood -1.409728
INFO: iteration 47, average log likelihood -1.409722
INFO: iteration 48, average log likelihood -1.409717
INFO: iteration 49, average log likelihood -1.409711
INFO: iteration 50, average log likelihood -1.409706
INFO: EM with 100000 data points 50 iterations avll -1.409706
236.4 data points per parameter
3: avll = [-1.4112197615636572,-1.4111585318698974,-1.4111037322495903,-1.411039507267923,-1.4109616650871606,-1.410870234665114,-1.4107696453142984,-1.4106669380028323,-1.4105683854532447,-1.4104770595327012,-1.4103930590225429,-1.4103154424480686,-1.4102438847496304,-1.4101790711804245,-1.410122079181876,-1.4100735435082141,-1.4100332426828865,-1.4100002242775433,-1.4099731927107244,-1.409950857017913,-1.4099321160104097,-1.4099161052806586,-1.409902172865441,-1.4098898335272951,-1.409878725434642,-1.4098685763277876,-1.40985917906832,-1.4098503744526758,-1.4098420391630289,-1.4098340772358553,-1.4098264139254388,-1.4098189912065089,-1.409811764406994,-1.4098046996239197,-1.4097977716833143,-1.4097909624793734,-1.4097842595814742,-1.4097776550369163,-1.4097711443259209,-1.4097647254453844,-1.4097583981104456,-1.4097521630695726,-1.4097460215311977,-1.4097399746995496,-1.409734023415634,-1.4097281678972824,-1.4097224075703412,-1.4097167409816298,-1.4097111657832035,-1.4097056787767002]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.409709
INFO: iteration 2, average log likelihood -1.409652
INFO: iteration 3, average log likelihood -1.409598
INFO: iteration 4, average log likelihood -1.409534
INFO: iteration 5, average log likelihood -1.409454
INFO: iteration 6, average log likelihood -1.409356
INFO: iteration 7, average log likelihood -1.409241
INFO: iteration 8, average log likelihood -1.409115
INFO: iteration 9, average log likelihood -1.408986
INFO: iteration 10, average log likelihood -1.408860
INFO: iteration 11, average log likelihood -1.408742
INFO: iteration 12, average log likelihood -1.408632
INFO: iteration 13, average log likelihood -1.408531
INFO: iteration 14, average log likelihood -1.408438
INFO: iteration 15, average log likelihood -1.408352
INFO: iteration 16, average log likelihood -1.408274
INFO: iteration 17, average log likelihood -1.408203
INFO: iteration 18, average log likelihood -1.408139
INFO: iteration 19, average log likelihood -1.408082
INFO: iteration 20, average log likelihood -1.408031
INFO: iteration 21, average log likelihood -1.407985
INFO: iteration 22, average log likelihood -1.407943
INFO: iteration 23, average log likelihood -1.407904
INFO: iteration 24, average log likelihood -1.407869
INFO: iteration 25, average log likelihood -1.407836
INFO: iteration 26, average log likelihood -1.407805
INFO: iteration 27, average log likelihood -1.407776
INFO: iteration 28, average log likelihood -1.407749
INFO: iteration 29, average log likelihood -1.407724
INFO: iteration 30, average log likelihood -1.407700
INFO: iteration 31, average log likelihood -1.407677
INFO: iteration 32, average log likelihood -1.407656
INFO: iteration 33, average log likelihood -1.407636
INFO: iteration 34, average log likelihood -1.407617
INFO: iteration 35, average log likelihood -1.407598
INFO: iteration 36, average log likelihood -1.407581
INFO: iteration 37, average log likelihood -1.407565
INFO: iteration 38, average log likelihood -1.407550
INFO: iteration 39, average log likelihood -1.407536
INFO: iteration 40, average log likelihood -1.407523
INFO: iteration 41, average log likelihood -1.407510
INFO: iteration 42, average log likelihood -1.407498
INFO: iteration 43, average log likelihood -1.407487
INFO: iteration 44, average log likelihood -1.407477
INFO: iteration 45, average log likelihood -1.407467
INFO: iteration 46, average log likelihood -1.407458
INFO: iteration 47, average log likelihood -1.407450
INFO: iteration 48, average log likelihood -1.407442
INFO: iteration 49, average log likelihood -1.407434
INFO: iteration 50, average log likelihood -1.407427
INFO: EM with 100000 data points 50 iterations avll -1.407427
118.1 data points per parameter
4: avll = [-1.4097090266550898,-1.4096519587987926,-1.4095977346668198,-1.4095335982806285,-1.409453919496661,-1.409355975102545,-1.4092411359330212,-1.4091150368733436,-1.4089855871222141,-1.4088597966718388,-1.40874168936258,-1.4086323722144796,-1.4085314132596571,-1.4084381667243282,-1.408352359316221,-1.4082740146609232,-1.4082031256718988,-1.408139417571905,-1.4080823138457297,-1.4080310424528895,-1.4079847758640816,-1.4079427372997142,-1.4079042556842467,-1.4078687800289544,-1.407835870757544,-1.4078051818559723,-1.4077764419259056,-1.4077494377149982,-1.4077240010513405,-1.4076999988557763,-1.407677325476004,-1.407655896584974,-1.4076356440813063,-1.4076165116802302,-1.4075984510955142,-1.4075814188354996,-1.4075653736679203,-1.4075502747798374,-1.4075360806075299,-1.407522748261812,-1.4075102334392064,-1.4074984906925154,-1.407487473934391,-1.4074771370604833,-1.4074674345992617,-1.4074583223187052,-1.4074497577423761,-1.4074417005471573,-1.407434112831761,-1.4074269592590054]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.407430
INFO: iteration 2, average log likelihood -1.407364
INFO: iteration 3, average log likelihood -1.407299
INFO: iteration 4, average log likelihood -1.407219
INFO: iteration 5, average log likelihood -1.407117
INFO: iteration 6, average log likelihood -1.406989
INFO: iteration 7, average log likelihood -1.406836
INFO: iteration 8, average log likelihood -1.406669
INFO: iteration 9, average log likelihood -1.406498
INFO: iteration 10, average log likelihood -1.406336
INFO: iteration 11, average log likelihood -1.406187
INFO: iteration 12, average log likelihood -1.406053
INFO: iteration 13, average log likelihood -1.405936
INFO: iteration 14, average log likelihood -1.405832
INFO: iteration 15, average log likelihood -1.405742
INFO: iteration 16, average log likelihood -1.405662
INFO: iteration 17, average log likelihood -1.405593
INFO: iteration 18, average log likelihood -1.405531
INFO: iteration 19, average log likelihood -1.405476
INFO: iteration 20, average log likelihood -1.405427
INFO: iteration 21, average log likelihood -1.405382
INFO: iteration 22, average log likelihood -1.405342
INFO: iteration 23, average log likelihood -1.405304
INFO: iteration 24, average log likelihood -1.405269
INFO: iteration 25, average log likelihood -1.405237
INFO: iteration 26, average log likelihood -1.405206
INFO: iteration 27, average log likelihood -1.405176
INFO: iteration 28, average log likelihood -1.405148
INFO: iteration 29, average log likelihood -1.405121
INFO: iteration 30, average log likelihood -1.405095
INFO: iteration 31, average log likelihood -1.405070
INFO: iteration 32, average log likelihood -1.405046
INFO: iteration 33, average log likelihood -1.405022
INFO: iteration 34, average log likelihood -1.404999
INFO: iteration 35, average log likelihood -1.404977
INFO: iteration 36, average log likelihood -1.404956
INFO: iteration 37, average log likelihood -1.404935
INFO: iteration 38, average log likelihood -1.404916
INFO: iteration 39, average log likelihood -1.404897
INFO: iteration 40, average log likelihood -1.404878
INFO: iteration 41, average log likelihood -1.404860
INFO: iteration 42, average log likelihood -1.404843
INFO: iteration 43, average log likelihood -1.404827
INFO: iteration 44, average log likelihood -1.404811
INFO: iteration 45, average log likelihood -1.404795
INFO: iteration 46, average log likelihood -1.404780
INFO: iteration 47, average log likelihood -1.404766
INFO: iteration 48, average log likelihood -1.404752
INFO: iteration 49, average log likelihood -1.404738
INFO: iteration 50, average log likelihood -1.404725
INFO: EM with 100000 data points 50 iterations avll -1.404725
59.0 data points per parameter
5: avll = [-1.4074302090464228,-1.407363911924928,-1.407298872827681,-1.4072191382934478,-1.4071169159807226,-1.4069885047093045,-1.4068362446474854,-1.4066688464406243,-1.4064984020528544,-1.40633555741378,-1.4061865163866551,-1.4060533262159238,-1.405935677130561,-1.4058323328913658,-1.4057417776332832,-1.405662422666521,-1.405592690329542,-1.4055310869727462,-1.4054762658007287,-1.4054270623334368,-1.4053824995894668,-1.4053417719636632,-1.4053042194658876,-1.4052693012328288,-1.4052365730859568,-1.4052056705238976,-1.4051762966076446,-1.4051482134860742,-1.405121236087602,-1.4050952264471706,-1.405070087557684,-1.4050457564769256,-1.4050221969810173,-1.404999392043347,-1.4049773363241422,-1.4049560290720189,-1.404935468133062,-1.4049156457335334,-1.4048965463086238,-1.404878146169887,-1.4048604144995382,-1.4048433150965942,-1.404826808396499,-1.4048108534349808,-1.4047954095641628,-1.4047804378336533,-1.404765902019645,-1.4047517693235663,-1.4047380107742642,-1.4047246013654768]
[-1.4178040065860649,-1.4178224937255675,-1.4177535808709438,-1.4176999495480704,-1.4176379252784546,-1.4175644357117472,-1.4174803101689941,-1.4173907667915921,-1.417303892743788,-1.4172268822491694,-1.4171620358326866,-1.4171046514696004,-1.417042262844244,-1.4169523816466056,-1.4167963182928924,-1.416510490503392,-1.4160091819223888,-1.415241141643434,-1.4143147187461411,-1.4135027230893065,-1.4129905108088208,-1.4127379816936554,-1.4126282879635685,-1.412582475455724,-1.4125632784076354,-1.4125550336048132,-1.4125513272029016,-1.412549528560032,-1.4125485500116786,-1.412547937516835,-1.41254749925414,-1.4125471527157354,-1.4125468613117627,-1.4125466079256404,-1.4125463838196448,-1.4125461839517637,-1.4125460049833145,-1.4125458444212442,-1.4125457002413935,-1.4125455707169843,-1.4125454543355276,-1.4125453497544522,-1.41254525577419,-1.4125451713195425,-1.4125450954253256,-1.4125450272244853,-1.4125449659378646,-1.4125449108651869,-1.412544861377035,-1.4125448169076726,-1.4125447769486008,-1.412559458187422,-1.4125038148595472,-1.4124554124338062,-1.4123948147356975,-1.4123163918296628,-1.4122179396078904,-1.4121027071465047,-1.4119796004937968,-1.4118597442560303,-1.4117516647979198,-1.4116592552821356,-1.4115830032164765,-1.411521759258751,-1.4114735714070972,-1.411436033351038,-1.411406665123185,-1.4113832818422345,-1.4113641844466462,-1.4113481624329094,-1.4113343973852193,-1.4113223480694683,-1.4113116556694365,-1.4113020771594051,-1.4112934420411891,-1.4112856252732826,-1.4112785305656714,-1.4112720801179701,-1.411266208348564,-1.4112608581075294,-1.4112559784342094,-1.4112515232608847,-1.411247450675715,-1.4112437224965124,-1.411240304000423,-1.4112371637183192,-1.4112342732451062,-1.4112316070440984,-1.4112291422394936,-1.4112268583993102,-1.4112247373146287,-1.411222762781609,-1.4112209203919066,-1.4112191973356838,-1.4112175822198767,-1.4112160649030527,-1.4112146363471345,-1.4112132884855093,-1.411212014106549,-1.4112108067512812,-1.4112096606238298,-1.4112197615636572,-1.4111585318698974,-1.4111037322495903,-1.411039507267923,-1.4109616650871606,-1.410870234665114,-1.4107696453142984,-1.4106669380028323,-1.4105683854532447,-1.4104770595327012,-1.4103930590225429,-1.4103154424480686,-1.4102438847496304,-1.4101790711804245,-1.410122079181876,-1.4100735435082141,-1.4100332426828865,-1.4100002242775433,-1.4099731927107244,-1.409950857017913,-1.4099321160104097,-1.4099161052806586,-1.409902172865441,-1.4098898335272951,-1.409878725434642,-1.4098685763277876,-1.40985917906832,-1.4098503744526758,-1.4098420391630289,-1.4098340772358553,-1.4098264139254388,-1.4098189912065089,-1.409811764406994,-1.4098046996239197,-1.4097977716833143,-1.4097909624793734,-1.4097842595814742,-1.4097776550369163,-1.4097711443259209,-1.4097647254453844,-1.4097583981104456,-1.4097521630695726,-1.4097460215311977,-1.4097399746995496,-1.409734023415634,-1.4097281678972824,-1.4097224075703412,-1.4097167409816298,-1.4097111657832035,-1.4097056787767002,-1.4097090266550898,-1.4096519587987926,-1.4095977346668198,-1.4095335982806285,-1.409453919496661,-1.409355975102545,-1.4092411359330212,-1.4091150368733436,-1.4089855871222141,-1.4088597966718388,-1.40874168936258,-1.4086323722144796,-1.4085314132596571,-1.4084381667243282,-1.408352359316221,-1.4082740146609232,-1.4082031256718988,-1.408139417571905,-1.4080823138457297,-1.4080310424528895,-1.4079847758640816,-1.4079427372997142,-1.4079042556842467,-1.4078687800289544,-1.407835870757544,-1.4078051818559723,-1.4077764419259056,-1.4077494377149982,-1.4077240010513405,-1.4076999988557763,-1.407677325476004,-1.407655896584974,-1.4076356440813063,-1.4076165116802302,-1.4075984510955142,-1.4075814188354996,-1.4075653736679203,-1.4075502747798374,-1.4075360806075299,-1.407522748261812,-1.4075102334392064,-1.4074984906925154,-1.407487473934391,-1.4074771370604833,-1.4074674345992617,-1.4074583223187052,-1.4074497577423761,-1.4074417005471573,-1.407434112831761,-1.4074269592590054,-1.4074302090464228,-1.407363911924928,-1.407298872827681,-1.4072191382934478,-1.4071169159807226,-1.4069885047093045,-1.4068362446474854,-1.4066688464406243,-1.4064984020528544,-1.40633555741378,-1.4061865163866551,-1.4060533262159238,-1.405935677130561,-1.4058323328913658,-1.4057417776332832,-1.405662422666521,-1.405592690329542,-1.4055310869727462,-1.4054762658007287,-1.4054270623334368,-1.4053824995894668,-1.4053417719636632,-1.4053042194658876,-1.4052693012328288,-1.4052365730859568,-1.4052056705238976,-1.4051762966076446,-1.4051482134860742,-1.405121236087602,-1.4050952264471706,-1.405070087557684,-1.4050457564769256,-1.4050221969810173,-1.404999392043347,-1.4049773363241422,-1.4049560290720189,-1.404935468133062,-1.4049156457335334,-1.4048965463086238,-1.404878146169887,-1.4048604144995382,-1.4048433150965942,-1.404826808396499,-1.4048108534349808,-1.4047954095641628,-1.4047804378336533,-1.404765902019645,-1.4047517693235663,-1.4047380107742642,-1.4047246013654768]
32x26 Array{Float64,2}:
  0.238209    -0.642249   -0.358665   â€¦  -0.236226   -0.416237   -0.600922  
 -0.287458    -0.644401   -0.371969      -0.12218    -0.105066    0.449247  
 -0.0347203   -0.295524   -0.132644      -0.217119   -0.307403    0.122858  
  0.00820105   0.0761786   0.016406       0.246474    0.325708    0.0179576 
  0.429286     0.16228     0.028282       0.157578   -0.0412839   0.0785808 
  0.0608602   -0.0791412   0.0612151  â€¦  -0.249965    0.584853    0.0276312 
  0.617171     0.152366   -0.118087      -0.340372   -0.445154    0.389314  
  0.415148    -0.062024    0.0856836      0.939742    0.273857    0.694455  
 -0.322827    -0.354442    0.0294032     -0.210211   -0.412014   -0.50082   
 -0.132098     0.287212   -0.293         -0.414156    0.0913056  -0.258022  
  â‹®                                   â‹±                           â‹®         
 -0.369956    -0.052404   -0.143676       0.59165     0.740503   -0.0928473 
 -0.180125     0.552154    0.145535       0.41955     0.249797   -0.00920534
  0.145897     0.462818   -0.0804102  â€¦  -0.16355    -0.252897    0.380286  
 -0.216682    -0.478841    0.251746      -0.341062   -0.66401     0.107245  
 -0.142794     0.199321   -0.259932       0.0984837  -0.191304   -0.0630561 
 -0.152746     0.041574    0.116288       0.125423    0.159648   -0.383901  
  0.0366028   -0.201686    0.106781       0.0851375   0.197277   -0.230056  
  0.358091     0.0486296  -0.068667   â€¦  -0.26742    -0.459429    0.0915076 
  0.564266    -0.0221854  -0.265513       0.33332     1.06093     0.593623  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.404712
INFO: iteration 2, average log likelihood -1.404699
INFO: iteration 3, average log likelihood -1.404686
INFO: iteration 4, average log likelihood -1.404674
INFO: iteration 5, average log likelihood -1.404662
INFO: iteration 6, average log likelihood -1.404651
INFO: iteration 7, average log likelihood -1.404639
INFO: iteration 8, average log likelihood -1.404628
INFO: iteration 9, average log likelihood -1.404617
INFO: iteration 10, average log likelihood -1.404607
INFO: EM with 100000 data points 10 iterations avll -1.404607
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.191202e+05
      1       6.957504e+05      -2.233698e+05 |       32
      2       6.834133e+05      -1.233707e+04 |       32
      3       6.784387e+05      -4.974670e+03 |       32
      4       6.759573e+05      -2.481398e+03 |       32
      5       6.744259e+05      -1.531414e+03 |       32
      6       6.733011e+05      -1.124750e+03 |       32
      7       6.724706e+05      -8.304951e+02 |       32
      8       6.718027e+05      -6.678838e+02 |       32
      9       6.712642e+05      -5.385460e+02 |       32
     10       6.708250e+05      -4.391695e+02 |       32
     11       6.704667e+05      -3.583316e+02 |       32
     12       6.701699e+05      -2.968275e+02 |       32
     13       6.699069e+05      -2.629943e+02 |       32
     14       6.696540e+05      -2.529084e+02 |       32
     15       6.694347e+05      -2.192483e+02 |       32
     16       6.692324e+05      -2.022910e+02 |       32
     17       6.690438e+05      -1.886509e+02 |       32
     18       6.688739e+05      -1.698750e+02 |       32
     19       6.686901e+05      -1.837904e+02 |       32
     20       6.685183e+05      -1.718287e+02 |       32
     21       6.683575e+05      -1.607920e+02 |       32
     22       6.681855e+05      -1.719834e+02 |       32
     23       6.680370e+05      -1.484499e+02 |       32
     24       6.678871e+05      -1.499022e+02 |       32
     25       6.677465e+05      -1.406156e+02 |       32
     26       6.676088e+05      -1.376815e+02 |       32
     27       6.674808e+05      -1.280722e+02 |       32
     28       6.673485e+05      -1.323110e+02 |       32
     29       6.672193e+05      -1.291413e+02 |       32
     30       6.671113e+05      -1.079763e+02 |       32
     31       6.670095e+05      -1.018890e+02 |       32
     32       6.668925e+05      -1.169441e+02 |       32
     33       6.667761e+05      -1.163868e+02 |       32
     34       6.666728e+05      -1.033400e+02 |       32
     35       6.665896e+05      -8.319933e+01 |       32
     36       6.665215e+05      -6.810620e+01 |       32
     37       6.664458e+05      -7.569337e+01 |       32
     38       6.663743e+05      -7.146299e+01 |       32
     39       6.663142e+05      -6.008611e+01 |       32
     40       6.662559e+05      -5.833348e+01 |       32
     41       6.662048e+05      -5.110786e+01 |       32
     42       6.661540e+05      -5.082342e+01 |       32
     43       6.661013e+05      -5.268724e+01 |       32
     44       6.660536e+05      -4.766339e+01 |       32
     45       6.660087e+05      -4.495497e+01 |       32
     46       6.659669e+05      -4.176923e+01 |       32
     47       6.659257e+05      -4.118183e+01 |       32
     48       6.658844e+05      -4.134012e+01 |       32
     49       6.658458e+05      -3.855558e+01 |       32
     50       6.658052e+05      -4.064508e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 665805.1738970444)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.416757
INFO: iteration 2, average log likelihood -1.411610
INFO: iteration 3, average log likelihood -1.410106
INFO: iteration 4, average log likelihood -1.408926
INFO: iteration 5, average log likelihood -1.407788
INFO: iteration 6, average log likelihood -1.406910
INFO: iteration 7, average log likelihood -1.406399
INFO: iteration 8, average log likelihood -1.406132
INFO: iteration 9, average log likelihood -1.405977
INFO: iteration 10, average log likelihood -1.405871
INFO: iteration 11, average log likelihood -1.405789
INFO: iteration 12, average log likelihood -1.405720
INFO: iteration 13, average log likelihood -1.405661
INFO: iteration 14, average log likelihood -1.405608
INFO: iteration 15, average log likelihood -1.405559
INFO: iteration 16, average log likelihood -1.405515
INFO: iteration 17, average log likelihood -1.405473
INFO: iteration 18, average log likelihood -1.405434
INFO: iteration 19, average log likelihood -1.405397
INFO: iteration 20, average log likelihood -1.405363
INFO: iteration 21, average log likelihood -1.405330
INFO: iteration 22, average log likelihood -1.405298
INFO: iteration 23, average log likelihood -1.405269
INFO: iteration 24, average log likelihood -1.405241
INFO: iteration 25, average log likelihood -1.405214
INFO: iteration 26, average log likelihood -1.405189
INFO: iteration 27, average log likelihood -1.405165
INFO: iteration 28, average log likelihood -1.405142
INFO: iteration 29, average log likelihood -1.405120
INFO: iteration 30, average log likelihood -1.405100
INFO: iteration 31, average log likelihood -1.405080
INFO: iteration 32, average log likelihood -1.405061
INFO: iteration 33, average log likelihood -1.405043
INFO: iteration 34, average log likelihood -1.405026
INFO: iteration 35, average log likelihood -1.405009
INFO: iteration 36, average log likelihood -1.404994
INFO: iteration 37, average log likelihood -1.404979
INFO: iteration 38, average log likelihood -1.404964
INFO: iteration 39, average log likelihood -1.404950
INFO: iteration 40, average log likelihood -1.404936
INFO: iteration 41, average log likelihood -1.404923
INFO: iteration 42, average log likelihood -1.404910
INFO: iteration 43, average log likelihood -1.404898
INFO: iteration 44, average log likelihood -1.404886
INFO: iteration 45, average log likelihood -1.404874
INFO: iteration 46, average log likelihood -1.404862
INFO: iteration 47, average log likelihood -1.404851
INFO: iteration 48, average log likelihood -1.404840
INFO: iteration 49, average log likelihood -1.404829
INFO: iteration 50, average log likelihood -1.404818
INFO: EM with 100000 data points 50 iterations avll -1.404818
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.478675   -0.497231   -0.299026    â€¦  -0.919792   -0.181731    0.0828117 
 -0.327284   -0.0489132  -0.234727       -0.450995   -0.48669    -0.00277014
 -0.392381    0.15088    -0.334266        0.169823   -0.113053   -0.241001  
  0.0821041  -0.169481   -0.0172279       0.0666724  -0.293194   -0.318129  
  0.362862   -0.280347   -0.532069       -0.179845   -0.247824    0.204256  
 -0.0805765  -0.128013    0.22554     â€¦  -0.577266    0.232189    0.0263538 
 -0.222153   -0.253652   -0.240786        0.396591    0.634614    0.025125  
  0.390709    0.259412   -0.00408986     -0.213287   -0.4773      0.129393  
 -0.592857   -0.544918   -0.0745643       0.573344   -0.048794   -0.180978  
  0.269246    0.257927    0.157391        0.264965    0.0826631   0.0407595 
  â‹®                                   â‹±                           â‹®         
  0.296887   -0.340573   -0.258885       -0.0645843   0.134034    0.450842  
 -0.217248   -0.144382   -0.0508976       0.372117    0.668818   -0.0628854 
  0.628925    0.157563   -0.430559    â€¦   0.310194    0.253729   -0.292497  
 -0.23754     0.0824681   0.658689        0.206035    0.710384    0.19066   
 -0.487179   -0.148227   -0.144178       -0.81383     0.519597   -0.037505  
 -0.195442    0.0432742   0.0275685      -0.161428    0.0530158  -0.602028  
  0.241809    0.0539385   0.353419        0.519952    0.209637   -0.158745  
  0.530742    0.413436   -0.19434     â€¦   0.467102    0.801429    0.597192  
 -0.734282   -0.550958    0.0817902      -0.453464   -0.699355   -0.242389  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.404807
INFO: iteration 2, average log likelihood -1.404796
INFO: iteration 3, average log likelihood -1.404786
INFO: iteration 4, average log likelihood -1.404776
INFO: iteration 5, average log likelihood -1.404765
INFO: iteration 6, average log likelihood -1.404755
INFO: iteration 7, average log likelihood -1.404745
INFO: iteration 8, average log likelihood -1.404735
INFO: iteration 9, average log likelihood -1.404725
INFO: iteration 10, average log likelihood -1.404716
INFO: EM with 100000 data points 10 iterations avll -1.404716
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
