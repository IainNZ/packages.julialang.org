>>> 'Pkg.add("GaussianMixtures")' log
INFO: Installing BinDeps v0.4.7
INFO: Installing Blosc v0.2.1
INFO: Installing Calculus v0.2.2
INFO: Installing Clustering v0.7.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.11.1
INFO: Installing FileIO v0.2.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.7.3
INFO: Installing JLD v0.6.11
INFO: Installing LegacyStrings v0.2.2
INFO: Installing NearestNeighbors v0.0.5
INFO: Installing PDMats v0.6.0
INFO: Installing Rmath v0.1.7
INFO: Installing SHA v0.3.3
INFO: Installing ScikitLearnBase v0.2.2
INFO: Installing StatsBase v0.12.0
INFO: Installing StatsFuns v0.4.0
INFO: Installing URIParser v0.1.8
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.4.7
Commit ae26b25 (2016-09-18 16:17 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-121-generic #170-Ubuntu SMP Wed Jun 14 09:04:33 UTC 2017 x86_64 x86_64
Memory: 2.9392738342285156 GB (723.5546875 MB free)
Uptime: 33522.0 sec
Load Avg:  0.90185546875  0.96142578125  0.95947265625
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    1626472 s       5373 s     114208 s    1265605 s         55 s
#2  3500 MHz    1073609 s         63 s      98760 s    2042410 s          3 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.4
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.9.1
19 additional packages:
 - BinDeps                       0.4.7
 - Blosc                         0.2.1
 - Calculus                      0.2.2
 - Clustering                    0.7.0
 - Compat                        0.26.0
 - Distances                     0.3.2
 - Distributions                 0.11.1
 - FileIO                        0.2.2
 - HDF5                          0.7.3
 - JLD                           0.6.11
 - LegacyStrings                 0.2.2
 - NearestNeighbors              0.0.5
 - PDMats                        0.6.0
 - Rmath                         0.1.7
 - SHA                           0.3.3
 - ScikitLearnBase               0.2.2
 - StatsBase                     0.12.0
 - StatsFuns                     0.4.0
 - URIParser                     0.1.8
INFO: Testing GaussianMixtures
INFO: Testing Data
(100000,-658060.7296193013,[94222.24927059836,5777.750729401653],
[-7306.871519058057 -5667.4495912686825 2392.8245980266015
 7147.762680944619 5270.042490560038 -2871.164113329488],

[
[87941.47912134507 -5906.581074980246 2610.600969559742
 -5906.581074980247 87227.63182207284 -1709.9533563151178
 2610.600969559742 -1709.9533563151176 93087.00141398502],

[11573.203965963628 5653.269933746807 -2239.101113692766
 5653.269933746807 12970.220336735389 1687.723038150125
 -2239.101113692766 1687.723038150125 6885.35746094773]])
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       2.315325e+03
      1       1.323063e+03      -9.922620e+02 |        8
      2       1.257548e+03      -6.551513e+01 |        4
      3       1.216214e+03      -4.133397e+01 |        0
      4       1.216214e+03       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 1216.214132168474)
INFO: K-means with 272 data points using 4 iterations
11.3 data points per parameter
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
INFO: EM with 272 data points 0 iterations avll -2.083069
5.8 data points per parameter
INFO: iteration 1, lowerbound -3.902329
INFO: iteration 2, lowerbound -3.831755
INFO: iteration 3, lowerbound -3.758341
INFO: iteration 4, lowerbound -3.657404
INFO: iteration 5, lowerbound -3.530819
INFO: iteration 6, lowerbound -3.393843
INFO: iteration 7, lowerbound -3.268409
INFO: dropping number of Gaussions to 7
INFO: iteration 8, lowerbound -3.155226
INFO: dropping number of Gaussions to 6
INFO: iteration 9, lowerbound -3.052172
INFO: dropping number of Gaussions to 5
INFO: iteration 10, lowerbound -2.946891
INFO: iteration 11, lowerbound -2.849743
INFO: dropping number of Gaussions to 4
INFO: iteration 12, lowerbound -2.761015
INFO: iteration 13, lowerbound -2.673820
INFO: iteration 14, lowerbound -2.598286
INFO: iteration 15, lowerbound -2.536150
INFO: iteration 16, lowerbound -2.490409
INFO: dropping number of Gaussions to 3
INFO: iteration 17, lowerbound -2.444069
INFO: iteration 18, lowerbound -2.403442
INFO: iteration 19, lowerbound -2.370292
INFO: iteration 20, lowerbound -2.340996
INFO: iteration 21, lowerbound -2.318490
INFO: iteration 22, lowerbound -2.307854
INFO: dropping number of Gaussions to 2
INFO: iteration 23, lowerbound -2.303030
INFO: iteration 24, lowerbound -2.299262
INFO: iteration 25, lowerbound -2.299257
INFO: iteration 26, lowerbound -2.299255
INFO: iteration 27, lowerbound -2.299254
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
[Tue 01 Aug 2017 01:30:28 PM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Tue 01 Aug 2017 01:30:29 PM UTC: K-means with 272 data points using 4 iterations
11.3 data points per parameter
,Tue 01 Aug 2017 01:30:31 PM UTC: EM with 272 data points 0 iterations avll -2.083069
5.8 data points per parameter
,Tue 01 Aug 2017 01:30:32 PM UTC: GMM converted to Variational GMM
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 1, lowerbound -3.902329
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 2, lowerbound -3.831755
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 3, lowerbound -3.758341
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 4, lowerbound -3.657404
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 5, lowerbound -3.530819
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 6, lowerbound -3.393843
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 7, lowerbound -3.268409
,Tue 01 Aug 2017 01:30:34 PM UTC: dropping number of Gaussions to 7
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 8, lowerbound -3.155226
,Tue 01 Aug 2017 01:30:34 PM UTC: dropping number of Gaussions to 6
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 9, lowerbound -3.052172
,Tue 01 Aug 2017 01:30:34 PM UTC: dropping number of Gaussions to 5
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 10, lowerbound -2.946891
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 11, lowerbound -2.849743
,Tue 01 Aug 2017 01:30:34 PM UTC: dropping number of Gaussions to 4
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 12, lowerbound -2.761015
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 13, lowerbound -2.673820
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 14, lowerbound -2.598286
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 15, lowerbound -2.536150
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 16, lowerbound -2.490409
,Tue 01 Aug 2017 01:30:34 PM UTC: dropping number of Gaussions to 3
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 17, lowerbound -2.444069
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 18, lowerbound -2.403442
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 19, lowerbound -2.370292
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 20, lowerbound -2.340996
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 21, lowerbound -2.318490
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 22, lowerbound -2.307854
,Tue 01 Aug 2017 01:30:34 PM UTC: dropping number of Gaussions to 2
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 23, lowerbound -2.303030
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 24, lowerbound -2.299262
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 25, lowerbound -2.299257
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 26, lowerbound -2.299255
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 27, lowerbound -2.299254
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 28, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 29, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 30, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 31, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 32, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 33, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 34, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 35, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 36, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 37, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 38, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 39, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 40, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 41, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 42, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 43, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 44, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 45, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 46, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 47, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 48, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 49, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: iteration 50, lowerbound -2.299253
,Tue 01 Aug 2017 01:30:34 PM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [95.95490777397804,178.04509222602195]
Î² = [95.95490777397804,178.04509222602195]
m = [2.000229257775302 53.851987172460944
 4.250300733269845 79.28686694436087]
Î½ = [97.95490777397804,180.04509222602195]
W = [
[0.3758763611949496 -0.00895312382734729
 0.0 0.012748664777409751],

[0.1840415554748387 -0.007644049042328411
 0.0 0.008581705166332285]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -0.983636291376039
avll from llpg:  -0.9836362913761707
avll direct:     -0.9836362913761707
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9831505289633035
avll from llpg:  -0.9831505289633035
avll direct:     -0.9831505289633035
sum posterior: 100000.0
32x26 Array{Float64,2}:
  0.289432    0.0725847  -0.0951998    â€¦  -0.0219124   -4.25513e-5
 -0.0345407  -0.153738    0.0590641       -0.0844527    0.0941722 
  0.0358382  -0.213719   -0.000357557      0.0630683    0.00142351
 -0.0104994   0.0352793   0.0503343        0.0741939    0.0634332 
  0.0794519  -0.0252808  -0.0605797       -0.0437185    0.133489  
  0.0576368  -0.0373565   0.101967     â€¦  -0.01123      0.0534084 
 -0.116912   -0.134028   -0.0416252       -0.192818     0.122017  
 -0.140997    0.106179    0.0702689        0.161464    -0.00658789
 -0.0130219  -0.0652855   0.0339454       -0.0739646    0.23535   
  0.100808   -0.0112849   0.0233185       -0.0177836    0.0915311 
  â‹®                                    â‹±                â‹®         
 -0.0118879   0.174376   -0.0304622       -0.0860252   -0.0471125 
  0.0891129  -0.089944    0.0662597        0.0968744   -0.0285408 
 -0.065783    0.0204598  -0.175072     â€¦  -0.00537945   0.120392  
 -0.0385824  -0.0550279   0.0107717        0.0769984    0.0979407 
 -0.121214   -0.0386069   0.0821473        0.0744044   -0.122893  
  0.203893    0.0696613  -0.0656119        0.0269746   -0.188794  
 -0.0217983   0.0458511   0.152394        -0.0404829   -0.101408  
 -0.0432573  -0.20779    -0.167487     â€¦  -0.0191559    0.0760509 
  0.0600175  -0.0241531   0.311971        -0.293533    -0.0463557 kind diag, method split
0: avll = -1.4019729081036945
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.402076
INFO: iteration 2, average log likelihood -1.401970
INFO: iteration 3, average log likelihood -1.400996
INFO: iteration 4, average log likelihood -1.390767
INFO: iteration 5, average log likelihood -1.368671
INFO: iteration 6, average log likelihood -1.362642
INFO: iteration 7, average log likelihood -1.361699
INFO: iteration 8, average log likelihood -1.361113
INFO: iteration 9, average log likelihood -1.360591
INFO: iteration 10, average log likelihood -1.360125
INFO: iteration 11, average log likelihood -1.359821
INFO: iteration 12, average log likelihood -1.359642
INFO: iteration 13, average log likelihood -1.359531
INFO: iteration 14, average log likelihood -1.359458
INFO: iteration 15, average log likelihood -1.359406
INFO: iteration 16, average log likelihood -1.359365
INFO: iteration 17, average log likelihood -1.359331
INFO: iteration 18, average log likelihood -1.359304
INFO: iteration 19, average log likelihood -1.359280
INFO: iteration 20, average log likelihood -1.359261
INFO: iteration 21, average log likelihood -1.359244
INFO: iteration 22, average log likelihood -1.359230
INFO: iteration 23, average log likelihood -1.359217
INFO: iteration 24, average log likelihood -1.359205
INFO: iteration 25, average log likelihood -1.359194
INFO: iteration 26, average log likelihood -1.359183
INFO: iteration 27, average log likelihood -1.359172
INFO: iteration 28, average log likelihood -1.359158
INFO: iteration 29, average log likelihood -1.359140
INFO: iteration 30, average log likelihood -1.359117
INFO: iteration 31, average log likelihood -1.359086
INFO: iteration 32, average log likelihood -1.359050
INFO: iteration 33, average log likelihood -1.359010
INFO: iteration 34, average log likelihood -1.358970
INFO: iteration 35, average log likelihood -1.358930
INFO: iteration 36, average log likelihood -1.358892
INFO: iteration 37, average log likelihood -1.358858
INFO: iteration 38, average log likelihood -1.358826
INFO: iteration 39, average log likelihood -1.358797
INFO: iteration 40, average log likelihood -1.358772
INFO: iteration 41, average log likelihood -1.358751
INFO: iteration 42, average log likelihood -1.358733
INFO: iteration 43, average log likelihood -1.358720
INFO: iteration 44, average log likelihood -1.358710
INFO: iteration 45, average log likelihood -1.358702
INFO: iteration 46, average log likelihood -1.358696
INFO: iteration 47, average log likelihood -1.358692
INFO: iteration 48, average log likelihood -1.358688
INFO: iteration 49, average log likelihood -1.358685
INFO: iteration 50, average log likelihood -1.358683
INFO: EM with 100000 data points 50 iterations avll -1.358683
952.4 data points per parameter
1: avll = [-1.4020760941975534,-1.4019696687862566,-1.4009960132120765,-1.3907671240749833,-1.3686710082655986,-1.362641713670889,-1.3616988510243337,-1.3611132298322595,-1.3605908813458003,-1.3601252882424764,-1.3598210002762623,-1.3596423579743344,-1.359531498037684,-1.359458108669863,-1.3594055417606554,-1.3593647203196635,-1.3593314095882745,-1.3593035502782254,-1.3592801487419295,-1.3592606248604675,-1.3592441239126016,-1.3592298233867097,-1.359217081115616,-1.3592054057096157,-1.3591943246811926,-1.3591832763683451,-1.3591715109071554,-1.3591578845469048,-1.3591404995687042,-1.3591167840432297,-1.3590858131900019,-1.3590495311836321,-1.359010408093617,-1.3589702791866252,-1.358930177836747,-1.3588922114335857,-1.3588577944678117,-1.3588263986585978,-1.3587973975576095,-1.3587718100852404,-1.35875052211336,-1.3587334485349916,-1.3587201637889577,-1.3587099954657664,-1.3587021977653135,-1.3586961822171961,-1.3586915394845067,-1.3586879718109681,-1.3586852453272489,-1.3586831717537304]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.358836
INFO: iteration 2, average log likelihood -1.358709
INFO: iteration 3, average log likelihood -1.358190
INFO: iteration 4, average log likelihood -1.352532
INFO: iteration 5, average log likelihood -1.334389
INFO: iteration 6, average log likelihood -1.321646
INFO: iteration 7, average log likelihood -1.317232
INFO: iteration 8, average log likelihood -1.314327
INFO: iteration 9, average log likelihood -1.311935
INFO: iteration 10, average log likelihood -1.310218
INFO: iteration 11, average log likelihood -1.309165
INFO: iteration 12, average log likelihood -1.308588
INFO: iteration 13, average log likelihood -1.308223
INFO: iteration 14, average log likelihood -1.307929
INFO: iteration 15, average log likelihood -1.307651
INFO: iteration 16, average log likelihood -1.307362
INFO: iteration 17, average log likelihood -1.307056
INFO: iteration 18, average log likelihood -1.306722
INFO: iteration 19, average log likelihood -1.306387
INFO: iteration 20, average log likelihood -1.306113
INFO: iteration 21, average log likelihood -1.305956
INFO: iteration 22, average log likelihood -1.305870
INFO: iteration 23, average log likelihood -1.305816
INFO: iteration 24, average log likelihood -1.305778
INFO: iteration 25, average log likelihood -1.305751
INFO: iteration 26, average log likelihood -1.305732
INFO: iteration 27, average log likelihood -1.305719
INFO: iteration 28, average log likelihood -1.305710
INFO: iteration 29, average log likelihood -1.305703
INFO: iteration 30, average log likelihood -1.305699
INFO: iteration 31, average log likelihood -1.305697
INFO: iteration 32, average log likelihood -1.305695
INFO: iteration 33, average log likelihood -1.305694
INFO: iteration 34, average log likelihood -1.305693
INFO: iteration 35, average log likelihood -1.305693
INFO: iteration 36, average log likelihood -1.305693
INFO: iteration 37, average log likelihood -1.305692
INFO: iteration 38, average log likelihood -1.305692
INFO: iteration 39, average log likelihood -1.305692
INFO: iteration 40, average log likelihood -1.305692
INFO: iteration 41, average log likelihood -1.305692
INFO: iteration 42, average log likelihood -1.305692
INFO: iteration 43, average log likelihood -1.305692
INFO: iteration 44, average log likelihood -1.305692
INFO: iteration 45, average log likelihood -1.305692
INFO: iteration 46, average log likelihood -1.305692
INFO: iteration 47, average log likelihood -1.305692
INFO: iteration 48, average log likelihood -1.305692
INFO: iteration 49, average log likelihood -1.305692
INFO: iteration 50, average log likelihood -1.305692
INFO: EM with 100000 data points 50 iterations avll -1.305692
473.9 data points per parameter
2: avll = [-1.3588355136200252,-1.3587086357559415,-1.3581900230233965,-1.352532048676354,-1.3343890977135884,-1.3216461824144743,-1.3172322881650889,-1.3143271374118732,-1.3119346786136366,-1.3102176473802558,-1.309165363393954,-1.3085879943896206,-1.3082232391126996,-1.3079293931290374,-1.3076513489852801,-1.3073619858983716,-1.3070559270459234,-1.3067215959789027,-1.3063870125338752,-1.3061129134578466,-1.3059563123269184,-1.3058704199391564,-1.3058157910756918,-1.30577784722937,-1.3057509033084957,-1.3057318466417556,-1.3057185661715385,-1.3057095060597153,-1.3057034503356932,-1.3056994603884289,-1.3056968516209957,-1.3056951505518843,-1.30569404093672,-1.3056933155691508,-1.30569283991204,-1.3056925268855393,-1.3056923201132562,-1.3056921830179478,-1.3056920917917714,-1.3056920308798645,-1.3056919900785624,-1.3056919626672139,-1.3056919442015733,-1.305691931731459,-1.305691923291376,-1.3056919175674129,-1.3056919136784775,-1.3056919110320198,-1.3056919092284889,-1.3056919079978326]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.305868
INFO: iteration 2, average log likelihood -1.305696
INFO: iteration 3, average log likelihood -1.304873
INFO: iteration 4, average log likelihood -1.296567
INFO: iteration 5, average log likelihood -1.275768
INFO: iteration 6, average log likelihood -1.263397
INFO: iteration 7, average log likelihood -1.257678
INFO: iteration 8, average log likelihood -1.252406
INFO: iteration 9, average log likelihood -1.247819
INFO: iteration 10, average log likelihood -1.245693
INFO: iteration 11, average log likelihood -1.244876
INFO: iteration 12, average log likelihood -1.244514
INFO: iteration 13, average log likelihood -1.244324
INFO: iteration 14, average log likelihood -1.244201
INFO: iteration 15, average log likelihood -1.244110
INFO: iteration 16, average log likelihood -1.244038
INFO: iteration 17, average log likelihood -1.243980
INFO: iteration 18, average log likelihood -1.243932
INFO: iteration 19, average log likelihood -1.243891
INFO: iteration 20, average log likelihood -1.243854
INFO: iteration 21, average log likelihood -1.243822
INFO: iteration 22, average log likelihood -1.243794
INFO: iteration 23, average log likelihood -1.243769
INFO: iteration 24, average log likelihood -1.243747
INFO: iteration 25, average log likelihood -1.243726
INFO: iteration 26, average log likelihood -1.243707
INFO: iteration 27, average log likelihood -1.243689
INFO: iteration 28, average log likelihood -1.243671
INFO: iteration 29, average log likelihood -1.243654
INFO: iteration 30, average log likelihood -1.243638
INFO: iteration 31, average log likelihood -1.243622
INFO: iteration 32, average log likelihood -1.243607
INFO: iteration 33, average log likelihood -1.243591
INFO: iteration 34, average log likelihood -1.243574
INFO: iteration 35, average log likelihood -1.243558
INFO: iteration 36, average log likelihood -1.243540
INFO: iteration 37, average log likelihood -1.243522
INFO: iteration 38, average log likelihood -1.243502
INFO: iteration 39, average log likelihood -1.243480
INFO: iteration 40, average log likelihood -1.243455
INFO: iteration 41, average log likelihood -1.243428
INFO: iteration 42, average log likelihood -1.243399
INFO: iteration 43, average log likelihood -1.243372
INFO: iteration 44, average log likelihood -1.243346
INFO: iteration 45, average log likelihood -1.243320
INFO: iteration 46, average log likelihood -1.243295
INFO: iteration 47, average log likelihood -1.243273
INFO: iteration 48, average log likelihood -1.243252
INFO: iteration 49, average log likelihood -1.243233
INFO: iteration 50, average log likelihood -1.243217
INFO: EM with 100000 data points 50 iterations avll -1.243217
236.4 data points per parameter
3: avll = [-1.3058683893634135,-1.3056958153202556,-1.3048726614914612,-1.2965673590738496,-1.2757679340764263,-1.2633965426425773,-1.2576780567661145,-1.2524064791117175,-1.247819078082853,-1.245692879406199,-1.2448755836841232,-1.2445136268143202,-1.2443237874965376,-1.2442007745893908,-1.2441095530325508,-1.2440383609163956,-1.2439803918011119,-1.243932100134133,-1.243890662470613,-1.2438543158627782,-1.2438222929679246,-1.243794074415421,-1.2437690595800157,-1.2437465139376989,-1.2437258507007796,-1.2437066864400905,-1.243688619342447,-1.2436712838821564,-1.2436544779038723,-1.243638172360525,-1.2436222815189943,-1.2436065490091563,-1.2435906788616864,-1.2435744686163406,-1.2435577373039135,-1.243540291749777,-1.2435218432116106,-1.2435019141990866,-1.2434798945698449,-1.243455031113597,-1.2434275462543543,-1.2433994674160582,-1.243372128546116,-1.2433456926964324,-1.2433200026816549,-1.2432954084586234,-1.2432726542342432,-1.2432520658613653,-1.2432334796733133,-1.2432168174695644]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.243453
INFO: iteration 2, average log likelihood -1.243166
INFO: iteration 3, average log likelihood -1.241932
INFO: iteration 4, average log likelihood -1.226668
WARNING: Variances had to be floored 7
INFO: iteration 5, average log likelihood -1.183135
WARNING: Variances had to be floored 8
INFO: iteration 6, average log likelihood -1.153329
WARNING: Variances had to be floored 7 16
INFO: iteration 7, average log likelihood -1.153765
WARNING: Variances had to be floored 9
INFO: iteration 8, average log likelihood -1.157377
WARNING: Variances had to be floored 7 8
INFO: iteration 9, average log likelihood -1.148579
WARNING: Variances had to be floored 16
INFO: iteration 10, average log likelihood -1.158253
INFO: iteration 11, average log likelihood -1.158992
WARNING: Variances had to be floored 7
INFO: iteration 12, average log likelihood -1.139716
WARNING: Variances had to be floored 8 16
INFO: iteration 13, average log likelihood -1.135863
WARNING: Variances had to be floored 7 9
INFO: iteration 14, average log likelihood -1.159475
INFO: iteration 15, average log likelihood -1.157290
WARNING: Variances had to be floored 7 8 16
INFO: iteration 16, average log likelihood -1.137897
INFO: iteration 17, average log likelihood -1.166149
INFO: iteration 18, average log likelihood -1.148820
WARNING: Variances had to be floored 7 9 16
INFO: iteration 19, average log likelihood -1.134087
WARNING: Variances had to be floored 8
INFO: iteration 20, average log likelihood -1.157007
WARNING: Variances had to be floored 7
INFO: iteration 21, average log likelihood -1.157007
WARNING: Variances had to be floored 16
INFO: iteration 22, average log likelihood -1.145025
WARNING: Variances had to be floored 7 8
INFO: iteration 23, average log likelihood -1.144398
WARNING: Variances had to be floored 9
INFO: iteration 24, average log likelihood -1.154287
WARNING: Variances had to be floored 16
INFO: iteration 25, average log likelihood -1.152916
WARNING: Variances had to be floored 7
INFO: iteration 26, average log likelihood -1.150042
WARNING: Variances had to be floored 8
INFO: iteration 27, average log likelihood -1.140132
WARNING: Variances had to be floored 7 16
INFO: iteration 28, average log likelihood -1.147242
WARNING: Variances had to be floored 9
INFO: iteration 29, average log likelihood -1.152418
WARNING: Variances had to be floored 7 8
INFO: iteration 30, average log likelihood -1.144884
WARNING: Variances had to be floored 16
INFO: iteration 31, average log likelihood -1.155300
INFO: iteration 32, average log likelihood -1.156365
WARNING: Variances had to be floored 7 16
INFO: iteration 33, average log likelihood -1.137138
WARNING: Variances had to be floored 8 9
INFO: iteration 34, average log likelihood -1.144705
WARNING: Variances had to be floored 7
INFO: iteration 35, average log likelihood -1.160316
WARNING: Variances had to be floored 16
INFO: iteration 36, average log likelihood -1.146131
WARNING: Variances had to be floored 7 8
INFO: iteration 37, average log likelihood -1.144679
INFO: iteration 38, average log likelihood -1.154321
WARNING: Variances had to be floored 7 9 16
INFO: iteration 39, average log likelihood -1.141379
INFO: iteration 40, average log likelihood -1.159006
WARNING: Variances had to be floored 7 8
INFO: iteration 41, average log likelihood -1.138084
WARNING: Variances had to be floored 16
INFO: iteration 42, average log likelihood -1.152089
WARNING: Variances had to be floored 7
INFO: iteration 43, average log likelihood -1.154120
WARNING: Variances had to be floored 9
INFO: iteration 44, average log likelihood -1.140600
WARNING: Variances had to be floored 7 8 16
INFO: iteration 45, average log likelihood -1.138873
INFO: iteration 46, average log likelihood -1.166428
WARNING: Variances had to be floored 7
INFO: iteration 47, average log likelihood -1.147914
WARNING: Variances had to be floored 16
INFO: iteration 48, average log likelihood -1.137734
WARNING: Variances had to be floored 7 8 9
INFO: iteration 49, average log likelihood -1.140057
INFO: iteration 50, average log likelihood -1.163427
INFO: EM with 100000 data points 50 iterations avll -1.163427
118.1 data points per parameter
4: avll = [-1.243453106606283,-1.2431655085238316,-1.2419320230712974,-1.2266681266869919,-1.1831348253291134,-1.1533285906920006,-1.1537653041760827,-1.1573766746345198,-1.1485789370052586,-1.1582531309301722,-1.1589918627748779,-1.1397157338929942,-1.1358626256251343,-1.1594754565845176,-1.1572899835450305,-1.1378966077187225,-1.1661487096908543,-1.1488203189021178,-1.1340871352783022,-1.1570072147685984,-1.157006541530595,-1.1450249600721456,-1.1443981797384641,-1.154286774772525,-1.1529157694388397,-1.1500415726799325,-1.1401320923954248,-1.147242280110949,-1.1524175670242807,-1.1448838690806942,-1.1552997490877632,-1.1563654818255436,-1.1371379175344911,-1.1447050696189123,-1.1603157097841499,-1.1461308977863216,-1.14467916344525,-1.1543212785803154,-1.1413789642818164,-1.1590062841842463,-1.138083953534356,-1.152088742906511,-1.1541200705113688,-1.1406000934597913,-1.1388732484104802,-1.1664276399715807,-1.1479138606355401,-1.137734031041943,-1.1400572495878907,-1.1634270427978308]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 13 14 31 32
INFO: iteration 1, average log likelihood -1.146961
WARNING: Variances had to be floored 13 14 31 32
INFO: iteration 2, average log likelihood -1.136120
WARNING: Variances had to be floored 13 14 15 16 31 32
INFO: iteration 3, average log likelihood -1.128357
WARNING: Variances had to be floored 5 13 14 17 31 32
INFO: iteration 4, average log likelihood -1.116577
WARNING: Variances had to be floored 13 14 18 31 32
INFO: iteration 5, average log likelihood -1.073630
WARNING: Variances had to be floored 4 5 6 13 14 15 16 31 32
INFO: iteration 6, average log likelihood -1.044929
WARNING: Variances had to be floored 13 14 21 31 32
INFO: iteration 7, average log likelihood -1.069055
WARNING: Variances had to be floored 5 13 14 15 16 18 24 31 32
INFO: iteration 8, average log likelihood -1.037179
WARNING: Variances had to be floored 2 4 5 6 13 14 31 32
INFO: iteration 9, average log likelihood -1.034070
WARNING: Variances had to be floored 11 13 14 15 16 31 32
INFO: iteration 10, average log likelihood -1.036270
WARNING: Variances had to be floored 5 13 14 17 18 21 24 31 32
INFO: iteration 11, average log likelihood -1.027269
WARNING: Variances had to be floored 4 6 13 14 15 16 31 32
INFO: iteration 12, average log likelihood -1.048145
WARNING: Variances had to be floored 2 5 13 14 31 32
INFO: iteration 13, average log likelihood -1.047212
WARNING: Variances had to be floored 13 14 15 16 18 24 31 32
INFO: iteration 14, average log likelihood -1.025934
WARNING: Variances had to be floored 4 5 6 11 13 14 17 21 31 32
INFO: iteration 15, average log likelihood -1.021009
WARNING: Variances had to be floored 13 14 15 16 31 32
INFO: iteration 16, average log likelihood -1.060929
WARNING: Variances had to be floored 2 5 13 14 18 24 31 32
INFO: iteration 17, average log likelihood -1.032843
WARNING: Variances had to be floored 4 6 13 14 15 16 31 32
INFO: iteration 18, average log likelihood -1.032646
WARNING: Variances had to be floored 5 13 14 17 21 31 32
INFO: iteration 19, average log likelihood -1.033477
WARNING: Variances had to be floored 13 14 15 16 18 24 31 32
INFO: iteration 20, average log likelihood -1.034994
WARNING: Variances had to be floored 2 4 5 6 11 13 14 31 32
INFO: iteration 21, average log likelihood -1.027177
WARNING: Variances had to be floored 13 14 15 16 31 32
INFO: iteration 22, average log likelihood -1.046730
WARNING: Variances had to be floored 5 13 14 17 18 21 24 31 32
INFO: iteration 23, average log likelihood -1.021774
WARNING: Variances had to be floored 4 6 13 14 15 16 31 32
INFO: iteration 24, average log likelihood -1.046512
WARNING: Variances had to be floored 2 5 13 14 31 32
INFO: iteration 25, average log likelihood -1.045315
WARNING: Variances had to be floored 11 13 14 15 16 18 24 31 32
INFO: iteration 26, average log likelihood -1.023720
WARNING: Variances had to be floored 4 5 6 13 14 17 21 31 32
INFO: iteration 27, average log likelihood -1.031238
WARNING: Variances had to be floored 13 14 15 16 31 32
INFO: iteration 28, average log likelihood -1.056985
WARNING: Variances had to be floored 2 5 13 14 18 24 31 32
INFO: iteration 29, average log likelihood -1.029340
WARNING: Variances had to be floored 4 6 13 14 15 16 31 32
INFO: iteration 30, average log likelihood -1.029777
WARNING: Variances had to be floored 5 11 13 14 17 21 31 32
INFO: iteration 31, average log likelihood -1.030078
WARNING: Variances had to be floored 13 14 16 18 24 31 32
INFO: iteration 32, average log likelihood -1.043052
WARNING: Variances had to be floored 2 4 5 6 13 14 15 31 32
INFO: iteration 33, average log likelihood -1.023602
WARNING: Variances had to be floored 13 14 31 32
INFO: iteration 34, average log likelihood -1.050625
WARNING: Variances had to be floored 5 13 14 15 17 18 21 24 31 32
INFO: iteration 35, average log likelihood -1.010847
WARNING: Variances had to be floored 4 6 13 14 31 32
INFO: iteration 36, average log likelihood -1.048460
WARNING: Variances had to be floored 2 5 11 13 14 15 16 31 32
INFO: iteration 37, average log likelihood -1.017835
WARNING: Variances had to be floored 13 14 18 24 31 32
INFO: iteration 38, average log likelihood -1.044142
WARNING: Variances had to be floored 4 5 6 13 14 15 17 21 31 32
INFO: iteration 39, average log likelihood -1.018961
WARNING: Variances had to be floored 13 14 31 32
INFO: iteration 40, average log likelihood -1.063105
WARNING: Variances had to be floored 2 5 13 14 16 18 24 31 32
INFO: iteration 41, average log likelihood -1.017783
WARNING: Variances had to be floored 4 6 11 13 14 31 32
INFO: iteration 42, average log likelihood -1.036714
WARNING: Variances had to be floored 5 13 14 15 17 21 31 32
INFO: iteration 43, average log likelihood -1.029727
WARNING: Variances had to be floored 13 14 16 18 24 31 32
INFO: iteration 44, average log likelihood -1.040568
WARNING: Variances had to be floored 2 4 5 6 13 14 31 32
INFO: iteration 45, average log likelihood -1.031654
WARNING: Variances had to be floored 13 14 16 31 32
INFO: iteration 46, average log likelihood -1.038497
WARNING: Variances had to be floored 5 11 13 14 17 18 21 24 31 32
INFO: iteration 47, average log likelihood -1.014603
WARNING: Variances had to be floored 4 6 13 14 15 16 31 32
INFO: iteration 48, average log likelihood -1.040759
WARNING: Variances had to be floored 2 5 13 14 31 32
INFO: iteration 49, average log likelihood -1.051275
WARNING: Variances had to be floored 13 14 16 18 24 31 32
INFO: iteration 50, average log likelihood -1.031685
INFO: EM with 100000 data points 50 iterations avll -1.031685
59.0 data points per parameter
5: avll = [-1.1469614901695226,-1.1361199224402994,-1.1283568330782323,-1.1165765764105502,-1.073630348476796,-1.0449291323659222,-1.069055209463286,-1.0371787303912046,-1.0340697325539867,-1.0362695261078396,-1.027269114312192,-1.0481454300814659,-1.0472120971655685,-1.0259342056446954,-1.021008781589171,-1.060929338677344,-1.0328429905245198,-1.0326456966220212,-1.0334769115646791,-1.0349941200370367,-1.0271774808719625,-1.0467300058566553,-1.021773688775601,-1.046511983843166,-1.0453154411289955,-1.0237202573853,-1.0312383783450196,-1.0569846377969483,-1.0293395555166909,-1.029777493187917,-1.0300780759882555,-1.0430515456438103,-1.0236015963056078,-1.0506252560181895,-1.0108472758525957,-1.0484598041912316,-1.0178346014390562,-1.0441424548803242,-1.0189610648623475,-1.0631046376703335,-1.0177831516791926,-1.0367136590229662,-1.0297272486017348,-1.040567691776224,-1.0316544147936262,-1.0384967679120682,-1.0146029199913396,-1.040758859378765,-1.0512748184901601,-1.0316846661822057]
[-1.4019729081036945,-1.4020760941975534,-1.4019696687862566,-1.4009960132120765,-1.3907671240749833,-1.3686710082655986,-1.362641713670889,-1.3616988510243337,-1.3611132298322595,-1.3605908813458003,-1.3601252882424764,-1.3598210002762623,-1.3596423579743344,-1.359531498037684,-1.359458108669863,-1.3594055417606554,-1.3593647203196635,-1.3593314095882745,-1.3593035502782254,-1.3592801487419295,-1.3592606248604675,-1.3592441239126016,-1.3592298233867097,-1.359217081115616,-1.3592054057096157,-1.3591943246811926,-1.3591832763683451,-1.3591715109071554,-1.3591578845469048,-1.3591404995687042,-1.3591167840432297,-1.3590858131900019,-1.3590495311836321,-1.359010408093617,-1.3589702791866252,-1.358930177836747,-1.3588922114335857,-1.3588577944678117,-1.3588263986585978,-1.3587973975576095,-1.3587718100852404,-1.35875052211336,-1.3587334485349916,-1.3587201637889577,-1.3587099954657664,-1.3587021977653135,-1.3586961822171961,-1.3586915394845067,-1.3586879718109681,-1.3586852453272489,-1.3586831717537304,-1.3588355136200252,-1.3587086357559415,-1.3581900230233965,-1.352532048676354,-1.3343890977135884,-1.3216461824144743,-1.3172322881650889,-1.3143271374118732,-1.3119346786136366,-1.3102176473802558,-1.309165363393954,-1.3085879943896206,-1.3082232391126996,-1.3079293931290374,-1.3076513489852801,-1.3073619858983716,-1.3070559270459234,-1.3067215959789027,-1.3063870125338752,-1.3061129134578466,-1.3059563123269184,-1.3058704199391564,-1.3058157910756918,-1.30577784722937,-1.3057509033084957,-1.3057318466417556,-1.3057185661715385,-1.3057095060597153,-1.3057034503356932,-1.3056994603884289,-1.3056968516209957,-1.3056951505518843,-1.30569404093672,-1.3056933155691508,-1.30569283991204,-1.3056925268855393,-1.3056923201132562,-1.3056921830179478,-1.3056920917917714,-1.3056920308798645,-1.3056919900785624,-1.3056919626672139,-1.3056919442015733,-1.305691931731459,-1.305691923291376,-1.3056919175674129,-1.3056919136784775,-1.3056919110320198,-1.3056919092284889,-1.3056919079978326,-1.3058683893634135,-1.3056958153202556,-1.3048726614914612,-1.2965673590738496,-1.2757679340764263,-1.2633965426425773,-1.2576780567661145,-1.2524064791117175,-1.247819078082853,-1.245692879406199,-1.2448755836841232,-1.2445136268143202,-1.2443237874965376,-1.2442007745893908,-1.2441095530325508,-1.2440383609163956,-1.2439803918011119,-1.243932100134133,-1.243890662470613,-1.2438543158627782,-1.2438222929679246,-1.243794074415421,-1.2437690595800157,-1.2437465139376989,-1.2437258507007796,-1.2437066864400905,-1.243688619342447,-1.2436712838821564,-1.2436544779038723,-1.243638172360525,-1.2436222815189943,-1.2436065490091563,-1.2435906788616864,-1.2435744686163406,-1.2435577373039135,-1.243540291749777,-1.2435218432116106,-1.2435019141990866,-1.2434798945698449,-1.243455031113597,-1.2434275462543543,-1.2433994674160582,-1.243372128546116,-1.2433456926964324,-1.2433200026816549,-1.2432954084586234,-1.2432726542342432,-1.2432520658613653,-1.2432334796733133,-1.2432168174695644,-1.243453106606283,-1.2431655085238316,-1.2419320230712974,-1.2266681266869919,-1.1831348253291134,-1.1533285906920006,-1.1537653041760827,-1.1573766746345198,-1.1485789370052586,-1.1582531309301722,-1.1589918627748779,-1.1397157338929942,-1.1358626256251343,-1.1594754565845176,-1.1572899835450305,-1.1378966077187225,-1.1661487096908543,-1.1488203189021178,-1.1340871352783022,-1.1570072147685984,-1.157006541530595,-1.1450249600721456,-1.1443981797384641,-1.154286774772525,-1.1529157694388397,-1.1500415726799325,-1.1401320923954248,-1.147242280110949,-1.1524175670242807,-1.1448838690806942,-1.1552997490877632,-1.1563654818255436,-1.1371379175344911,-1.1447050696189123,-1.1603157097841499,-1.1461308977863216,-1.14467916344525,-1.1543212785803154,-1.1413789642818164,-1.1590062841842463,-1.138083953534356,-1.152088742906511,-1.1541200705113688,-1.1406000934597913,-1.1388732484104802,-1.1664276399715807,-1.1479138606355401,-1.137734031041943,-1.1400572495878907,-1.1634270427978308,-1.1469614901695226,-1.1361199224402994,-1.1283568330782323,-1.1165765764105502,-1.073630348476796,-1.0449291323659222,-1.069055209463286,-1.0371787303912046,-1.0340697325539867,-1.0362695261078396,-1.027269114312192,-1.0481454300814659,-1.0472120971655685,-1.0259342056446954,-1.021008781589171,-1.060929338677344,-1.0328429905245198,-1.0326456966220212,-1.0334769115646791,-1.0349941200370367,-1.0271774808719625,-1.0467300058566553,-1.021773688775601,-1.046511983843166,-1.0453154411289955,-1.0237202573853,-1.0312383783450196,-1.0569846377969483,-1.0293395555166909,-1.029777493187917,-1.0300780759882555,-1.0430515456438103,-1.0236015963056078,-1.0506252560181895,-1.0108472758525957,-1.0484598041912316,-1.0178346014390562,-1.0441424548803242,-1.0189610648623475,-1.0631046376703335,-1.0177831516791926,-1.0367136590229662,-1.0297272486017348,-1.040567691776224,-1.0316544147936262,-1.0384967679120682,-1.0146029199913396,-1.040758859378765,-1.0512748184901601,-1.0316846661822057]
32x26 Array{Float64,2}:
  0.0390997    0.0121798  -0.0606066   â€¦   0.0943972    0.10206   
  0.00798879   0.203189   -0.0491589      -0.0763397   -0.0229632 
  0.0785274    0.0996543   0.0253959      -0.00957602  -0.0404599 
  0.0579924   -0.0839225   0.0655288       0.0744837   -0.0281374 
 -0.0175505   -0.0703638   0.00585484     -0.073966     0.233292  
  0.0848178   -0.0262451  -0.0401874   â€¦  -0.0418333    0.132507  
  0.116074    -0.125066    0.156274       -0.00425041   0.0786853 
 -0.0700728   -0.0254941  -0.129913       -0.00960793   0.109442  
  0.0960966   -0.0946573   0.0325536      -0.0379278   -0.0673215 
  0.110907    -0.0249132  -0.115274        0.0269434   -0.0887638 
  â‹®                                    â‹±                â‹®         
  0.0324363   -0.233878   -0.0809942       0.067831     0.00153422
 -0.110441    -0.145227    0.135984       -0.230513     0.219546  
 -0.128031    -0.12145    -0.260105    â€¦  -0.201414    -0.00916342
  0.0352917   -0.0181314   0.101215       -0.0517563    0.00462264
  0.0909872   -0.0479356   0.110751        0.0614702    0.0666758 
 -0.0211059    0.0446503   0.150501       -0.0375584   -0.150973  
 -0.00467876   0.0348107   0.161474       -0.0434347   -0.114002  
  0.00544566   0.0575895  -0.0580595   â€¦   0.115178    -0.142657  
 -0.0187896    0.158277   -0.0568745       0.105906    -0.107909  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 4 5 6 13 14 21 31 32
INFO: iteration 1, average log likelihood -1.023115
WARNING: Variances had to be floored 4 5 6 13 14 15 17 21 31 32
INFO: iteration 2, average log likelihood -0.994226
WARNING: Variances had to be floored 2 4 5 6 11 13 14 18 21 24 31 32
INFO: iteration 3, average log likelihood -0.988507
WARNING: Variances had to be floored 4 5 6 13 14 15 16 17 21 31 32
INFO: iteration 4, average log likelihood -1.010686
WARNING: Variances had to be floored 4 5 6 11 13 14 21 31 32
INFO: iteration 5, average log likelihood -1.000101
WARNING: Variances had to be floored 2 4 5 6 13 14 15 17 18 21 24 31 32
INFO: iteration 6, average log likelihood -0.985126
WARNING: Variances had to be floored 4 5 6 13 14 16 21 31 32
INFO: iteration 7, average log likelihood -1.013379
WARNING: Variances had to be floored 4 5 6 11 13 14 15 17 21 31 32
INFO: iteration 8, average log likelihood -0.991756
WARNING: Variances had to be floored 2 4 5 6 13 14 18 21 24 31 32
INFO: iteration 9, average log likelihood -0.992013
WARNING: Variances had to be floored 4 5 6 11 13 14 15 16 17 21 31 32
INFO: iteration 10, average log likelihood -1.003079
INFO: EM with 100000 data points 10 iterations avll -1.003079
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.351917e+05
      1       6.644549e+05      -1.707369e+05 |       32
      2       6.323319e+05      -3.212293e+04 |       32
      3       6.189397e+05      -1.339225e+04 |       32
      4       6.110591e+05      -7.880622e+03 |       32
      5       6.069506e+05      -4.108423e+03 |       32
      6       6.049168e+05      -2.033804e+03 |       32
      7       6.038175e+05      -1.099294e+03 |       32
      8       6.028834e+05      -9.340920e+02 |       32
      9       6.018175e+05      -1.065941e+03 |       32
     10       6.006871e+05      -1.130401e+03 |       32
     11       5.996065e+05      -1.080635e+03 |       32
     12       5.987998e+05      -8.066858e+02 |       32
     13       5.979840e+05      -8.157929e+02 |       32
     14       5.970592e+05      -9.248344e+02 |       32
     15       5.962114e+05      -8.477999e+02 |       32
     16       5.954827e+05      -7.286158e+02 |       32
     17       5.949021e+05      -5.806432e+02 |       32
     18       5.944335e+05      -4.686240e+02 |       32
     19       5.939812e+05      -4.522735e+02 |       32
     20       5.935917e+05      -3.894884e+02 |       32
     21       5.933004e+05      -2.913310e+02 |       32
     22       5.930335e+05      -2.668808e+02 |       32
     23       5.928153e+05      -2.182268e+02 |       32
     24       5.925995e+05      -2.157214e+02 |       32
     25       5.924294e+05      -1.701231e+02 |       32
     26       5.922960e+05      -1.334332e+02 |       32
     27       5.921745e+05      -1.214585e+02 |       32
     28       5.920716e+05      -1.029174e+02 |       32
     29       5.919804e+05      -9.117235e+01 |       32
     30       5.918887e+05      -9.171398e+01 |       32
     31       5.917745e+05      -1.141939e+02 |       32
     32       5.916589e+05      -1.155860e+02 |       31
     33       5.915277e+05      -1.312074e+02 |       31
     34       5.913960e+05      -1.317297e+02 |       32
     35       5.912755e+05      -1.205055e+02 |       32
     36       5.911925e+05      -8.301128e+01 |       31
     37       5.911200e+05      -7.244904e+01 |       32
     38       5.910474e+05      -7.263948e+01 |       30
     39       5.909903e+05      -5.711112e+01 |       32
     40       5.909414e+05      -4.888835e+01 |       32
     41       5.908943e+05      -4.713976e+01 |       32
     42       5.908495e+05      -4.475325e+01 |       32
     43       5.908169e+05      -3.263924e+01 |       31
     44       5.907887e+05      -2.818752e+01 |       32
     45       5.907633e+05      -2.540001e+01 |       31
     46       5.907385e+05      -2.479003e+01 |       31
     47       5.907167e+05      -2.181990e+01 |       32
     48       5.906974e+05      -1.924410e+01 |       32
     49       5.906778e+05      -1.968193e+01 |       30
     50       5.906541e+05      -2.361755e+01 |       31
K-means terminated without convergence after 50 iterations (objv = 590654.1333950715)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.298135
INFO: iteration 2, average log likelihood -1.262787
INFO: iteration 3, average log likelihood -1.222482
INFO: iteration 4, average log likelihood -1.165729
WARNING: Variances had to be floored 10 17
INFO: iteration 5, average log likelihood -1.100851
WARNING: Variances had to be floored 21 22 24
INFO: iteration 6, average log likelihood -1.063826
WARNING: Variances had to be floored 3 14 16 26 30
INFO: iteration 7, average log likelihood -1.046372
WARNING: Variances had to be floored 1 2
INFO: iteration 8, average log likelihood -1.058855
WARNING: Variances had to be floored 5 10
INFO: iteration 9, average log likelihood -1.030507
WARNING: Variances had to be floored 15 17 21
INFO: iteration 10, average log likelihood -1.020975
WARNING: Variances had to be floored 14 22 24 26 30
INFO: iteration 11, average log likelihood -1.019153
WARNING: Variances had to be floored 2 3 5 10 23
INFO: iteration 12, average log likelihood -1.050721
WARNING: Variances had to be floored 1
INFO: iteration 13, average log likelihood -1.058879
WARNING: Variances had to be floored 15 17 21 26 28 30
INFO: iteration 14, average log likelihood -1.013145
WARNING: Variances had to be floored 14 22 24
INFO: iteration 15, average log likelihood -1.057226
WARNING: Variances had to be floored 2 3 5 10
INFO: iteration 16, average log likelihood -1.035933
WARNING: Variances had to be floored 1 17
INFO: iteration 17, average log likelihood -1.037831
WARNING: Variances had to be floored 15 21 22 26 29 30
INFO: iteration 18, average log likelihood -1.003974
WARNING: Variances had to be floored 10 14 24
INFO: iteration 19, average log likelihood -1.053390
WARNING: Variances had to be floored 2 3 5 17
INFO: iteration 20, average log likelihood -1.036770
WARNING: Variances had to be floored 1
INFO: iteration 21, average log likelihood -1.026760
WARNING: Variances had to be floored 10 15 21 22 26 28 29 30
INFO: iteration 22, average log likelihood -0.984416
WARNING: Variances had to be floored 14 24
INFO: iteration 23, average log likelihood -1.077767
WARNING: Variances had to be floored 2 3 5 17
INFO: iteration 24, average log likelihood -1.033925
WARNING: Variances had to be floored 1 10
INFO: iteration 25, average log likelihood -1.029433
WARNING: Variances had to be floored 15 21 22 26 29 30
INFO: iteration 26, average log likelihood -1.007670
WARNING: Variances had to be floored 14 24
INFO: iteration 27, average log likelihood -1.058148
WARNING: Variances had to be floored 2 3 5 10 17
INFO: iteration 28, average log likelihood -1.019175
WARNING: Variances had to be floored 1
INFO: iteration 29, average log likelihood -1.036232
WARNING: Variances had to be floored 15 21 22 26 28 29 30
INFO: iteration 30, average log likelihood -0.990363
WARNING: Variances had to be floored 10 14 24
INFO: iteration 31, average log likelihood -1.059375
WARNING: Variances had to be floored 2 3 5 17
INFO: iteration 32, average log likelihood -1.042619
WARNING: Variances had to be floored 1
INFO: iteration 33, average log likelihood -1.035534
WARNING: Variances had to be floored 10 15 21 22 26 29 30
INFO: iteration 34, average log likelihood -0.990296
WARNING: Variances had to be floored 14 24
INFO: iteration 35, average log likelihood -1.069740
WARNING: Variances had to be floored 2 3 5 17
INFO: iteration 36, average log likelihood -1.026014
WARNING: Variances had to be floored 1 10
INFO: iteration 37, average log likelihood -1.019636
WARNING: Variances had to be floored 15 21 22 26 28 29 30
INFO: iteration 38, average log likelihood -1.001646
WARNING: Variances had to be floored 14 24
INFO: iteration 39, average log likelihood -1.066203
WARNING: Variances had to be floored 2 3 5 10 17
INFO: iteration 40, average log likelihood -1.026732
WARNING: Variances had to be floored 1
INFO: iteration 41, average log likelihood -1.045118
WARNING: Variances had to be floored 15 21 22 26 29 30
INFO: iteration 42, average log likelihood -0.996742
WARNING: Variances had to be floored 10 14 24
INFO: iteration 43, average log likelihood -1.051397
WARNING: Variances had to be floored 2 3 5 17
INFO: iteration 44, average log likelihood -1.035102
WARNING: Variances had to be floored 1
INFO: iteration 45, average log likelihood -1.026749
WARNING: Variances had to be floored 10 15 21 22 26 28 29 30
INFO: iteration 46, average log likelihood -0.984396
WARNING: Variances had to be floored 14 24
INFO: iteration 47, average log likelihood -1.077766
WARNING: Variances had to be floored 2 3 5 17
INFO: iteration 48, average log likelihood -1.033920
WARNING: Variances had to be floored 1 10
INFO: iteration 49, average log likelihood -1.029430
WARNING: Variances had to be floored 15 21 22 26 29 30
INFO: iteration 50, average log likelihood -1.007664
INFO: EM with 100000 data points 50 iterations avll -1.007664
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.00262842   0.129284   -0.0601765   â€¦   0.123937    -0.154153  
 -0.0749382    0.0124637   0.00851345     -0.205938    -0.0529891 
 -0.0312984   -0.197743   -0.143389        0.00405559   0.076166  
  0.0987873   -0.0930024   0.0358094      -0.0346528   -0.0727353 
 -0.00215135   0.0787838   0.0334373       0.0759491    0.0575754 
  0.0408406    0.105845   -0.151983    â€¦   0.0130097   -0.109541  
  0.0907845    0.137635    0.243093        0.292987    -0.154532  
  0.0930731    0.145617    0.0412507      -0.0823018    0.0595665 
  0.223913     0.0746391  -0.064601        0.0561808   -0.201807  
  0.0337223   -0.239828   -0.090837        0.0758724    0.0138751 
  â‹®                                    â‹±                â‹®         
  0.0742472    0.216429    0.00504305      0.0646629    0.269029  
  0.0635936   -0.0318386   0.101668        0.0028073    0.0292359 
  0.269134     0.0735978  -0.0613879   â€¦  -0.0315054    0.00479323
  0.114929    -0.122449    0.15515        -0.00218282   0.0781765 
  0.0692939   -0.0174528   0.0276777      -0.00261129   0.0865314 
 -0.0674947    0.0398344  -0.174625       -0.00558686   0.121793  
  0.0655195   -0.0920269   0.0700725       0.0617679   -0.0286601 
 -0.0125053    0.0494247   0.142384    â€¦  -0.0399034   -0.148246  
  0.125278    -0.0340987  -0.110002       -0.0193393    0.0837014 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 14 24
INFO: iteration 1, average log likelihood -1.058143
WARNING: Variances had to be floored 2 3 5 10 14 17 24
INFO: iteration 2, average log likelihood -0.989207
WARNING: Variances had to be floored 1 2 3 10 14 15 17 21 22 24 26 28 30
INFO: iteration 3, average log likelihood -0.956131
WARNING: Variances had to be floored 5 14 24 29
INFO: iteration 4, average log likelihood -1.033543
WARNING: Variances had to be floored 2 3 10 14 17 24
INFO: iteration 5, average log likelihood -1.001905
WARNING: Variances had to be floored 1 2 3 5 10 14 15 17 21 22 24 26 28 30
INFO: iteration 6, average log likelihood -0.950641
WARNING: Variances had to be floored 14 24 29
INFO: iteration 7, average log likelihood -1.042627
WARNING: Variances had to be floored 2 3 5 10 14 17 24
INFO: iteration 8, average log likelihood -0.995006
WARNING: Variances had to be floored 1 2 3 10 14 15 17 21 22 24 26 28 30
INFO: iteration 9, average log likelihood -0.958626
WARNING: Variances had to be floored 5 14 24 29
INFO: iteration 10, average log likelihood -1.034399
INFO: EM with 100000 data points 10 iterations avll -1.034399
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.280804      0.0771614    0.0538101    â€¦   0.0552145    0.110668  
 -0.0548185     0.0413152    0.17621         -0.0255012   -0.028555  
  0.0893699     0.00228444  -0.000245496     -0.0977194    0.0352052 
  0.0617719    -0.159918    -0.00941414       0.158207     0.129766  
 -0.014308     -0.0108267   -0.0436017        0.0637415    0.00573997
 -0.117094      0.00247431  -0.175781     â€¦   0.0892168   -0.0759922 
  0.000463036  -0.0876558   -0.307801         0.039689    -0.141893  
  0.0496764    -0.125216    -0.0651008        0.0379221   -0.052759  
 -0.0645232     0.0822184   -0.133558        -0.157622    -0.0485532 
  0.109649      0.00552798  -0.0956541       -0.0361001   -0.0807828 
  â‹®                                       â‹±                â‹®         
 -0.182081     -0.101932     0.0958684        0.124614    -0.067157  
 -0.132184      0.0345041    0.145077         0.120709    -0.122215  
 -0.0042337     0.0218104    0.0223342    â€¦  -0.131712     0.210467  
 -0.087848      0.0486763    0.0108808       -0.00973187   0.158198  
  0.138844     -0.0618147    0.045078         0.179699    -0.0839644 
 -0.251675      0.0364354   -0.185427         0.151606     0.0041369 
  0.0652479    -0.0484766    0.130021        -0.206228     0.142421  
  0.0428731     0.15552     -0.000702305  â€¦   0.0916704   -0.168127  
  0.0299423     0.0940454    0.124797        -0.0850009    0.143068  kind full, method split
0: avll = -1.414897982369032
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.414918
INFO: iteration 2, average log likelihood -1.414852
INFO: iteration 3, average log likelihood -1.414806
INFO: iteration 4, average log likelihood -1.414754
INFO: iteration 5, average log likelihood -1.414690
INFO: iteration 6, average log likelihood -1.414601
INFO: iteration 7, average log likelihood -1.414453
INFO: iteration 8, average log likelihood -1.414168
INFO: iteration 9, average log likelihood -1.413602
INFO: iteration 10, average log likelihood -1.412646
INFO: iteration 11, average log likelihood -1.411475
INFO: iteration 12, average log likelihood -1.410532
INFO: iteration 13, average log likelihood -1.410020
INFO: iteration 14, average log likelihood -1.409803
INFO: iteration 15, average log likelihood -1.409719
INFO: iteration 16, average log likelihood -1.409687
INFO: iteration 17, average log likelihood -1.409673
INFO: iteration 18, average log likelihood -1.409668
INFO: iteration 19, average log likelihood -1.409665
INFO: iteration 20, average log likelihood -1.409664
INFO: iteration 21, average log likelihood -1.409663
INFO: iteration 22, average log likelihood -1.409662
INFO: iteration 23, average log likelihood -1.409661
INFO: iteration 24, average log likelihood -1.409661
INFO: iteration 25, average log likelihood -1.409661
INFO: iteration 26, average log likelihood -1.409660
INFO: iteration 27, average log likelihood -1.409660
INFO: iteration 28, average log likelihood -1.409660
INFO: iteration 29, average log likelihood -1.409659
INFO: iteration 30, average log likelihood -1.409659
INFO: iteration 31, average log likelihood -1.409659
INFO: iteration 32, average log likelihood -1.409659
INFO: iteration 33, average log likelihood -1.409658
INFO: iteration 34, average log likelihood -1.409658
INFO: iteration 35, average log likelihood -1.409658
INFO: iteration 36, average log likelihood -1.409658
INFO: iteration 37, average log likelihood -1.409658
INFO: iteration 38, average log likelihood -1.409658
INFO: iteration 39, average log likelihood -1.409658
INFO: iteration 40, average log likelihood -1.409657
INFO: iteration 41, average log likelihood -1.409657
INFO: iteration 42, average log likelihood -1.409657
INFO: iteration 43, average log likelihood -1.409657
INFO: iteration 44, average log likelihood -1.409657
INFO: iteration 45, average log likelihood -1.409657
INFO: iteration 46, average log likelihood -1.409657
INFO: iteration 47, average log likelihood -1.409657
INFO: iteration 48, average log likelihood -1.409657
INFO: iteration 49, average log likelihood -1.409657
INFO: iteration 50, average log likelihood -1.409657
INFO: EM with 100000 data points 50 iterations avll -1.409657
952.4 data points per parameter
1: avll = [-1.4149177129566761,-1.414851826802912,-1.4148055714524015,-1.4147537704885438,-1.4146898198961746,-1.4146007932669944,-1.4144533408017559,-1.4141676064159747,-1.4136018693733903,-1.4126461888371036,-1.4114747832359602,-1.410531732338953,-1.4100199566139417,-1.4098032595308732,-1.4097192272204766,-1.40968657879785,-1.409673426333036,-1.4096677967635507,-1.4096651386422772,-1.409663689711501,-1.4096627569834366,-1.409662063665336,-1.40966149673372,-1.4096610082162824,-1.4096605762685726,-1.4096601897245424,-1.4096598419230109,-1.4096595282191935,-1.4096592449674228,-1.4096589890943567,-1.4096587579108597,-1.409658549021475,-1.4096583602746422,-1.409658189730641,-1.409658035637833,-1.4096578964132973,-1.409657770626163,-1.409657656982877,-1.4096575543140073,-1.4096574615623598,-1.4096573777722436,-1.4096573020797645,-1.4096572337040472,-1.4096571719392879,-1.4096571161475702,-1.40965706575236,-1.4096570202326228,-1.4096569791175002,-1.4096569419814966,-1.4096569084401225]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.409676
INFO: iteration 2, average log likelihood -1.409609
INFO: iteration 3, average log likelihood -1.409563
INFO: iteration 4, average log likelihood -1.409513
INFO: iteration 5, average log likelihood -1.409457
INFO: iteration 6, average log likelihood -1.409396
INFO: iteration 7, average log likelihood -1.409333
INFO: iteration 8, average log likelihood -1.409273
INFO: iteration 9, average log likelihood -1.409219
INFO: iteration 10, average log likelihood -1.409175
INFO: iteration 11, average log likelihood -1.409140
INFO: iteration 12, average log likelihood -1.409113
INFO: iteration 13, average log likelihood -1.409092
INFO: iteration 14, average log likelihood -1.409076
INFO: iteration 15, average log likelihood -1.409062
INFO: iteration 16, average log likelihood -1.409050
INFO: iteration 17, average log likelihood -1.409038
INFO: iteration 18, average log likelihood -1.409026
INFO: iteration 19, average log likelihood -1.409013
INFO: iteration 20, average log likelihood -1.408999
INFO: iteration 21, average log likelihood -1.408983
INFO: iteration 22, average log likelihood -1.408965
INFO: iteration 23, average log likelihood -1.408945
INFO: iteration 24, average log likelihood -1.408924
INFO: iteration 25, average log likelihood -1.408902
INFO: iteration 26, average log likelihood -1.408879
INFO: iteration 27, average log likelihood -1.408856
INFO: iteration 28, average log likelihood -1.408834
INFO: iteration 29, average log likelihood -1.408813
INFO: iteration 30, average log likelihood -1.408794
INFO: iteration 31, average log likelihood -1.408777
INFO: iteration 32, average log likelihood -1.408762
INFO: iteration 33, average log likelihood -1.408749
INFO: iteration 34, average log likelihood -1.408738
INFO: iteration 35, average log likelihood -1.408729
INFO: iteration 36, average log likelihood -1.408721
INFO: iteration 37, average log likelihood -1.408715
INFO: iteration 38, average log likelihood -1.408709
INFO: iteration 39, average log likelihood -1.408704
INFO: iteration 40, average log likelihood -1.408699
INFO: iteration 41, average log likelihood -1.408695
INFO: iteration 42, average log likelihood -1.408691
INFO: iteration 43, average log likelihood -1.408687
INFO: iteration 44, average log likelihood -1.408684
INFO: iteration 45, average log likelihood -1.408681
INFO: iteration 46, average log likelihood -1.408677
INFO: iteration 47, average log likelihood -1.408674
INFO: iteration 48, average log likelihood -1.408672
INFO: iteration 49, average log likelihood -1.408669
INFO: iteration 50, average log likelihood -1.408666
INFO: EM with 100000 data points 50 iterations avll -1.408666
473.9 data points per parameter
2: avll = [-1.4096764379632891,-1.4096093293080578,-1.4095629773924792,-1.4095128812305862,-1.4094570127533466,-1.4093960423480332,-1.4093330827396993,-1.4092726541068714,-1.4092189832725246,-1.4091745357262486,-1.409139597710749,-1.4091128623556906,-1.4090923488016696,-1.4090760906171598,-1.4090624482018512,-1.4090501585803508,-1.4090382718734462,-1.4090260677444473,-1.4090129910259497,-1.4089986165252333,-1.4089826413149145,-1.4089648983193275,-1.408945381867234,-1.4089242725060034,-1.4089019460416585,-1.4088789531686257,-1.4088559632693292,-1.4088336782258168,-1.4088127347708115,-1.4087936204380513,-1.40877662434403,-1.4087618314340598,-1.4087491540728345,-1.408738385055355,-1.4087292544210237,-1.4087214771837855,-1.4087147861389755,-1.4087089497810323,-1.408703778606795,-1.4086991239378266,-1.408694872836626,-1.4086909416228608,-1.4086872694693724,-1.408683812794511,-1.4086805406877412,-1.4086774313468444,-1.4086744693906479,-1.4086716438790068,-1.4086689468800515,-1.4086663724490807]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.408677
INFO: iteration 2, average log likelihood -1.408624
INFO: iteration 3, average log likelihood -1.408584
INFO: iteration 4, average log likelihood -1.408541
INFO: iteration 5, average log likelihood -1.408492
INFO: iteration 6, average log likelihood -1.408437
INFO: iteration 7, average log likelihood -1.408374
INFO: iteration 8, average log likelihood -1.408304
INFO: iteration 9, average log likelihood -1.408231
INFO: iteration 10, average log likelihood -1.408156
INFO: iteration 11, average log likelihood -1.408082
INFO: iteration 12, average log likelihood -1.408014
INFO: iteration 13, average log likelihood -1.407954
INFO: iteration 14, average log likelihood -1.407901
INFO: iteration 15, average log likelihood -1.407857
INFO: iteration 16, average log likelihood -1.407819
INFO: iteration 17, average log likelihood -1.407787
INFO: iteration 18, average log likelihood -1.407759
INFO: iteration 19, average log likelihood -1.407735
INFO: iteration 20, average log likelihood -1.407714
INFO: iteration 21, average log likelihood -1.407694
INFO: iteration 22, average log likelihood -1.407677
INFO: iteration 23, average log likelihood -1.407660
INFO: iteration 24, average log likelihood -1.407645
INFO: iteration 25, average log likelihood -1.407631
INFO: iteration 26, average log likelihood -1.407618
INFO: iteration 27, average log likelihood -1.407605
INFO: iteration 28, average log likelihood -1.407593
INFO: iteration 29, average log likelihood -1.407581
INFO: iteration 30, average log likelihood -1.407570
INFO: iteration 31, average log likelihood -1.407560
INFO: iteration 32, average log likelihood -1.407549
INFO: iteration 33, average log likelihood -1.407539
INFO: iteration 34, average log likelihood -1.407529
INFO: iteration 35, average log likelihood -1.407519
INFO: iteration 36, average log likelihood -1.407509
INFO: iteration 37, average log likelihood -1.407499
INFO: iteration 38, average log likelihood -1.407489
INFO: iteration 39, average log likelihood -1.407479
INFO: iteration 40, average log likelihood -1.407469
INFO: iteration 41, average log likelihood -1.407459
INFO: iteration 42, average log likelihood -1.407449
INFO: iteration 43, average log likelihood -1.407438
INFO: iteration 44, average log likelihood -1.407428
INFO: iteration 45, average log likelihood -1.407417
INFO: iteration 46, average log likelihood -1.407406
INFO: iteration 47, average log likelihood -1.407395
INFO: iteration 48, average log likelihood -1.407384
INFO: iteration 49, average log likelihood -1.407372
INFO: iteration 50, average log likelihood -1.407361
INFO: EM with 100000 data points 50 iterations avll -1.407361
236.4 data points per parameter
3: avll = [-1.4086774860631666,-1.408624247797093,-1.408583983215976,-1.4085408967001818,-1.4084922245988905,-1.4084365563298753,-1.4083736319991305,-1.4083043330509788,-1.4082306518792487,-1.4081555133332238,-1.40808233095209,-1.4080142938714206,-1.4079536300940168,-1.407901222431506,-1.4078567456450077,-1.4078191435370742,-1.4077871269956934,-1.4077594973925702,-1.4077352783574058,-1.4077137263816835,-1.4076942910521206,-1.407676565986544,-1.407660246765942,-1.4076450994344114,-1.4076309384649404,-1.407617611989546,-1.4076049921886147,-1.407592969137821,-1.407581446853571,-1.4075703406734463,-1.4075595754210937,-1.4075490840277727,-1.4075388064277359,-1.4075286886326797,-1.4075186819414975,-1.407508742269878,-1.40749882959909,-1.4074889075500012,-1.4074789430903651,-1.4074689063826387,-1.4074587707772563,-1.4074485129528203,-1.4074381132000071,-1.4074275558395988,-1.4074168297559688,-1.4074059290146683,-1.4073948535158038,-1.407383609614338,-1.4073722106171997,-1.407360677051093]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.407358
INFO: iteration 2, average log likelihood -1.407298
INFO: iteration 3, average log likelihood -1.407244
INFO: iteration 4, average log likelihood -1.407185
INFO: iteration 5, average log likelihood -1.407118
INFO: iteration 6, average log likelihood -1.407040
INFO: iteration 7, average log likelihood -1.406952
INFO: iteration 8, average log likelihood -1.406857
INFO: iteration 9, average log likelihood -1.406759
INFO: iteration 10, average log likelihood -1.406662
INFO: iteration 11, average log likelihood -1.406569
INFO: iteration 12, average log likelihood -1.406483
INFO: iteration 13, average log likelihood -1.406405
INFO: iteration 14, average log likelihood -1.406335
INFO: iteration 15, average log likelihood -1.406272
INFO: iteration 16, average log likelihood -1.406217
INFO: iteration 17, average log likelihood -1.406167
INFO: iteration 18, average log likelihood -1.406123
INFO: iteration 19, average log likelihood -1.406084
INFO: iteration 20, average log likelihood -1.406049
INFO: iteration 21, average log likelihood -1.406017
INFO: iteration 22, average log likelihood -1.405988
INFO: iteration 23, average log likelihood -1.405962
INFO: iteration 24, average log likelihood -1.405938
INFO: iteration 25, average log likelihood -1.405915
INFO: iteration 26, average log likelihood -1.405894
INFO: iteration 27, average log likelihood -1.405874
INFO: iteration 28, average log likelihood -1.405856
INFO: iteration 29, average log likelihood -1.405838
INFO: iteration 30, average log likelihood -1.405820
INFO: iteration 31, average log likelihood -1.405804
INFO: iteration 32, average log likelihood -1.405787
INFO: iteration 33, average log likelihood -1.405772
INFO: iteration 34, average log likelihood -1.405757
INFO: iteration 35, average log likelihood -1.405742
INFO: iteration 36, average log likelihood -1.405728
INFO: iteration 37, average log likelihood -1.405714
INFO: iteration 38, average log likelihood -1.405700
INFO: iteration 39, average log likelihood -1.405687
INFO: iteration 40, average log likelihood -1.405674
INFO: iteration 41, average log likelihood -1.405661
INFO: iteration 42, average log likelihood -1.405649
INFO: iteration 43, average log likelihood -1.405637
INFO: iteration 44, average log likelihood -1.405625
INFO: iteration 45, average log likelihood -1.405614
INFO: iteration 46, average log likelihood -1.405603
INFO: iteration 47, average log likelihood -1.405592
INFO: iteration 48, average log likelihood -1.405582
INFO: iteration 49, average log likelihood -1.405572
INFO: iteration 50, average log likelihood -1.405562
INFO: EM with 100000 data points 50 iterations avll -1.405562
118.1 data points per parameter
4: avll = [-1.4073581921740563,-1.4072978403326415,-1.4072441203382349,-1.4071854662359664,-1.407118023111992,-1.4070400875400413,-1.4069522424115297,-1.4068572120882263,-1.4067590477299055,-1.40666195496821,-1.4065693530530128,-1.4064834597218001,-1.4064053265676737,-1.4063351209091883,-1.406272469043495,-1.406216737233323,-1.4061672048980924,-1.4061231469906068,-1.4060838653838121,-1.4060487013621012,-1.4060170448199816,-1.405988343580446,-1.4059621109787102,-1.405937929413777,-1.405915449106704,-1.4058943828534414,-1.4058744983280358,-1.4058556095021741,-1.4058375683400883,-1.405820257426256,-1.4058035837716114,-1.4057874737808278,-1.4057718692342471,-1.4057567241016822,-1.4057420020198912,-1.4057276742997773,-1.4057137183644468,-1.40570011654575,-1.4056868551818977,-1.4056739239627556,-1.4056613154658157,-1.4056490248199875,-1.4056370494326758,-1.4056253887231838,-1.405614043823137,-1.405603017227906,-1.4055923124044816,-1.4055819333748856,-1.4055718842980698,-1.4055621690696167]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.405561
INFO: iteration 2, average log likelihood -1.405498
INFO: iteration 3, average log likelihood -1.405435
INFO: iteration 4, average log likelihood -1.405360
INFO: iteration 5, average log likelihood -1.405265
INFO: iteration 6, average log likelihood -1.405147
INFO: iteration 7, average log likelihood -1.405006
INFO: iteration 8, average log likelihood -1.404848
INFO: iteration 9, average log likelihood -1.404682
INFO: iteration 10, average log likelihood -1.404517
INFO: iteration 11, average log likelihood -1.404362
INFO: iteration 12, average log likelihood -1.404222
INFO: iteration 13, average log likelihood -1.404099
INFO: iteration 14, average log likelihood -1.403994
INFO: iteration 15, average log likelihood -1.403905
INFO: iteration 16, average log likelihood -1.403829
INFO: iteration 17, average log likelihood -1.403764
INFO: iteration 18, average log likelihood -1.403708
INFO: iteration 19, average log likelihood -1.403659
INFO: iteration 20, average log likelihood -1.403616
INFO: iteration 21, average log likelihood -1.403577
INFO: iteration 22, average log likelihood -1.403542
INFO: iteration 23, average log likelihood -1.403510
INFO: iteration 24, average log likelihood -1.403480
INFO: iteration 25, average log likelihood -1.403453
INFO: iteration 26, average log likelihood -1.403428
INFO: iteration 27, average log likelihood -1.403405
INFO: iteration 28, average log likelihood -1.403383
INFO: iteration 29, average log likelihood -1.403362
INFO: iteration 30, average log likelihood -1.403342
INFO: iteration 31, average log likelihood -1.403323
INFO: iteration 32, average log likelihood -1.403304
INFO: iteration 33, average log likelihood -1.403286
INFO: iteration 34, average log likelihood -1.403269
INFO: iteration 35, average log likelihood -1.403252
INFO: iteration 36, average log likelihood -1.403235
INFO: iteration 37, average log likelihood -1.403219
INFO: iteration 38, average log likelihood -1.403203
INFO: iteration 39, average log likelihood -1.403188
INFO: iteration 40, average log likelihood -1.403173
INFO: iteration 41, average log likelihood -1.403158
INFO: iteration 42, average log likelihood -1.403144
INFO: iteration 43, average log likelihood -1.403130
INFO: iteration 44, average log likelihood -1.403116
INFO: iteration 45, average log likelihood -1.403103
INFO: iteration 46, average log likelihood -1.403090
INFO: iteration 47, average log likelihood -1.403078
INFO: iteration 48, average log likelihood -1.403066
INFO: iteration 49, average log likelihood -1.403055
INFO: iteration 50, average log likelihood -1.403043
INFO: EM with 100000 data points 50 iterations avll -1.403043
59.0 data points per parameter
5: avll = [-1.4055609362953123,-1.4054979338064535,-1.4054350034299026,-1.4053597050164055,-1.405265028431375,-1.4051470089097264,-1.405006153093616,-1.4048479677381882,-1.4046815125058723,-1.4045166612037292,-1.4043616342710061,-1.4042217396934487,-1.4040992838075201,-1.4039941859473615,-1.4039048441346906,-1.4038289445700336,-1.4037640593469265,-1.4037079984889516,-1.4036589577658267,-1.4036155319992187,-1.4035766589683134,-1.403541540273025,-1.4035095658875816,-1.403480254252234,-1.40345321035906,-1.4034280993551895,-1.4034046313832227,-1.40338255347794,-1.4033616453228466,-1.4033417168210767,-1.4033226063699427,-1.403304179336746,-1.4032863265552513,-1.403268962779291,-1.4032520250174179,-1.403235470604418,-1.4032192748282373,-1.403203427995892,-1.4031879319902236,-1.4031727965582388,-1.403158035679389,-1.4031436643462305,-1.4031296959826898,-1.4031161405904395,-1.4031030036044179,-1.4030902853785308,-1.4030779812056091,-1.4030660817733385,-1.4030545739449258,-1.4030434417298119]
[-1.414897982369032,-1.4149177129566761,-1.414851826802912,-1.4148055714524015,-1.4147537704885438,-1.4146898198961746,-1.4146007932669944,-1.4144533408017559,-1.4141676064159747,-1.4136018693733903,-1.4126461888371036,-1.4114747832359602,-1.410531732338953,-1.4100199566139417,-1.4098032595308732,-1.4097192272204766,-1.40968657879785,-1.409673426333036,-1.4096677967635507,-1.4096651386422772,-1.409663689711501,-1.4096627569834366,-1.409662063665336,-1.40966149673372,-1.4096610082162824,-1.4096605762685726,-1.4096601897245424,-1.4096598419230109,-1.4096595282191935,-1.4096592449674228,-1.4096589890943567,-1.4096587579108597,-1.409658549021475,-1.4096583602746422,-1.409658189730641,-1.409658035637833,-1.4096578964132973,-1.409657770626163,-1.409657656982877,-1.4096575543140073,-1.4096574615623598,-1.4096573777722436,-1.4096573020797645,-1.4096572337040472,-1.4096571719392879,-1.4096571161475702,-1.40965706575236,-1.4096570202326228,-1.4096569791175002,-1.4096569419814966,-1.4096569084401225,-1.4096764379632891,-1.4096093293080578,-1.4095629773924792,-1.4095128812305862,-1.4094570127533466,-1.4093960423480332,-1.4093330827396993,-1.4092726541068714,-1.4092189832725246,-1.4091745357262486,-1.409139597710749,-1.4091128623556906,-1.4090923488016696,-1.4090760906171598,-1.4090624482018512,-1.4090501585803508,-1.4090382718734462,-1.4090260677444473,-1.4090129910259497,-1.4089986165252333,-1.4089826413149145,-1.4089648983193275,-1.408945381867234,-1.4089242725060034,-1.4089019460416585,-1.4088789531686257,-1.4088559632693292,-1.4088336782258168,-1.4088127347708115,-1.4087936204380513,-1.40877662434403,-1.4087618314340598,-1.4087491540728345,-1.408738385055355,-1.4087292544210237,-1.4087214771837855,-1.4087147861389755,-1.4087089497810323,-1.408703778606795,-1.4086991239378266,-1.408694872836626,-1.4086909416228608,-1.4086872694693724,-1.408683812794511,-1.4086805406877412,-1.4086774313468444,-1.4086744693906479,-1.4086716438790068,-1.4086689468800515,-1.4086663724490807,-1.4086774860631666,-1.408624247797093,-1.408583983215976,-1.4085408967001818,-1.4084922245988905,-1.4084365563298753,-1.4083736319991305,-1.4083043330509788,-1.4082306518792487,-1.4081555133332238,-1.40808233095209,-1.4080142938714206,-1.4079536300940168,-1.407901222431506,-1.4078567456450077,-1.4078191435370742,-1.4077871269956934,-1.4077594973925702,-1.4077352783574058,-1.4077137263816835,-1.4076942910521206,-1.407676565986544,-1.407660246765942,-1.4076450994344114,-1.4076309384649404,-1.407617611989546,-1.4076049921886147,-1.407592969137821,-1.407581446853571,-1.4075703406734463,-1.4075595754210937,-1.4075490840277727,-1.4075388064277359,-1.4075286886326797,-1.4075186819414975,-1.407508742269878,-1.40749882959909,-1.4074889075500012,-1.4074789430903651,-1.4074689063826387,-1.4074587707772563,-1.4074485129528203,-1.4074381132000071,-1.4074275558395988,-1.4074168297559688,-1.4074059290146683,-1.4073948535158038,-1.407383609614338,-1.4073722106171997,-1.407360677051093,-1.4073581921740563,-1.4072978403326415,-1.4072441203382349,-1.4071854662359664,-1.407118023111992,-1.4070400875400413,-1.4069522424115297,-1.4068572120882263,-1.4067590477299055,-1.40666195496821,-1.4065693530530128,-1.4064834597218001,-1.4064053265676737,-1.4063351209091883,-1.406272469043495,-1.406216737233323,-1.4061672048980924,-1.4061231469906068,-1.4060838653838121,-1.4060487013621012,-1.4060170448199816,-1.405988343580446,-1.4059621109787102,-1.405937929413777,-1.405915449106704,-1.4058943828534414,-1.4058744983280358,-1.4058556095021741,-1.4058375683400883,-1.405820257426256,-1.4058035837716114,-1.4057874737808278,-1.4057718692342471,-1.4057567241016822,-1.4057420020198912,-1.4057276742997773,-1.4057137183644468,-1.40570011654575,-1.4056868551818977,-1.4056739239627556,-1.4056613154658157,-1.4056490248199875,-1.4056370494326758,-1.4056253887231838,-1.405614043823137,-1.405603017227906,-1.4055923124044816,-1.4055819333748856,-1.4055718842980698,-1.4055621690696167,-1.4055609362953123,-1.4054979338064535,-1.4054350034299026,-1.4053597050164055,-1.405265028431375,-1.4051470089097264,-1.405006153093616,-1.4048479677381882,-1.4046815125058723,-1.4045166612037292,-1.4043616342710061,-1.4042217396934487,-1.4040992838075201,-1.4039941859473615,-1.4039048441346906,-1.4038289445700336,-1.4037640593469265,-1.4037079984889516,-1.4036589577658267,-1.4036155319992187,-1.4035766589683134,-1.403541540273025,-1.4035095658875816,-1.403480254252234,-1.40345321035906,-1.4034280993551895,-1.4034046313832227,-1.40338255347794,-1.4033616453228466,-1.4033417168210767,-1.4033226063699427,-1.403304179336746,-1.4032863265552513,-1.403268962779291,-1.4032520250174179,-1.403235470604418,-1.4032192748282373,-1.403203427995892,-1.4031879319902236,-1.4031727965582388,-1.403158035679389,-1.4031436643462305,-1.4031296959826898,-1.4031161405904395,-1.4031030036044179,-1.4030902853785308,-1.4030779812056091,-1.4030660817733385,-1.4030545739449258,-1.4030434417298119]
32x26 Array{Float64,2}:
 -0.0800337    -0.10211    -0.155671   â€¦   0.232834    0.122623    0.499012 
 -0.447562     -0.462032   -0.766163       0.217199   -0.15361     0.132224 
  0.616626     -0.80863    -0.723851      -0.0684678  -0.820728   -0.552319 
 -0.0634431    -0.633256   -0.56168       -0.101359    0.280943    0.0309368
 -0.0194851    -1.02838     0.257243       0.498525    0.121934    0.0874781
  0.154052      0.604405   -0.0518921  â€¦  -0.0330071   0.790934   -0.151113 
  0.0889299    -0.0193652  -0.12973       -0.730753    0.6972      0.0426392
  0.0159186     0.245817   -0.242399      -0.434827    0.44816     0.0291948
  0.0544012    -0.491233   -0.196112      -0.145219    0.0219218   0.119197 
  0.159618     -0.0892369   0.42987        1.00779    -0.0523795  -0.189839 
  â‹®                                    â‹±                           â‹®        
  0.295404     -0.508391   -0.367127      -0.0813665   0.933431   -0.0500929
 -0.153445     -0.0422644  -0.0358276      0.0464646  -0.0382213   0.213515 
  0.0166589     0.101556    0.0869404  â€¦   0.0833542  -0.0142862   0.0260299
  0.148934     -0.1181     -0.320563      -0.0203144   0.235007   -0.255132 
  0.000349205   0.124938   -0.0790318     -0.362618    0.0607725  -0.417689 
 -0.27106      -0.172289    0.234249       0.185419   -0.433153   -0.0408266
  0.214801      0.462739    0.195088       0.108637   -0.507979   -0.12895  
  0.196425     -0.17673     0.129862   â€¦  -0.0852418   0.0669268   0.0894378
  0.359142     -0.120998   -0.0480749      0.371016   -0.384228   -0.240505 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.403033
INFO: iteration 2, average log likelihood -1.403022
INFO: iteration 3, average log likelihood -1.403012
INFO: iteration 4, average log likelihood -1.403002
INFO: iteration 5, average log likelihood -1.402993
INFO: iteration 6, average log likelihood -1.402984
INFO: iteration 7, average log likelihood -1.402974
INFO: iteration 8, average log likelihood -1.402966
INFO: iteration 9, average log likelihood -1.402957
INFO: iteration 10, average log likelihood -1.402949
INFO: EM with 100000 data points 10 iterations avll -1.402949
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.355758e+05
      1       6.928825e+05      -2.426933e+05 |       32
      2       6.811165e+05      -1.176596e+04 |       32
      3       6.760489e+05      -5.067632e+03 |       32
      4       6.733129e+05      -2.735941e+03 |       32
      5       6.716497e+05      -1.663280e+03 |       32
      6       6.704958e+05      -1.153900e+03 |       32
      7       6.696074e+05      -8.883550e+02 |       32
      8       6.688822e+05      -7.252477e+02 |       32
      9       6.683047e+05      -5.774781e+02 |       32
     10       6.678362e+05      -4.685245e+02 |       32
     11       6.674345e+05      -4.016850e+02 |       32
     12       6.670997e+05      -3.348237e+02 |       32
     13       6.668067e+05      -2.929351e+02 |       32
     14       6.665374e+05      -2.693278e+02 |       32
     15       6.662893e+05      -2.481221e+02 |       32
     16       6.660844e+05      -2.048947e+02 |       32
     17       6.658966e+05      -1.877637e+02 |       32
     18       6.657184e+05      -1.782484e+02 |       32
     19       6.655371e+05      -1.812268e+02 |       32
     20       6.653703e+05      -1.668096e+02 |       32
     21       6.652305e+05      -1.397968e+02 |       32
     22       6.650996e+05      -1.309188e+02 |       32
     23       6.649783e+05      -1.213045e+02 |       32
     24       6.648700e+05      -1.083442e+02 |       32
     25       6.647644e+05      -1.055951e+02 |       32
     26       6.646623e+05      -1.020925e+02 |       32
     27       6.645601e+05      -1.021810e+02 |       32
     28       6.644641e+05      -9.598284e+01 |       32
     29       6.643784e+05      -8.566546e+01 |       32
     30       6.643014e+05      -7.703756e+01 |       32
     31       6.642299e+05      -7.153625e+01 |       32
     32       6.641572e+05      -7.264521e+01 |       32
     33       6.640943e+05      -6.297604e+01 |       32
     34       6.640406e+05      -5.369745e+01 |       32
     35       6.639833e+05      -5.722284e+01 |       32
     36       6.639303e+05      -5.306424e+01 |       32
     37       6.638790e+05      -5.123205e+01 |       32
     38       6.638263e+05      -5.271118e+01 |       32
     39       6.637694e+05      -5.695105e+01 |       32
     40       6.637137e+05      -5.562370e+01 |       32
     41       6.636733e+05      -4.042352e+01 |       32
     42       6.636390e+05      -3.431039e+01 |       32
     43       6.636069e+05      -3.207639e+01 |       32
     44       6.635738e+05      -3.315831e+01 |       32
     45       6.635450e+05      -2.874929e+01 |       32
     46       6.635170e+05      -2.803295e+01 |       32
     47       6.634863e+05      -3.071842e+01 |       32
     48       6.634513e+05      -3.498255e+01 |       32
     49       6.634178e+05      -3.347692e+01 |       32
     50       6.633870e+05      -3.083269e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 663386.9864882914)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.415050
INFO: iteration 2, average log likelihood -1.409823
INFO: iteration 3, average log likelihood -1.408379
INFO: iteration 4, average log likelihood -1.407309
INFO: iteration 5, average log likelihood -1.406223
INFO: iteration 6, average log likelihood -1.405257
INFO: iteration 7, average log likelihood -1.404598
INFO: iteration 8, average log likelihood -1.404220
INFO: iteration 9, average log likelihood -1.404001
INFO: iteration 10, average log likelihood -1.403858
INFO: iteration 11, average log likelihood -1.403752
INFO: iteration 12, average log likelihood -1.403668
INFO: iteration 13, average log likelihood -1.403599
INFO: iteration 14, average log likelihood -1.403539
INFO: iteration 15, average log likelihood -1.403486
INFO: iteration 16, average log likelihood -1.403440
INFO: iteration 17, average log likelihood -1.403398
INFO: iteration 18, average log likelihood -1.403360
INFO: iteration 19, average log likelihood -1.403325
INFO: iteration 20, average log likelihood -1.403292
INFO: iteration 21, average log likelihood -1.403262
INFO: iteration 22, average log likelihood -1.403234
INFO: iteration 23, average log likelihood -1.403208
INFO: iteration 24, average log likelihood -1.403184
INFO: iteration 25, average log likelihood -1.403161
INFO: iteration 26, average log likelihood -1.403139
INFO: iteration 27, average log likelihood -1.403118
INFO: iteration 28, average log likelihood -1.403099
INFO: iteration 29, average log likelihood -1.403080
INFO: iteration 30, average log likelihood -1.403063
INFO: iteration 31, average log likelihood -1.403046
INFO: iteration 32, average log likelihood -1.403030
INFO: iteration 33, average log likelihood -1.403014
INFO: iteration 34, average log likelihood -1.402999
INFO: iteration 35, average log likelihood -1.402984
INFO: iteration 36, average log likelihood -1.402970
INFO: iteration 37, average log likelihood -1.402956
INFO: iteration 38, average log likelihood -1.402942
INFO: iteration 39, average log likelihood -1.402928
INFO: iteration 40, average log likelihood -1.402915
INFO: iteration 41, average log likelihood -1.402902
INFO: iteration 42, average log likelihood -1.402888
INFO: iteration 43, average log likelihood -1.402875
INFO: iteration 44, average log likelihood -1.402862
INFO: iteration 45, average log likelihood -1.402849
INFO: iteration 46, average log likelihood -1.402836
INFO: iteration 47, average log likelihood -1.402823
INFO: iteration 48, average log likelihood -1.402810
INFO: iteration 49, average log likelihood -1.402797
INFO: iteration 50, average log likelihood -1.402785
INFO: EM with 100000 data points 50 iterations avll -1.402785
59.0 data points per parameter
32x26 Array{Float64,2}:
  0.0322027    0.0549627  -0.188769   â€¦  -0.00732284  -0.0180544 
 -0.326554     0.285137    0.540749       0.261787     0.480777  
  0.0129495    0.696586   -0.0343435      0.748627     0.0593796 
 -0.763803     0.853675   -0.350697      -0.330115     0.101465  
 -0.0619849    0.840695    0.506698      -0.350189    -0.503782  
 -0.144865     0.0485879   0.316491   â€¦  -0.129915     0.00719432
 -0.234795     0.119406   -0.659874       0.114542    -0.252475  
 -0.0794994   -0.217896   -0.101692       0.15038      0.189945  
  0.101889    -0.354748   -0.181505       0.154593    -0.130032  
 -0.184147    -0.856135    0.278816       0.0255804    0.0774117 
  â‹®                                   â‹±                â‹®         
  0.112055     0.400538    0.368311      -0.214505     0.0937495 
 -0.19045     -0.0450062   0.146852      -0.0923467    0.30657   
 -0.76286     -0.382909    0.0332793  â€¦  -0.151083     0.825152  
  0.0400586    0.307807   -0.389168      -0.420349    -0.088915  
 -0.0115886   -0.316084   -0.0686975      0.104294    -0.154886  
 -0.120694     0.53501     0.521069       0.372685    -0.0260691 
 -0.392519     0.0200323   0.420264      -0.77733     -0.355118  
  0.601981    -0.38471    -0.353616   â€¦   0.863909     0.0538975 
  0.00941372   0.0245684  -0.0773771     -0.178573    -0.21299   INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.402772
INFO: iteration 2, average log likelihood -1.402760
INFO: iteration 3, average log likelihood -1.402748
INFO: iteration 4, average log likelihood -1.402736
INFO: iteration 5, average log likelihood -1.402725
INFO: iteration 6, average log likelihood -1.402714
INFO: iteration 7, average log likelihood -1.402703
INFO: iteration 8, average log likelihood -1.402692
INFO: iteration 9, average log likelihood -1.402682
INFO: iteration 10, average log likelihood -1.402673
INFO: EM with 100000 data points 10 iterations avll -1.402673
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
