>>> 'Pkg.add("GaussianMixtures")' log
INFO: Installing BinDeps v0.4.7
INFO: Installing Blosc v0.2.1
INFO: Installing Calculus v0.2.2
INFO: Installing Clustering v0.7.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.11.1
INFO: Installing FileIO v0.2.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.7.3
INFO: Installing JLD v0.6.11
INFO: Installing LegacyStrings v0.2.2
INFO: Installing NearestNeighbors v0.0.5
INFO: Installing PDMats v0.6.0
INFO: Installing Rmath v0.1.7
INFO: Installing SHA v0.3.3
INFO: Installing ScikitLearnBase v0.2.2
INFO: Installing StatsBase v0.12.0
INFO: Installing StatsFuns v0.4.0
INFO: Installing URIParser v0.1.8
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.4.7
Commit ae26b25 (2016-09-18 16:17 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-128-generic #177-Ubuntu SMP Tue Aug 8 11:40:23 UTC 2017 x86_64 x86_64
Memory: 2.9392738342285156 GB (591.42578125 MB free)
Uptime: 34413.0 sec
Load Avg:  0.87109375  0.93603515625  0.947265625
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3499 MHz    1578652 s       5500 s     125337 s    1397946 s         49 s
#2  3499 MHz    1152228 s       1279 s     113349 s    2050510 s          0 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.4
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.9.1
19 additional packages:
 - BinDeps                       0.4.7
 - Blosc                         0.2.1
 - Calculus                      0.2.2
 - Clustering                    0.7.0
 - Compat                        0.26.0
 - Distances                     0.3.2
 - Distributions                 0.11.1
 - FileIO                        0.2.2
 - HDF5                          0.7.3
 - JLD                           0.6.11
 - LegacyStrings                 0.2.2
 - NearestNeighbors              0.0.5
 - PDMats                        0.6.0
 - Rmath                         0.1.7
 - SHA                           0.3.3
 - ScikitLearnBase               0.2.2
 - StatsBase                     0.12.0
 - StatsFuns                     0.4.0
 - URIParser                     0.1.8
INFO: Testing GaussianMixtures
INFO: Testing Data
(100000,-1.3866862169151329e7,[3962.5301210881494,96037.46987891184],
[-5159.547440467122 5851.175006959375 3361.698276360902
 4733.752158559798 -5697.8129217458045 -3520.2964780483717],

[
[9619.79225706931 -5947.604997314117 -3764.6805332501335
 -5947.604997314117 11306.293397619573 3618.3684952386498
 -3764.6805332501335 3618.3684952386498 6870.217761912167],

[90888.8329495913 6507.590445030187 3677.536603686584
 6507.590445030187 88597.87033797876 -3474.3094578050986
 3677.5366036865844 -3474.3094578050986 92724.5852665567]])
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.327002e+03
      1       1.198824e+03      -1.281775e+02 |        4
      2       1.162917e+03      -3.590775e+01 |        2
      3       1.133212e+03      -2.970462e+01 |        3
      4       1.100978e+03      -3.223403e+01 |        2
      5       1.067234e+03      -3.374437e+01 |        2
      6       1.030729e+03      -3.650425e+01 |        4
      7       9.691591e+02      -6.157024e+01 |        0
      8       9.691591e+02       0.000000e+00 |        0
K-means converged with 8 iterations (objv = 969.1590899958119)
INFO: K-means with 272 data points using 8 iterations
11.3 data points per parameter
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
INFO: EM with 272 data points 0 iterations avll -2.068644
5.8 data points per parameter
INFO: iteration 1, lowerbound -3.895780
INFO: iteration 2, lowerbound -3.817816
INFO: iteration 3, lowerbound -3.735944
INFO: iteration 4, lowerbound -3.624965
INFO: iteration 5, lowerbound -3.481702
INFO: iteration 6, lowerbound -3.316341
INFO: dropping number of Gaussions to 7
INFO: iteration 7, lowerbound -3.137761
INFO: iteration 8, lowerbound -2.960195
INFO: dropping number of Gaussions to 6
INFO: iteration 9, lowerbound -2.794857
INFO: iteration 10, lowerbound -2.648991
INFO: dropping number of Gaussions to 5
INFO: iteration 11, lowerbound -2.532660
INFO: iteration 12, lowerbound -2.447818
INFO: iteration 13, lowerbound -2.400931
INFO: dropping number of Gaussions to 3
INFO: iteration 14, lowerbound -2.362025
INFO: iteration 15, lowerbound -2.328334
INFO: iteration 16, lowerbound -2.311309
INFO: iteration 17, lowerbound -2.307838
INFO: dropping number of Gaussions to 2
INFO: iteration 18, lowerbound -2.302917
INFO: iteration 19, lowerbound -2.299259
INFO: iteration 20, lowerbound -2.299256
INFO: iteration 21, lowerbound -2.299254
INFO: iteration 22, lowerbound -2.299254
INFO: iteration 23, lowerbound -2.299253
INFO: iteration 24, lowerbound -2.299253
INFO: iteration 25, lowerbound -2.299253
INFO: iteration 26, lowerbound -2.299253
INFO: iteration 27, lowerbound -2.299253
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
[Mon 21 Aug 2017 01:35:41 PM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Mon 21 Aug 2017 01:35:42 PM UTC: K-means with 272 data points using 8 iterations
11.3 data points per parameter
,Mon 21 Aug 2017 01:35:43 PM UTC: EM with 272 data points 0 iterations avll -2.068644
5.8 data points per parameter
,Mon 21 Aug 2017 01:35:43 PM UTC: GMM converted to Variational GMM
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 1, lowerbound -3.895780
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 2, lowerbound -3.817816
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 3, lowerbound -3.735944
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 4, lowerbound -3.624965
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 5, lowerbound -3.481702
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 6, lowerbound -3.316341
,Mon 21 Aug 2017 01:35:44 PM UTC: dropping number of Gaussions to 7
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 7, lowerbound -3.137761
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 8, lowerbound -2.960195
,Mon 21 Aug 2017 01:35:44 PM UTC: dropping number of Gaussions to 6
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 9, lowerbound -2.794857
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 10, lowerbound -2.648991
,Mon 21 Aug 2017 01:35:44 PM UTC: dropping number of Gaussions to 5
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 11, lowerbound -2.532660
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 12, lowerbound -2.447818
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 13, lowerbound -2.400931
,Mon 21 Aug 2017 01:35:44 PM UTC: dropping number of Gaussions to 3
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 14, lowerbound -2.362025
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 15, lowerbound -2.328334
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 16, lowerbound -2.311309
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 17, lowerbound -2.307838
,Mon 21 Aug 2017 01:35:44 PM UTC: dropping number of Gaussions to 2
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 18, lowerbound -2.302917
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 19, lowerbound -2.299259
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 20, lowerbound -2.299256
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 21, lowerbound -2.299254
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 22, lowerbound -2.299254
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 23, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 24, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 25, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 26, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 27, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 28, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 29, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 30, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 31, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 32, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 33, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 34, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 35, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 36, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 37, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 38, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 39, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 40, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 41, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 42, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 43, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 44, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 45, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 46, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 47, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 48, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 49, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: iteration 50, lowerbound -2.299253
,Mon 21 Aug 2017 01:35:44 PM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.04509222601374,95.95490777398624]
Î² = [178.04509222601374,95.95490777398624]
m = [4.250300733269912 79.28686694436186
 2.0002292577753713 53.85198717246131]
Î½ = [180.04509222601374,97.95490777398624]
W = [
[0.184041555474847 -0.007644049042327245
 0.0 0.008581705166333511],

[0.375876361194838 -0.0089531238273459
 0.0 0.012748664777409378]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000006
avll from stats: -1.0135529298912849
avll from llpg:  -1.0135529298912855
avll direct:     -1.0135529298912855
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0129094635997518
avll from llpg:  -1.0129094635997518
avll direct:     -1.0129094635997518
sum posterior: 100000.0
32x26 Array{Float64,2}:
 -0.0358132    -0.0297123    0.00906085  â€¦  -0.0771173  -0.0755597 
  0.0413008     0.191293    -0.26134         0.108457    0.0260069 
 -0.0954794    -0.11816      0.0631953       0.127754    0.0336637 
  0.0639717    -0.00822711  -0.0927037       0.0719155   0.128134  
  0.00142929   -0.0805772   -0.156951        0.0711947  -0.0217806 
  0.0190016    -0.0305166    0.357497    â€¦  -0.0501822   0.114856  
  0.127363     -0.0511774    0.200063        0.0597138   0.00810349
  0.143581     -0.00741238  -0.157818        0.0348191  -0.0208642 
  0.137676     -0.140777    -0.100737        0.0438721   0.109675  
 -0.11465      -0.0963315   -0.024832       -0.0184436  -0.0578476 
  â‹®                                      â‹±               â‹®         
  0.135493      0.0990156   -0.0920768       0.0292675   0.0262236 
  0.0515611    -0.116332    -0.00622012     -0.012761    0.0665701 
  0.0128113     0.033304    -0.0729988   â€¦   0.124549    0.0753703 
  0.0371977    -0.0598783    0.00477367      0.0869394  -0.129944  
  0.000890379  -0.0715525    0.0302029      -0.129807   -0.0940776 
  0.0300303     0.0813823    0.0297279      -0.0023824  -0.155655  
  0.108189     -0.0964679    0.15022        -0.0656006   0.0297316 
  0.102611     -0.0997859   -0.116091    â€¦   0.180942    0.00619468
  0.0530972    -0.100472    -0.0226667       0.0679317  -0.0775548 kind diag, method split
0: avll = -1.429091063655497
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.429196
INFO: iteration 2, average log likelihood -1.429079
INFO: iteration 3, average log likelihood -1.428012
INFO: iteration 4, average log likelihood -1.420376
INFO: iteration 5, average log likelihood -1.406545
INFO: iteration 6, average log likelihood -1.400998
INFO: iteration 7, average log likelihood -1.399289
INFO: iteration 8, average log likelihood -1.398126
INFO: iteration 9, average log likelihood -1.397218
INFO: iteration 10, average log likelihood -1.396569
INFO: iteration 11, average log likelihood -1.396080
INFO: iteration 12, average log likelihood -1.395707
INFO: iteration 13, average log likelihood -1.395421
INFO: iteration 14, average log likelihood -1.395180
INFO: iteration 15, average log likelihood -1.394907
INFO: iteration 16, average log likelihood -1.394321
INFO: iteration 17, average log likelihood -1.393165
INFO: iteration 18, average log likelihood -1.392627
INFO: iteration 19, average log likelihood -1.392451
INFO: iteration 20, average log likelihood -1.392386
INFO: iteration 21, average log likelihood -1.392357
INFO: iteration 22, average log likelihood -1.392342
INFO: iteration 23, average log likelihood -1.392333
INFO: iteration 24, average log likelihood -1.392327
INFO: iteration 25, average log likelihood -1.392321
INFO: iteration 26, average log likelihood -1.392315
INFO: iteration 27, average log likelihood -1.392310
INFO: iteration 28, average log likelihood -1.392305
INFO: iteration 29, average log likelihood -1.392299
INFO: iteration 30, average log likelihood -1.392292
INFO: iteration 31, average log likelihood -1.392285
INFO: iteration 32, average log likelihood -1.392277
INFO: iteration 33, average log likelihood -1.392268
INFO: iteration 34, average log likelihood -1.392258
INFO: iteration 35, average log likelihood -1.392246
INFO: iteration 36, average log likelihood -1.392232
INFO: iteration 37, average log likelihood -1.392214
INFO: iteration 38, average log likelihood -1.392188
INFO: iteration 39, average log likelihood -1.392147
INFO: iteration 40, average log likelihood -1.392082
INFO: iteration 41, average log likelihood -1.391990
INFO: iteration 42, average log likelihood -1.391881
INFO: iteration 43, average log likelihood -1.391771
INFO: iteration 44, average log likelihood -1.391672
INFO: iteration 45, average log likelihood -1.391585
INFO: iteration 46, average log likelihood -1.391513
INFO: iteration 47, average log likelihood -1.391454
INFO: iteration 48, average log likelihood -1.391405
INFO: iteration 49, average log likelihood -1.391365
INFO: iteration 50, average log likelihood -1.391331
INFO: EM with 100000 data points 50 iterations avll -1.391331
952.4 data points per parameter
1: avll = [-1.4291959543919248,-1.4290788028728993,-1.4280121563808315,-1.4203755217904097,-1.4065453068273566,-1.4009979158701558,-1.3992885404450204,-1.3981262676825235,-1.3972181833929371,-1.396569190161681,-1.3960801219565229,-1.3957073232952826,-1.3954208603777623,-1.395179659522098,-1.39490670567592,-1.3943214372269728,-1.3931650512502305,-1.3926271196769482,-1.3924513065893913,-1.3923857714857042,-1.3923572085950813,-1.3923424914009848,-1.3923333448512063,-1.392326554361518,-1.3923207724828617,-1.3923153760630742,-1.392310034943569,-1.3923045340318208,-1.3922986886845787,-1.392292308164524,-1.3922852030624513,-1.392277218205081,-1.3922682230124153,-1.392258018018162,-1.3922462048524322,-1.3922320026552015,-1.3922138138087423,-1.392188077273374,-1.3921474665104487,-1.3920824267231742,-1.391990003098436,-1.3918810883869972,-1.3917714738418205,-1.3916716298142253,-1.3915854780181152,-1.3915131438772232,-1.3914536294029118,-1.3914048155112213,-1.391364619747533,-1.391331307143658]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.391480
INFO: iteration 2, average log likelihood -1.391297
INFO: iteration 3, average log likelihood -1.390617
INFO: iteration 4, average log likelihood -1.383891
INFO: iteration 5, average log likelihood -1.365639
INFO: iteration 6, average log likelihood -1.356291
INFO: iteration 7, average log likelihood -1.353493
INFO: iteration 8, average log likelihood -1.352254
INFO: iteration 9, average log likelihood -1.351635
INFO: iteration 10, average log likelihood -1.351285
INFO: iteration 11, average log likelihood -1.351058
INFO: iteration 12, average log likelihood -1.350896
INFO: iteration 13, average log likelihood -1.350773
INFO: iteration 14, average log likelihood -1.350673
INFO: iteration 15, average log likelihood -1.350588
INFO: iteration 16, average log likelihood -1.350514
INFO: iteration 17, average log likelihood -1.350445
INFO: iteration 18, average log likelihood -1.350379
INFO: iteration 19, average log likelihood -1.350313
INFO: iteration 20, average log likelihood -1.350246
INFO: iteration 21, average log likelihood -1.350179
INFO: iteration 22, average log likelihood -1.350113
INFO: iteration 23, average log likelihood -1.350049
INFO: iteration 24, average log likelihood -1.349988
INFO: iteration 25, average log likelihood -1.349930
INFO: iteration 26, average log likelihood -1.349873
INFO: iteration 27, average log likelihood -1.349816
INFO: iteration 28, average log likelihood -1.349759
INFO: iteration 29, average log likelihood -1.349699
INFO: iteration 30, average log likelihood -1.349635
INFO: iteration 31, average log likelihood -1.349563
INFO: iteration 32, average log likelihood -1.349479
INFO: iteration 33, average log likelihood -1.349377
INFO: iteration 34, average log likelihood -1.349243
INFO: iteration 35, average log likelihood -1.349055
INFO: iteration 36, average log likelihood -1.348855
INFO: iteration 37, average log likelihood -1.348725
INFO: iteration 38, average log likelihood -1.348641
INFO: iteration 39, average log likelihood -1.348580
INFO: iteration 40, average log likelihood -1.348534
INFO: iteration 41, average log likelihood -1.348497
INFO: iteration 42, average log likelihood -1.348468
INFO: iteration 43, average log likelihood -1.348444
INFO: iteration 44, average log likelihood -1.348425
INFO: iteration 45, average log likelihood -1.348408
INFO: iteration 46, average log likelihood -1.348395
INFO: iteration 47, average log likelihood -1.348383
INFO: iteration 48, average log likelihood -1.348373
INFO: iteration 49, average log likelihood -1.348365
INFO: iteration 50, average log likelihood -1.348358
INFO: EM with 100000 data points 50 iterations avll -1.348358
473.9 data points per parameter
2: avll = [-1.3914796932659783,-1.391297203766517,-1.3906172539571824,-1.3838913035956553,-1.365638627147424,-1.3562914443267093,-1.3534928418672274,-1.3522537800520609,-1.3516349259521303,-1.3512850999153556,-1.3510576901259148,-1.3508958738552146,-1.3507726437296388,-1.3506728814226392,-1.3505883969717278,-1.3505140065188173,-1.35044539539641,-1.3503791308507689,-1.3503129779637384,-1.350246231224307,-1.3501792598546172,-1.3501131411060394,-1.3500492825397337,-1.3499883141849471,-1.34992975389211,-1.3498726290170195,-1.3498160293173531,-1.3497588629376367,-1.349699338338535,-1.3496348843899144,-1.3495625608345063,-1.3494788449271706,-1.3493774796906723,-1.3492429786137616,-1.349055377693274,-1.348854884063364,-1.348725109193373,-1.3486412579349216,-1.3485802050032134,-1.3485336835516277,-1.3484973109472673,-1.3484681492678972,-1.3484442916272399,-1.3484245658109397,-1.3484081765105504,-1.3483945092672365,-1.348383059825124,-1.3483734001668317,-1.348365182959666,-1.3483581493511976]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.348588
INFO: iteration 2, average log likelihood -1.348369
INFO: iteration 3, average log likelihood -1.347648
INFO: iteration 4, average log likelihood -1.341183
INFO: iteration 5, average log likelihood -1.323370
INFO: iteration 6, average log likelihood -1.312283
INFO: iteration 7, average log likelihood -1.307397
INFO: iteration 8, average log likelihood -1.303623
INFO: iteration 9, average log likelihood -1.300308
INFO: iteration 10, average log likelihood -1.297135
INFO: iteration 11, average log likelihood -1.294558
INFO: iteration 12, average log likelihood -1.292897
INFO: iteration 13, average log likelihood -1.291959
INFO: iteration 14, average log likelihood -1.291460
INFO: iteration 15, average log likelihood -1.291173
INFO: iteration 16, average log likelihood -1.290983
INFO: iteration 17, average log likelihood -1.290840
INFO: iteration 18, average log likelihood -1.290720
INFO: iteration 19, average log likelihood -1.290616
INFO: iteration 20, average log likelihood -1.290529
INFO: iteration 21, average log likelihood -1.290458
INFO: iteration 22, average log likelihood -1.290400
INFO: iteration 23, average log likelihood -1.290351
INFO: iteration 24, average log likelihood -1.290306
INFO: iteration 25, average log likelihood -1.290263
INFO: iteration 26, average log likelihood -1.290216
INFO: iteration 27, average log likelihood -1.290158
INFO: iteration 28, average log likelihood -1.290079
INFO: iteration 29, average log likelihood -1.289972
INFO: iteration 30, average log likelihood -1.289817
INFO: iteration 31, average log likelihood -1.289576
INFO: iteration 32, average log likelihood -1.289252
INFO: iteration 33, average log likelihood -1.288904
INFO: iteration 34, average log likelihood -1.288648
INFO: iteration 35, average log likelihood -1.288515
INFO: iteration 36, average log likelihood -1.288459
INFO: iteration 37, average log likelihood -1.288435
INFO: iteration 38, average log likelihood -1.288424
INFO: iteration 39, average log likelihood -1.288419
INFO: iteration 40, average log likelihood -1.288416
INFO: iteration 41, average log likelihood -1.288415
INFO: iteration 42, average log likelihood -1.288414
INFO: iteration 43, average log likelihood -1.288413
INFO: iteration 44, average log likelihood -1.288412
INFO: iteration 45, average log likelihood -1.288412
INFO: iteration 46, average log likelihood -1.288412
INFO: iteration 47, average log likelihood -1.288411
INFO: iteration 48, average log likelihood -1.288411
INFO: iteration 49, average log likelihood -1.288411
INFO: iteration 50, average log likelihood -1.288411
INFO: EM with 100000 data points 50 iterations avll -1.288411
236.4 data points per parameter
3: avll = [-1.3485876227504674,-1.348368517500737,-1.3476478782815133,-1.341183411186725,-1.3233696810045694,-1.3122831216883653,-1.3073966326502706,-1.303622517346981,-1.3003081301957844,-1.297135100313314,-1.294558075620537,-1.2928969060161943,-1.2919592409598801,-1.2914597969476331,-1.2911734763926792,-1.290982753335099,-1.290839572590159,-1.2907200310383342,-1.2906164829883666,-1.2905292675545836,-1.2904581349036284,-1.290399958643087,-1.2903506363630546,-1.2903063352506043,-1.2902629231856348,-1.2902158701757795,-1.2901578446322226,-1.2900786250385043,-1.2899717855599644,-1.289816590115669,-1.2895758883300377,-1.289251905580914,-1.2889038206644332,-1.288647785718922,-1.2885152823804653,-1.2884585940735185,-1.2884345615458412,-1.288423920660793,-1.2884188348281846,-1.2884161724299679,-1.2884146270322536,-1.2884136335834577,-1.288412935732822,-1.2884124100019871,-1.288411992718767,-1.288411648637879,-1.2884113568861366,-1.288411104342104,-1.2884108823335223,-1.2884106848860415]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.288766
INFO: iteration 2, average log likelihood -1.288392
INFO: iteration 3, average log likelihood -1.286620
INFO: iteration 4, average log likelihood -1.273082
INFO: iteration 5, average log likelihood -1.240571
INFO: iteration 6, average log likelihood -1.214662
WARNING: Variances had to be floored 6
INFO: iteration 7, average log likelihood -1.202306
INFO: iteration 8, average log likelihood -1.204693
INFO: iteration 9, average log likelihood -1.197446
WARNING: Variances had to be floored 1 6
INFO: iteration 10, average log likelihood -1.193902
INFO: iteration 11, average log likelihood -1.210200
INFO: iteration 12, average log likelihood -1.200363
WARNING: Variances had to be floored 6
INFO: iteration 13, average log likelihood -1.196560
INFO: iteration 14, average log likelihood -1.202089
INFO: iteration 15, average log likelihood -1.196639
WARNING: Variances had to be floored 2 6
INFO: iteration 16, average log likelihood -1.192883
INFO: iteration 17, average log likelihood -1.208760
INFO: iteration 18, average log likelihood -1.199071
WARNING: Variances had to be floored 6
INFO: iteration 19, average log likelihood -1.194797
INFO: iteration 20, average log likelihood -1.199615
INFO: iteration 21, average log likelihood -1.194251
WARNING: Variances had to be floored 6
INFO: iteration 22, average log likelihood -1.191544
WARNING: Variances had to be floored 1
INFO: iteration 23, average log likelihood -1.197308
INFO: iteration 24, average log likelihood -1.203212
INFO: iteration 25, average log likelihood -1.196070
WARNING: Variances had to be floored 6
INFO: iteration 26, average log likelihood -1.192294
WARNING: Variances had to be floored 2
INFO: iteration 27, average log likelihood -1.197677
INFO: iteration 28, average log likelihood -1.203352
INFO: iteration 29, average log likelihood -1.197103
WARNING: Variances had to be floored 6
INFO: iteration 30, average log likelihood -1.193475
INFO: iteration 31, average log likelihood -1.197934
WARNING: Variances had to be floored 2
INFO: iteration 32, average log likelihood -1.192117
INFO: iteration 33, average log likelihood -1.201999
INFO: iteration 34, average log likelihood -1.196041
WARNING: Variances had to be floored 6
INFO: iteration 35, average log likelihood -1.192167
INFO: iteration 36, average log likelihood -1.197953
WARNING: Variances had to be floored 2
INFO: iteration 37, average log likelihood -1.192128
INFO: iteration 38, average log likelihood -1.201559
WARNING: Variances had to be floored 6
INFO: iteration 39, average log likelihood -1.195166
INFO: iteration 40, average log likelihood -1.199073
INFO: iteration 41, average log likelihood -1.193526
WARNING: Variances had to be floored 2
INFO: iteration 42, average log likelihood -1.189950
WARNING: Variances had to be floored 6
INFO: iteration 43, average log likelihood -1.197058
INFO: iteration 44, average log likelihood -1.198243
INFO: iteration 45, average log likelihood -1.191425
WARNING: Variances had to be floored 2
INFO: iteration 46, average log likelihood -1.187710
WARNING: Variances had to be floored 12
INFO: iteration 47, average log likelihood -1.194124
WARNING: Variances had to be floored 6
INFO: iteration 48, average log likelihood -1.204585
INFO: iteration 49, average log likelihood -1.204230
WARNING: Variances had to be floored 2
INFO: iteration 50, average log likelihood -1.194953
INFO: EM with 100000 data points 50 iterations avll -1.194953
118.1 data points per parameter
4: avll = [-1.288765798069831,-1.2883921153425493,-1.286619725426257,-1.273081719168377,-1.2405710580005866,-1.2146617101874186,-1.202306034499299,-1.2046929220768952,-1.1974456469412582,-1.1939019883323567,-1.210200334287534,-1.2003632093854235,-1.1965604292496987,-1.2020888962623553,-1.196638579337675,-1.192882894141465,-1.2087600989472702,-1.199071287879507,-1.1947970756051665,-1.1996145803621951,-1.1942510832692974,-1.191543877930953,-1.1973082302440732,-1.2032116419601644,-1.1960699564087134,-1.192293784654622,-1.197677438054702,-1.203351652279724,-1.1971034908130966,-1.1934753711721622,-1.1979344228521323,-1.1921174804579233,-1.2019992803848665,-1.1960411448715271,-1.1921668568604278,-1.1979525650345864,-1.1921279585433753,-1.2015589617863818,-1.1951664232662706,-1.199072617190947,-1.193525734782635,-1.1899495752937437,-1.1970582812658483,-1.1982431805456155,-1.1914249664382595,-1.1877096943212235,-1.1941243944221498,-1.2045852106488626,-1.2042297865591267,-1.194952786370726]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.201133
INFO: iteration 2, average log likelihood -1.193526
WARNING: Variances had to be floored 12
INFO: iteration 3, average log likelihood -1.186229
WARNING: Variances had to be floored 3 4 11 23
INFO: iteration 4, average log likelihood -1.156628
WARNING: Variances had to be floored 31
INFO: iteration 5, average log likelihood -1.125967
WARNING: Variances had to be floored 11 16 23 26
INFO: iteration 6, average log likelihood -1.097000
WARNING: Variances had to be floored 11 31
INFO: iteration 7, average log likelihood -1.104032
WARNING: Variances had to be floored 3 4 5 16 23
INFO: iteration 8, average log likelihood -1.079103
WARNING: Variances had to be floored 11 26 31
INFO: iteration 9, average log likelihood -1.081501
WARNING: Variances had to be floored 2 16 23
INFO: iteration 10, average log likelihood -1.081543
WARNING: Variances had to be floored 3 4 11 31
INFO: iteration 11, average log likelihood -1.076243
WARNING: Variances had to be floored 5 16 23 26
INFO: iteration 12, average log likelihood -1.073383
WARNING: Variances had to be floored 11 31
INFO: iteration 13, average log likelihood -1.084675
WARNING: Variances had to be floored 2 3 4 16 23
INFO: iteration 14, average log likelihood -1.068361
WARNING: Variances had to be floored 11 26 31
INFO: iteration 15, average log likelihood -1.081318
WARNING: Variances had to be floored 5 16 23
INFO: iteration 16, average log likelihood -1.080470
WARNING: Variances had to be floored 3 11 31
INFO: iteration 17, average log likelihood -1.073457
WARNING: Variances had to be floored 2 4 16 23 26
INFO: iteration 18, average log likelihood -1.063842
WARNING: Variances had to be floored 11 31
INFO: iteration 19, average log likelihood -1.094079
WARNING: Variances had to be floored 5 16 23
INFO: iteration 20, average log likelihood -1.072072
WARNING: Variances had to be floored 4 11 26 31
INFO: iteration 21, average log likelihood -1.068915
WARNING: Variances had to be floored 2 16 23
INFO: iteration 22, average log likelihood -1.084687
WARNING: Variances had to be floored 11 31
INFO: iteration 23, average log likelihood -1.075220
WARNING: Variances had to be floored 4 5 16 23 26
INFO: iteration 24, average log likelihood -1.057248
WARNING: Variances had to be floored 2 11 31
INFO: iteration 25, average log likelihood -1.084763
WARNING: Variances had to be floored 16 23
INFO: iteration 26, average log likelihood -1.072517
WARNING: Variances had to be floored 4 11 26 31
INFO: iteration 27, average log likelihood -1.059349
WARNING: Variances had to be floored 2 5 16 23
INFO: iteration 28, average log likelihood -1.077451
WARNING: Variances had to be floored 11 26 31
INFO: iteration 29, average log likelihood -1.075334
WARNING: Variances had to be floored 4 16 23
INFO: iteration 30, average log likelihood -1.071341
WARNING: Variances had to be floored 2 11 26 31
INFO: iteration 31, average log likelihood -1.070370
WARNING: Variances had to be floored 16 23
INFO: iteration 32, average log likelihood -1.078367
WARNING: Variances had to be floored 4 11 26 31
INFO: iteration 33, average log likelihood -1.061579
WARNING: Variances had to be floored 2 16 23
INFO: iteration 34, average log likelihood -1.073301
WARNING: Variances had to be floored 5 6 11 26 31
INFO: iteration 35, average log likelihood -1.062194
WARNING: Variances had to be floored 16 23
INFO: iteration 36, average log likelihood -1.080530
WARNING: Variances had to be floored 4 11 26 31
INFO: iteration 37, average log likelihood -1.064962
WARNING: Variances had to be floored 2 16 23
INFO: iteration 38, average log likelihood -1.079499
WARNING: Variances had to be floored 11 26 31
INFO: iteration 39, average log likelihood -1.070504
WARNING: Variances had to be floored 4 16 23
INFO: iteration 40, average log likelihood -1.067070
WARNING: Variances had to be floored 2 6 11 26 31
INFO: iteration 41, average log likelihood -1.063223
WARNING: Variances had to be floored 16 23
INFO: iteration 42, average log likelihood -1.085941
WARNING: Variances had to be floored 4 11 26 31
INFO: iteration 43, average log likelihood -1.064890
WARNING: Variances had to be floored 16 23
INFO: iteration 44, average log likelihood -1.078232
WARNING: Variances had to be floored 2 11 26 31
INFO: iteration 45, average log likelihood -1.062346
WARNING: Variances had to be floored 4 16 23
INFO: iteration 46, average log likelihood -1.075017
WARNING: Variances had to be floored 5 11 26 31
INFO: iteration 47, average log likelihood -1.070345
WARNING: Variances had to be floored 2 16 23
INFO: iteration 48, average log likelihood -1.072649
WARNING: Variances had to be floored 4 6 11 26 31
INFO: iteration 49, average log likelihood -1.062568
WARNING: Variances had to be floored 16 23
INFO: iteration 50, average log likelihood -1.086412
INFO: EM with 100000 data points 50 iterations avll -1.086412
59.0 data points per parameter
5: avll = [-1.2011332101966523,-1.1935257312661989,-1.186228645116501,-1.1566282630750644,-1.1259671019353326,-1.0970001332672987,-1.104032375088258,-1.079102785593139,-1.0815013108597293,-1.081542504011055,-1.0762429325853942,-1.0733834826894424,-1.084674652761413,-1.0683609227802935,-1.081318434301781,-1.0804703069901578,-1.0734567124694576,-1.0638417020751432,-1.0940790968771654,-1.0720722671797553,-1.0689153791664456,-1.084686758707797,-1.0752195291901667,-1.0572476825028045,-1.0847625265131562,-1.072516933299437,-1.0593490545042816,-1.0774513082903683,-1.075333643213426,-1.071340558727091,-1.070369576285726,-1.0783674394914877,-1.0615789493324796,-1.0733006350279173,-1.0621936116994841,-1.0805298815835758,-1.064961939660559,-1.0794993220743248,-1.0705035715462614,-1.067070144223943,-1.0632227901565467,-1.0859411552937956,-1.0648902451341367,-1.0782322588242694,-1.062346134828409,-1.075017129312992,-1.0703450626009066,-1.0726491542467116,-1.062567722849192,-1.086411638791363]
[-1.429091063655497,-1.4291959543919248,-1.4290788028728993,-1.4280121563808315,-1.4203755217904097,-1.4065453068273566,-1.4009979158701558,-1.3992885404450204,-1.3981262676825235,-1.3972181833929371,-1.396569190161681,-1.3960801219565229,-1.3957073232952826,-1.3954208603777623,-1.395179659522098,-1.39490670567592,-1.3943214372269728,-1.3931650512502305,-1.3926271196769482,-1.3924513065893913,-1.3923857714857042,-1.3923572085950813,-1.3923424914009848,-1.3923333448512063,-1.392326554361518,-1.3923207724828617,-1.3923153760630742,-1.392310034943569,-1.3923045340318208,-1.3922986886845787,-1.392292308164524,-1.3922852030624513,-1.392277218205081,-1.3922682230124153,-1.392258018018162,-1.3922462048524322,-1.3922320026552015,-1.3922138138087423,-1.392188077273374,-1.3921474665104487,-1.3920824267231742,-1.391990003098436,-1.3918810883869972,-1.3917714738418205,-1.3916716298142253,-1.3915854780181152,-1.3915131438772232,-1.3914536294029118,-1.3914048155112213,-1.391364619747533,-1.391331307143658,-1.3914796932659783,-1.391297203766517,-1.3906172539571824,-1.3838913035956553,-1.365638627147424,-1.3562914443267093,-1.3534928418672274,-1.3522537800520609,-1.3516349259521303,-1.3512850999153556,-1.3510576901259148,-1.3508958738552146,-1.3507726437296388,-1.3506728814226392,-1.3505883969717278,-1.3505140065188173,-1.35044539539641,-1.3503791308507689,-1.3503129779637384,-1.350246231224307,-1.3501792598546172,-1.3501131411060394,-1.3500492825397337,-1.3499883141849471,-1.34992975389211,-1.3498726290170195,-1.3498160293173531,-1.3497588629376367,-1.349699338338535,-1.3496348843899144,-1.3495625608345063,-1.3494788449271706,-1.3493774796906723,-1.3492429786137616,-1.349055377693274,-1.348854884063364,-1.348725109193373,-1.3486412579349216,-1.3485802050032134,-1.3485336835516277,-1.3484973109472673,-1.3484681492678972,-1.3484442916272399,-1.3484245658109397,-1.3484081765105504,-1.3483945092672365,-1.348383059825124,-1.3483734001668317,-1.348365182959666,-1.3483581493511976,-1.3485876227504674,-1.348368517500737,-1.3476478782815133,-1.341183411186725,-1.3233696810045694,-1.3122831216883653,-1.3073966326502706,-1.303622517346981,-1.3003081301957844,-1.297135100313314,-1.294558075620537,-1.2928969060161943,-1.2919592409598801,-1.2914597969476331,-1.2911734763926792,-1.290982753335099,-1.290839572590159,-1.2907200310383342,-1.2906164829883666,-1.2905292675545836,-1.2904581349036284,-1.290399958643087,-1.2903506363630546,-1.2903063352506043,-1.2902629231856348,-1.2902158701757795,-1.2901578446322226,-1.2900786250385043,-1.2899717855599644,-1.289816590115669,-1.2895758883300377,-1.289251905580914,-1.2889038206644332,-1.288647785718922,-1.2885152823804653,-1.2884585940735185,-1.2884345615458412,-1.288423920660793,-1.2884188348281846,-1.2884161724299679,-1.2884146270322536,-1.2884136335834577,-1.288412935732822,-1.2884124100019871,-1.288411992718767,-1.288411648637879,-1.2884113568861366,-1.288411104342104,-1.2884108823335223,-1.2884106848860415,-1.288765798069831,-1.2883921153425493,-1.286619725426257,-1.273081719168377,-1.2405710580005866,-1.2146617101874186,-1.202306034499299,-1.2046929220768952,-1.1974456469412582,-1.1939019883323567,-1.210200334287534,-1.2003632093854235,-1.1965604292496987,-1.2020888962623553,-1.196638579337675,-1.192882894141465,-1.2087600989472702,-1.199071287879507,-1.1947970756051665,-1.1996145803621951,-1.1942510832692974,-1.191543877930953,-1.1973082302440732,-1.2032116419601644,-1.1960699564087134,-1.192293784654622,-1.197677438054702,-1.203351652279724,-1.1971034908130966,-1.1934753711721622,-1.1979344228521323,-1.1921174804579233,-1.2019992803848665,-1.1960411448715271,-1.1921668568604278,-1.1979525650345864,-1.1921279585433753,-1.2015589617863818,-1.1951664232662706,-1.199072617190947,-1.193525734782635,-1.1899495752937437,-1.1970582812658483,-1.1982431805456155,-1.1914249664382595,-1.1877096943212235,-1.1941243944221498,-1.2045852106488626,-1.2042297865591267,-1.194952786370726,-1.2011332101966523,-1.1935257312661989,-1.186228645116501,-1.1566282630750644,-1.1259671019353326,-1.0970001332672987,-1.104032375088258,-1.079102785593139,-1.0815013108597293,-1.081542504011055,-1.0762429325853942,-1.0733834826894424,-1.084674652761413,-1.0683609227802935,-1.081318434301781,-1.0804703069901578,-1.0734567124694576,-1.0638417020751432,-1.0940790968771654,-1.0720722671797553,-1.0689153791664456,-1.084686758707797,-1.0752195291901667,-1.0572476825028045,-1.0847625265131562,-1.072516933299437,-1.0593490545042816,-1.0774513082903683,-1.075333643213426,-1.071340558727091,-1.070369576285726,-1.0783674394914877,-1.0615789493324796,-1.0733006350279173,-1.0621936116994841,-1.0805298815835758,-1.064961939660559,-1.0794993220743248,-1.0705035715462614,-1.067070144223943,-1.0632227901565467,-1.0859411552937956,-1.0648902451341367,-1.0782322588242694,-1.062346134828409,-1.075017129312992,-1.0703450626009066,-1.0726491542467116,-1.062567722849192,-1.086411638791363]
32x26 Array{Float64,2}:
  0.0157803    0.0263129  -0.0642673   â€¦   0.133454     0.0966083 
 -0.143599    -0.047706    0.0490254       0.0153933   -0.0694603 
 -0.0516375   -0.117197   -0.0962036       0.0629021   -0.0345986 
 -0.00332758   0.0256649  -0.0158551      -0.0145606   -0.0563917 
  0.172069    -0.0251615  -0.0767559      -0.0516218   -0.0115807 
  0.0293143   -0.0828616   0.317931    â€¦  -0.0450357    0.116071  
  0.116166    -0.0636535   0.20998         0.104767     0.00890017
 -0.0903449    0.0347743  -0.0321052      -0.00975892   0.00237071
  0.0592128   -0.0660762   0.0137333      -0.0917104    0.0340489 
  0.0161013   -0.113141    0.0807857      -0.13161     -0.0265659 
  â‹®                                    â‹±                â‹®         
  0.0370042    0.0754377   0.0156138      -0.00660355  -0.148406  
 -0.0374171    0.0312891   0.248649        0.0182838   -0.0639819 
  0.0266462   -0.0665866   0.0036906   â€¦   0.172443    -0.129874  
 -0.102691    -0.0194245   0.0311771       0.0339698    0.0282611 
  0.129638    -0.121432    0.0224443      -0.0217053    0.0487598 
  0.0223182    0.0500095  -0.00448329     -0.0722561   -0.0672266 
  0.00231158   0.0893233   0.0756559      -0.0798239    0.0530236 
 -0.121622    -0.0951601  -0.0498534   â€¦  -0.0332245   -0.0687352 
  0.0513728   -0.115526   -0.00650179     -0.0120399    0.079187  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 11 26 31
INFO: iteration 1, average log likelihood -1.066600
WARNING: Variances had to be floored 2 4 11 16 23 26 31
INFO: iteration 2, average log likelihood -1.044605
WARNING: Variances had to be floored 2 11 26 31
INFO: iteration 3, average log likelihood -1.061788
WARNING: Variances had to be floored 2 4 6 11 16 23 26 31
INFO: iteration 4, average log likelihood -1.039572
WARNING: Variances had to be floored 11 26 31
INFO: iteration 5, average log likelihood -1.066705
WARNING: Variances had to be floored 2 4 11 16 23 26 31
INFO: iteration 6, average log likelihood -1.043833
WARNING: Variances had to be floored 2 11 26 31
INFO: iteration 7, average log likelihood -1.060537
WARNING: Variances had to be floored 2 4 6 11 16 23 26 31
INFO: iteration 8, average log likelihood -1.037505
WARNING: Variances had to be floored 11 26 31
INFO: iteration 9, average log likelihood -1.066738
WARNING: Variances had to be floored 2 4 11 16 23 26 31
INFO: iteration 10, average log likelihood -1.043659
INFO: EM with 100000 data points 10 iterations avll -1.043659
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.991088e+05
      1       7.089311e+05      -1.901777e+05 |       32
      2       6.793254e+05      -2.960569e+04 |       32
      3       6.629275e+05      -1.639791e+04 |       32
      4       6.537961e+05      -9.131399e+03 |       32
      5       6.484281e+05      -5.367945e+03 |       32
      6       6.443914e+05      -4.036782e+03 |       32
      7       6.405689e+05      -3.822494e+03 |       32
      8       6.373797e+05      -3.189202e+03 |       32
      9       6.357487e+05      -1.631005e+03 |       32
     10       6.347181e+05      -1.030598e+03 |       32
     11       6.339373e+05      -7.807518e+02 |       32
     12       6.332435e+05      -6.937610e+02 |       32
     13       6.322736e+05      -9.699181e+02 |       32
     14       6.305191e+05      -1.754536e+03 |       32
     15       6.287290e+05      -1.790133e+03 |       32
     16       6.276399e+05      -1.089070e+03 |       32
     17       6.266072e+05      -1.032640e+03 |       32
     18       6.253387e+05      -1.268522e+03 |       32
     19       6.238513e+05      -1.487451e+03 |       32
     20       6.226866e+05      -1.164623e+03 |       32
     21       6.221768e+05      -5.098461e+02 |       32
     22       6.219218e+05      -2.550173e+02 |       32
     23       6.217542e+05      -1.675398e+02 |       32
     24       6.216314e+05      -1.228909e+02 |       32
     25       6.215498e+05      -8.151565e+01 |       32
     26       6.214880e+05      -6.186475e+01 |       31
     27       6.214344e+05      -5.361062e+01 |       31
     28       6.213764e+05      -5.799339e+01 |       31
     29       6.213338e+05      -4.256714e+01 |       31
     30       6.213119e+05      -2.194638e+01 |       31
     31       6.212995e+05      -1.235892e+01 |       27
     32       6.212923e+05      -7.223513e+00 |       27
     33       6.212869e+05      -5.389232e+00 |       25
     34       6.212825e+05      -4.414927e+00 |       22
     35       6.212799e+05      -2.602170e+00 |       28
     36       6.212773e+05      -2.610646e+00 |       17
     37       6.212756e+05      -1.633206e+00 |       19
     38       6.212742e+05      -1.402247e+00 |       15
     39       6.212735e+05      -6.895856e-01 |       14
     40       6.212729e+05      -6.372446e-01 |       11
     41       6.212724e+05      -4.565431e-01 |       16
     42       6.212718e+05      -6.386392e-01 |        8
     43       6.212714e+05      -3.677836e-01 |        8
     44       6.212710e+05      -4.475622e-01 |        9
     45       6.212707e+05      -2.593563e-01 |        4
     46       6.212706e+05      -1.352312e-01 |        6
     47       6.212705e+05      -1.332227e-01 |        2
     48       6.212704e+05      -7.521914e-02 |        3
     49       6.212702e+05      -2.179048e-01 |        6
     50       6.212699e+05      -2.194602e-01 |        2
K-means terminated without convergence after 50 iterations (objv = 621269.9435972209)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.334052
INFO: iteration 2, average log likelihood -1.300024
INFO: iteration 3, average log likelihood -1.261348
INFO: iteration 4, average log likelihood -1.216487
INFO: iteration 5, average log likelihood -1.167490
WARNING: Variances had to be floored 14
INFO: iteration 6, average log likelihood -1.113310
WARNING: Variances had to be floored 1 2 11 16 20 32
INFO: iteration 7, average log likelihood -1.074216
WARNING: Variances had to be floored 3
INFO: iteration 8, average log likelihood -1.112288
WARNING: Variances had to be floored 10 13 29
INFO: iteration 9, average log likelihood -1.082563
WARNING: Variances had to be floored 11 14
INFO: iteration 10, average log likelihood -1.071943
WARNING: Variances had to be floored 1 3 16 32
INFO: iteration 11, average log likelihood -1.052556
WARNING: Variances had to be floored 20
INFO: iteration 12, average log likelihood -1.073467
WARNING: Variances had to be floored 10 11 14
INFO: iteration 13, average log likelihood -1.048545
WARNING: Variances had to be floored 2 3 13 29
INFO: iteration 14, average log likelihood -1.069404
WARNING: Variances had to be floored 1 16 20 32
INFO: iteration 15, average log likelihood -1.053251
WARNING: Variances had to be floored 11 14
INFO: iteration 16, average log likelihood -1.081069
WARNING: Variances had to be floored 3 10
INFO: iteration 17, average log likelihood -1.076005
WARNING: Variances had to be floored 13
INFO: iteration 18, average log likelihood -1.067366
WARNING: Variances had to be floored 1 3 11 14 16 20 32
INFO: iteration 19, average log likelihood -1.022186
WARNING: Variances had to be floored 2 10
INFO: iteration 20, average log likelihood -1.097557
WARNING: Variances had to be floored 29
INFO: iteration 21, average log likelihood -1.092724
WARNING: Variances had to be floored 11 13 14
INFO: iteration 22, average log likelihood -1.045926
WARNING: Variances had to be floored 1 2 10 16 20 32
INFO: iteration 23, average log likelihood -1.046412
WARNING: Variances had to be floored 3
INFO: iteration 24, average log likelihood -1.100857
WARNING: Variances had to be floored 11 14
INFO: iteration 25, average log likelihood -1.069036
WARNING: Variances had to be floored 13
INFO: iteration 26, average log likelihood -1.057965
WARNING: Variances had to be floored 1 3 10 16 20 32
INFO: iteration 27, average log likelihood -1.016243
WARNING: Variances had to be floored 11 14
INFO: iteration 28, average log likelihood -1.097243
WARNING: Variances had to be floored 29
INFO: iteration 29, average log likelihood -1.092790
WARNING: Variances had to be floored 3 13
INFO: iteration 30, average log likelihood -1.043853
WARNING: Variances had to be floored 1 10 11 14 16 20 32
INFO: iteration 31, average log likelihood -1.028715
INFO: iteration 32, average log likelihood -1.124731
WARNING: Variances had to be floored 2
INFO: iteration 33, average log likelihood -1.071489
WARNING: Variances had to be floored 3 11 13 14 29 32
INFO: iteration 34, average log likelihood -1.023053
WARNING: Variances had to be floored 1 10 16 20
INFO: iteration 35, average log likelihood -1.075934
INFO: iteration 36, average log likelihood -1.114301
WARNING: Variances had to be floored 3 14
INFO: iteration 37, average log likelihood -1.059599
WARNING: Variances had to be floored 10 11 13 29
INFO: iteration 38, average log likelihood -1.039224
WARNING: Variances had to be floored 1 16 20 32
INFO: iteration 39, average log likelihood -1.052224
WARNING: Variances had to be floored 3 14
INFO: iteration 40, average log likelihood -1.074511
WARNING: Variances had to be floored 10
INFO: iteration 41, average log likelihood -1.073597
WARNING: Variances had to be floored 11 13 32
INFO: iteration 42, average log likelihood -1.039109
WARNING: Variances had to be floored 1 3 14 16 20 29
INFO: iteration 43, average log likelihood -1.026398
WARNING: Variances had to be floored 10
INFO: iteration 44, average log likelihood -1.095004
WARNING: Variances had to be floored 11
INFO: iteration 45, average log likelihood -1.071864
WARNING: Variances had to be floored 3 13 14
INFO: iteration 46, average log likelihood -1.033462
WARNING: Variances had to be floored 1 10 16 20 32
INFO: iteration 47, average log likelihood -1.036242
WARNING: Variances had to be floored 11
INFO: iteration 48, average log likelihood -1.088419
WARNING: Variances had to be floored 3 14 29
INFO: iteration 49, average log likelihood -1.056949
WARNING: Variances had to be floored 10 13
INFO: iteration 50, average log likelihood -1.052815
INFO: EM with 100000 data points 50 iterations avll -1.052815
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.163075    -0.014067    -0.00544048  â€¦  -0.0348773    0.0432568
  0.0372909    0.0748789    0.0127192      -0.00645933  -0.152444 
  0.0441623    0.237961    -0.186561        0.0892282    0.0408475
  0.111079    -0.114011     0.145677       -0.0328975   -0.0224309
  0.0148357    0.0281517   -0.0654969       0.133685     0.0953372
  0.134099    -0.150847    -0.110164    â€¦   0.0430265    0.105874 
 -0.0144043   -0.0755624   -0.199534        0.0819396   -0.0219232
  0.0513882   -0.115452    -0.00657765     -0.0119894    0.0800794
  7.93904e-5  -0.0742271    0.0259734      -0.114329    -0.0948659
  0.0293811   -0.0671461    0.00382184      0.176311    -0.130905 
  â‹®                                     â‹±                â‹®        
  0.115753     0.0768031   -0.0916794       0.0234977    0.0345019
 -0.0868247   -0.10298      0.0721755       0.130686     0.0406338
 -0.0178489    0.0894797   -0.0662505   â€¦   0.00742765  -0.0377711
  0.120552    -0.0649046    0.203506        0.102445     0.0150382
 -0.0372742    0.0306951    0.245551        0.019038    -0.0639232
  0.124648    -0.159142     0.135455       -0.166092    -0.0270115
  0.0582566   -0.0205661   -0.104206        0.0700816    0.140877 
  0.0133386    0.0689826    0.0347515   â€¦  -0.0735648   -0.0132231
  0.0159586    0.00311689  -0.0153106      -0.0225371   -0.0532532INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 1 11 16 20 32
INFO: iteration 1, average log likelihood -1.037690
WARNING: Variances had to be floored 1 3 11 14 16 20 32
INFO: iteration 2, average log likelihood -1.000422
WARNING: Variances had to be floored 1 10 11 13 16 20 29 32
INFO: iteration 3, average log likelihood -0.999586
WARNING: Variances had to be floored 1 3 11 14 16 20 32
INFO: iteration 4, average log likelihood -1.020891
WARNING: Variances had to be floored 1 11 16 20 32
INFO: iteration 5, average log likelihood -1.012529
WARNING: Variances had to be floored 1 3 10 11 13 14 16 20 29 32
INFO: iteration 6, average log likelihood -0.982296
WARNING: Variances had to be floored 1 11 16 20 32
INFO: iteration 7, average log likelihood -1.037361
WARNING: Variances had to be floored 1 3 11 14 16 20 32
INFO: iteration 8, average log likelihood -1.000155
WARNING: Variances had to be floored 1 10 11 13 16 20 29 32
INFO: iteration 9, average log likelihood -0.999537
WARNING: Variances had to be floored 1 3 11 14 16 20 32
INFO: iteration 10, average log likelihood -1.020886
INFO: EM with 100000 data points 10 iterations avll -1.020886
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.10266    -0.168042     0.00483176  â€¦  -0.0350354    0.0816585 
 -0.0121776   0.0279669    0.00541638     -0.102216    -0.0462666 
 -0.019787    0.134576    -0.0202557       0.0405449    0.0348563 
 -0.0833746   0.112895     0.326984        0.070027    -0.070136  
  0.141473    0.148282    -0.0695862       0.074079    -0.0972135 
 -0.0516928   0.152933     0.0996655   â€¦  -0.176974     0.153857  
  0.0113417  -0.0608187   -0.0243339      -0.124042     0.110492  
 -0.101337    0.0127125    0.00714803      0.0185892   -0.0176824 
  0.0577696  -0.0652459    0.0412661      -0.0146776    0.0906919 
  0.109671    0.0781197    0.0419038      -0.072281     0.00115287
  â‹®                                    â‹±                â‹®         
 -0.0997731  -0.209188    -0.00441493      0.011802     0.0487676 
 -0.101377   -0.0704192    0.128719       -0.0642862    0.161754  
  0.0356339   0.0310332   -0.114436    â€¦  -0.229374    -0.0574594 
  0.106183    0.0112975    0.181883       -0.00347673   0.00636157
  0.0199263  -0.199951    -0.0246362      -0.074353    -0.0440202 
  0.024428   -0.161631    -0.0625739       0.00505683  -0.163629  
 -0.072491   -0.0104329    0.144571       -0.218774    -0.0363443 
  0.0689227  -0.0320014    0.0929372   â€¦   0.0477494    0.0325906 
  0.127124   -0.00602238  -0.0263433       0.0970867    0.251268  kind full, method split
0: avll = -1.4133138559504475
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.413331
INFO: iteration 2, average log likelihood -1.413269
INFO: iteration 3, average log likelihood -1.413221
INFO: iteration 4, average log likelihood -1.413160
INFO: iteration 5, average log likelihood -1.413081
INFO: iteration 6, average log likelihood -1.412978
INFO: iteration 7, average log likelihood -1.412843
INFO: iteration 8, average log likelihood -1.412653
INFO: iteration 9, average log likelihood -1.412355
INFO: iteration 10, average log likelihood -1.411858
INFO: iteration 11, average log likelihood -1.411083
INFO: iteration 12, average log likelihood -1.410093
INFO: iteration 13, average log likelihood -1.409166
INFO: iteration 14, average log likelihood -1.408547
INFO: iteration 15, average log likelihood -1.408228
INFO: iteration 16, average log likelihood -1.408085
INFO: iteration 17, average log likelihood -1.408023
INFO: iteration 18, average log likelihood -1.407997
INFO: iteration 19, average log likelihood -1.407985
INFO: iteration 20, average log likelihood -1.407980
INFO: iteration 21, average log likelihood -1.407978
INFO: iteration 22, average log likelihood -1.407977
INFO: iteration 23, average log likelihood -1.407976
INFO: iteration 24, average log likelihood -1.407976
INFO: iteration 25, average log likelihood -1.407975
INFO: iteration 26, average log likelihood -1.407975
INFO: iteration 27, average log likelihood -1.407975
INFO: iteration 28, average log likelihood -1.407975
INFO: iteration 29, average log likelihood -1.407975
INFO: iteration 30, average log likelihood -1.407975
INFO: iteration 31, average log likelihood -1.407975
INFO: iteration 32, average log likelihood -1.407975
INFO: iteration 33, average log likelihood -1.407974
INFO: iteration 34, average log likelihood -1.407974
INFO: iteration 35, average log likelihood -1.407974
INFO: iteration 36, average log likelihood -1.407974
INFO: iteration 37, average log likelihood -1.407974
INFO: iteration 38, average log likelihood -1.407974
INFO: iteration 39, average log likelihood -1.407974
INFO: iteration 40, average log likelihood -1.407974
INFO: iteration 41, average log likelihood -1.407974
INFO: iteration 42, average log likelihood -1.407974
INFO: iteration 43, average log likelihood -1.407974
INFO: iteration 44, average log likelihood -1.407974
INFO: iteration 45, average log likelihood -1.407974
INFO: iteration 46, average log likelihood -1.407974
INFO: iteration 47, average log likelihood -1.407974
INFO: iteration 48, average log likelihood -1.407974
INFO: iteration 49, average log likelihood -1.407974
INFO: iteration 50, average log likelihood -1.407974
INFO: EM with 100000 data points 50 iterations avll -1.407974
952.4 data points per parameter
1: avll = [-1.4133307944657536,-1.4132691073472634,-1.4132206553429767,-1.4131602267552894,-1.4130813004935279,-1.4129783590065623,-1.4128429029342722,-1.4126526924793417,-1.4123546709417667,-1.4118583279424957,-1.4110831453801262,-1.41009307645934,-1.4091664709915361,-1.4085472854414058,-1.4082281839581974,-1.408084810637956,-1.4080231914283745,-1.407996756189098,-1.407985259761517,-1.4079801445475693,-1.4079777846770931,-1.4079766305751358,-1.4079760139426254,-1.4079756438606477,-1.4079753923137657,-1.4079752021358847,-1.407975047211815,-1.4079749151568044,-1.4079747997304661,-1.4079746974921938,-1.4079746063153797,-1.407974524720856,-1.4079744515735106,-1.4079743859409621,-1.4079743270251512,-1.4079742741271177,-1.4079742266271607,-1.4079741839723467,-1.407974145667702,-1.4079741112693969,-1.407974080379128,-1.4079740526392936,-1.4079740277287698,-1.4079740053591594,-1.4079739852714481,-1.407973967233005,-1.4079739510348965,-1.4079739364894743,-1.4079739234282083,-1.4079739116997403]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.407988
INFO: iteration 2, average log likelihood -1.407921
INFO: iteration 3, average log likelihood -1.407862
INFO: iteration 4, average log likelihood -1.407788
INFO: iteration 5, average log likelihood -1.407692
INFO: iteration 6, average log likelihood -1.407576
INFO: iteration 7, average log likelihood -1.407447
INFO: iteration 8, average log likelihood -1.407319
INFO: iteration 9, average log likelihood -1.407202
INFO: iteration 10, average log likelihood -1.407100
INFO: iteration 11, average log likelihood -1.407013
INFO: iteration 12, average log likelihood -1.406939
INFO: iteration 13, average log likelihood -1.406877
INFO: iteration 14, average log likelihood -1.406827
INFO: iteration 15, average log likelihood -1.406786
INFO: iteration 16, average log likelihood -1.406753
INFO: iteration 17, average log likelihood -1.406725
INFO: iteration 18, average log likelihood -1.406701
INFO: iteration 19, average log likelihood -1.406679
INFO: iteration 20, average log likelihood -1.406659
INFO: iteration 21, average log likelihood -1.406641
INFO: iteration 22, average log likelihood -1.406625
INFO: iteration 23, average log likelihood -1.406609
INFO: iteration 24, average log likelihood -1.406595
INFO: iteration 25, average log likelihood -1.406583
INFO: iteration 26, average log likelihood -1.406571
INFO: iteration 27, average log likelihood -1.406560
INFO: iteration 28, average log likelihood -1.406550
INFO: iteration 29, average log likelihood -1.406541
INFO: iteration 30, average log likelihood -1.406533
INFO: iteration 31, average log likelihood -1.406525
INFO: iteration 32, average log likelihood -1.406518
INFO: iteration 33, average log likelihood -1.406512
INFO: iteration 34, average log likelihood -1.406506
INFO: iteration 35, average log likelihood -1.406501
INFO: iteration 36, average log likelihood -1.406497
INFO: iteration 37, average log likelihood -1.406492
INFO: iteration 38, average log likelihood -1.406488
INFO: iteration 39, average log likelihood -1.406484
INFO: iteration 40, average log likelihood -1.406481
INFO: iteration 41, average log likelihood -1.406478
INFO: iteration 42, average log likelihood -1.406474
INFO: iteration 43, average log likelihood -1.406472
INFO: iteration 44, average log likelihood -1.406469
INFO: iteration 45, average log likelihood -1.406466
INFO: iteration 46, average log likelihood -1.406463
INFO: iteration 47, average log likelihood -1.406461
INFO: iteration 48, average log likelihood -1.406459
INFO: iteration 49, average log likelihood -1.406456
INFO: iteration 50, average log likelihood -1.406454
INFO: EM with 100000 data points 50 iterations avll -1.406454
473.9 data points per parameter
2: avll = [-1.407987962952,-1.4079208119306361,-1.407861755015552,-1.407787702976455,-1.4076921900713795,-1.4075757971867318,-1.407447163049305,-1.4073192592311379,-1.4072023102833202,-1.4071001882105687,-1.4070126070985123,-1.4069385013612627,-1.4068770240073365,-1.406826961201544,-1.4067864005573925,-1.406753095861168,-1.406725008811612,-1.4067006042805303,-1.4066788657869216,-1.4066591729370164,-1.4066411605232563,-1.4066246102608604,-1.4066093818409484,-1.4065953738429562,-1.40658250338655,-1.406570696266691,-1.4065598824626453,-1.4065499941978457,-1.4065409651372278,-1.4065327300893338,-1.4065252249674065,-1.4065183869265097,-1.4065121546423724,-1.4065064686983715,-1.4065012720359067,-1.406496510416723,-1.4064921328480817,-1.406488091931691,-1.4064843441113644,-1.406480849808921,-1.4064775734503654,-1.4064744833935734,-1.406471551774295,-1.4064687542897194,-1.4064660699387892,-1.406463480736764,-1.4064609714189207,-1.4064585291452856,-1.4064561432153373,-1.4064538047989479]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.406461
INFO: iteration 2, average log likelihood -1.406399
INFO: iteration 3, average log likelihood -1.406342
INFO: iteration 4, average log likelihood -1.406274
INFO: iteration 5, average log likelihood -1.406187
INFO: iteration 6, average log likelihood -1.406080
INFO: iteration 7, average log likelihood -1.405959
INFO: iteration 8, average log likelihood -1.405833
INFO: iteration 9, average log likelihood -1.405711
INFO: iteration 10, average log likelihood -1.405599
INFO: iteration 11, average log likelihood -1.405502
INFO: iteration 12, average log likelihood -1.405420
INFO: iteration 13, average log likelihood -1.405351
INFO: iteration 14, average log likelihood -1.405296
INFO: iteration 15, average log likelihood -1.405251
INFO: iteration 16, average log likelihood -1.405215
INFO: iteration 17, average log likelihood -1.405185
INFO: iteration 18, average log likelihood -1.405159
INFO: iteration 19, average log likelihood -1.405137
INFO: iteration 20, average log likelihood -1.405116
INFO: iteration 21, average log likelihood -1.405097
INFO: iteration 22, average log likelihood -1.405080
INFO: iteration 23, average log likelihood -1.405063
INFO: iteration 24, average log likelihood -1.405048
INFO: iteration 25, average log likelihood -1.405033
INFO: iteration 26, average log likelihood -1.405020
INFO: iteration 27, average log likelihood -1.405007
INFO: iteration 28, average log likelihood -1.404994
INFO: iteration 29, average log likelihood -1.404983
INFO: iteration 30, average log likelihood -1.404972
INFO: iteration 31, average log likelihood -1.404962
INFO: iteration 32, average log likelihood -1.404952
INFO: iteration 33, average log likelihood -1.404943
INFO: iteration 34, average log likelihood -1.404934
INFO: iteration 35, average log likelihood -1.404926
INFO: iteration 36, average log likelihood -1.404919
INFO: iteration 37, average log likelihood -1.404911
INFO: iteration 38, average log likelihood -1.404904
INFO: iteration 39, average log likelihood -1.404898
INFO: iteration 40, average log likelihood -1.404891
INFO: iteration 41, average log likelihood -1.404885
INFO: iteration 42, average log likelihood -1.404880
INFO: iteration 43, average log likelihood -1.404874
INFO: iteration 44, average log likelihood -1.404869
INFO: iteration 45, average log likelihood -1.404864
INFO: iteration 46, average log likelihood -1.404859
INFO: iteration 47, average log likelihood -1.404854
INFO: iteration 48, average log likelihood -1.404849
INFO: iteration 49, average log likelihood -1.404845
INFO: iteration 50, average log likelihood -1.404840
INFO: EM with 100000 data points 50 iterations avll -1.404840
236.4 data points per parameter
3: avll = [-1.4064614481190165,-1.406398701004439,-1.4063420340933783,-1.4062735106456343,-1.406186736150865,-1.406080336586809,-1.4059591076748217,-1.4058325556645919,-1.4057105129219074,-1.405599482447901,-1.4055023331532641,-1.405419794711583,-1.4053514496318806,-1.405295960032485,-1.4052512548860177,-1.4052149583294462,-1.4051848495024841,-1.405159136240354,-1.4051365158035454,-1.405116107602581,-1.4050973450450102,-1.405079875142681,-1.4050634820354988,-1.4050480342344462,-1.4050334501238861,-1.405019676028612,-1.4050066724880925,-1.4049944058466153,-1.4049828433765876,-1.4049719508186784,-1.4049616915574534,-1.404952026824292,-1.4049429164507123,-1.4049343198254172,-1.4049261968311084,-1.4049185086377445,-1.4049112183010324,-1.4049042911607332,-1.4048976950589536,-1.4048914004102717,-1.4048853801586232,-1.4048796096539158,-1.404874066476934,-1.4048687302357334,-1.4048635823513893,-1.4048586058461388,-1.4048537851428828,-1.4048491058817227,-1.404844554756656,-1.4048401193736726]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.404844
INFO: iteration 2, average log likelihood -1.404791
INFO: iteration 3, average log likelihood -1.404744
INFO: iteration 4, average log likelihood -1.404692
INFO: iteration 5, average log likelihood -1.404629
INFO: iteration 6, average log likelihood -1.404552
INFO: iteration 7, average log likelihood -1.404460
INFO: iteration 8, average log likelihood -1.404354
INFO: iteration 9, average log likelihood -1.404238
INFO: iteration 10, average log likelihood -1.404118
INFO: iteration 11, average log likelihood -1.404000
INFO: iteration 12, average log likelihood -1.403887
INFO: iteration 13, average log likelihood -1.403784
INFO: iteration 14, average log likelihood -1.403691
INFO: iteration 15, average log likelihood -1.403608
INFO: iteration 16, average log likelihood -1.403535
INFO: iteration 17, average log likelihood -1.403471
INFO: iteration 18, average log likelihood -1.403414
INFO: iteration 19, average log likelihood -1.403364
INFO: iteration 20, average log likelihood -1.403321
INFO: iteration 21, average log likelihood -1.403282
INFO: iteration 22, average log likelihood -1.403247
INFO: iteration 23, average log likelihood -1.403215
INFO: iteration 24, average log likelihood -1.403186
INFO: iteration 25, average log likelihood -1.403159
INFO: iteration 26, average log likelihood -1.403135
INFO: iteration 27, average log likelihood -1.403112
INFO: iteration 28, average log likelihood -1.403091
INFO: iteration 29, average log likelihood -1.403071
INFO: iteration 30, average log likelihood -1.403052
INFO: iteration 31, average log likelihood -1.403035
INFO: iteration 32, average log likelihood -1.403019
INFO: iteration 33, average log likelihood -1.403003
INFO: iteration 34, average log likelihood -1.402989
INFO: iteration 35, average log likelihood -1.402975
INFO: iteration 36, average log likelihood -1.402962
INFO: iteration 37, average log likelihood -1.402949
INFO: iteration 38, average log likelihood -1.402937
INFO: iteration 39, average log likelihood -1.402926
INFO: iteration 40, average log likelihood -1.402915
INFO: iteration 41, average log likelihood -1.402905
INFO: iteration 42, average log likelihood -1.402895
INFO: iteration 43, average log likelihood -1.402886
INFO: iteration 44, average log likelihood -1.402877
INFO: iteration 45, average log likelihood -1.402868
INFO: iteration 46, average log likelihood -1.402859
INFO: iteration 47, average log likelihood -1.402851
INFO: iteration 48, average log likelihood -1.402843
INFO: iteration 49, average log likelihood -1.402835
INFO: iteration 50, average log likelihood -1.402827
INFO: EM with 100000 data points 50 iterations avll -1.402827
118.1 data points per parameter
4: avll = [-1.4048438039703803,-1.4047908415080106,-1.4047441808612482,-1.4046921000028967,-1.404629201740369,-1.4045521335007827,-1.4044597725510635,-1.4043536500886427,-1.4042378253379937,-1.4041179042120862,-1.4039995690094784,-1.4038873387531083,-1.4037840305286278,-1.4036908822054026,-1.4036080033962863,-1.4035348450654785,-1.403470536890418,-1.4034140774027242,-1.4033644289670812,-1.403320575518269,-1.4032815723011915,-1.4032465875946947,-1.40321492653489,-1.4031860331900632,-1.4031594757374253,-1.4031349232572572,-1.4031121214396352,-1.4030908714314947,-1.4030710133504132,-1.4030524143621959,-1.4030349605145647,-1.403018551371766,-1.4030030966041243,-1.4029885138749028,-1.4029747275506965,-1.4029616679113464,-1.4029492706469657,-1.402937476508446,-1.402926231031321,-1.4029154842879734,-1.402905190645312,-1.4028953085183336,-1.4028858001174356,-1.4028766311910867,-1.4028677707669965,-1.402859190895225,-1.4028508663963428,-1.4028427746171892,-1.4028348951961236,-1.402827209839097]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.402828
INFO: iteration 2, average log likelihood -1.402757
INFO: iteration 3, average log likelihood -1.402689
INFO: iteration 4, average log likelihood -1.402607
INFO: iteration 5, average log likelihood -1.402501
INFO: iteration 6, average log likelihood -1.402366
INFO: iteration 7, average log likelihood -1.402202
INFO: iteration 8, average log likelihood -1.402017
INFO: iteration 9, average log likelihood -1.401821
INFO: iteration 10, average log likelihood -1.401626
INFO: iteration 11, average log likelihood -1.401443
INFO: iteration 12, average log likelihood -1.401277
INFO: iteration 13, average log likelihood -1.401132
INFO: iteration 14, average log likelihood -1.401008
INFO: iteration 15, average log likelihood -1.400903
INFO: iteration 16, average log likelihood -1.400815
INFO: iteration 17, average log likelihood -1.400741
INFO: iteration 18, average log likelihood -1.400678
INFO: iteration 19, average log likelihood -1.400623
INFO: iteration 20, average log likelihood -1.400576
INFO: iteration 21, average log likelihood -1.400535
INFO: iteration 22, average log likelihood -1.400498
INFO: iteration 23, average log likelihood -1.400464
INFO: iteration 24, average log likelihood -1.400434
INFO: iteration 25, average log likelihood -1.400406
INFO: iteration 26, average log likelihood -1.400379
INFO: iteration 27, average log likelihood -1.400355
INFO: iteration 28, average log likelihood -1.400332
INFO: iteration 29, average log likelihood -1.400310
INFO: iteration 30, average log likelihood -1.400289
INFO: iteration 31, average log likelihood -1.400269
INFO: iteration 32, average log likelihood -1.400249
INFO: iteration 33, average log likelihood -1.400231
INFO: iteration 34, average log likelihood -1.400213
INFO: iteration 35, average log likelihood -1.400196
INFO: iteration 36, average log likelihood -1.400180
INFO: iteration 37, average log likelihood -1.400163
INFO: iteration 38, average log likelihood -1.400148
INFO: iteration 39, average log likelihood -1.400132
INFO: iteration 40, average log likelihood -1.400117
INFO: iteration 41, average log likelihood -1.400102
INFO: iteration 42, average log likelihood -1.400088
INFO: iteration 43, average log likelihood -1.400073
INFO: iteration 44, average log likelihood -1.400060
INFO: iteration 45, average log likelihood -1.400046
INFO: iteration 46, average log likelihood -1.400033
INFO: iteration 47, average log likelihood -1.400020
INFO: iteration 48, average log likelihood -1.400007
INFO: iteration 49, average log likelihood -1.399995
INFO: iteration 50, average log likelihood -1.399983
INFO: EM with 100000 data points 50 iterations avll -1.399983
59.0 data points per parameter
5: avll = [-1.4028284388750927,-1.4027573792832115,-1.4026892675962965,-1.4026068774501081,-1.4025009198536287,-1.4023659826969914,-1.4022024633419092,-1.4020171820758498,-1.4018211830733878,-1.4016263331176742,-1.4014426605335795,-1.40127686533046,-1.401131992802056,-1.4010081051365757,-1.4009034048916142,-1.4008152555975095,-1.4007408644567307,-1.4006776484831664,-1.4006233861465847,-1.4005762467076812,-1.4005347602495726,-1.4004977658479496,-1.4004643571597617,-1.4004338333111228,-1.4004056569047634,-1.4003794186545127,-1.4003548077820482,-1.4003315875446474,-1.4003095754974826,-1.4002886278948736,-1.4002686271378109,-1.4002494715557627,-1.4002310682034467,-1.4002133296750783,-1.4001961744412843,-1.4001795289293082,-1.400163329741445,-1.4001475252430349,-1.4001320763148266,-1.4001169562187126,-1.4001021495363941,-1.4000876502221373,-1.4000734589852128,-1.4000595803786076,-1.4000460200210736,-1.4000327823064405,-1.4000198688053773,-1.4000072774030874,-1.3999950020913257,-1.3999830332651775]
[-1.4133138559504475,-1.4133307944657536,-1.4132691073472634,-1.4132206553429767,-1.4131602267552894,-1.4130813004935279,-1.4129783590065623,-1.4128429029342722,-1.4126526924793417,-1.4123546709417667,-1.4118583279424957,-1.4110831453801262,-1.41009307645934,-1.4091664709915361,-1.4085472854414058,-1.4082281839581974,-1.408084810637956,-1.4080231914283745,-1.407996756189098,-1.407985259761517,-1.4079801445475693,-1.4079777846770931,-1.4079766305751358,-1.4079760139426254,-1.4079756438606477,-1.4079753923137657,-1.4079752021358847,-1.407975047211815,-1.4079749151568044,-1.4079747997304661,-1.4079746974921938,-1.4079746063153797,-1.407974524720856,-1.4079744515735106,-1.4079743859409621,-1.4079743270251512,-1.4079742741271177,-1.4079742266271607,-1.4079741839723467,-1.407974145667702,-1.4079741112693969,-1.407974080379128,-1.4079740526392936,-1.4079740277287698,-1.4079740053591594,-1.4079739852714481,-1.407973967233005,-1.4079739510348965,-1.4079739364894743,-1.4079739234282083,-1.4079739116997403,-1.407987962952,-1.4079208119306361,-1.407861755015552,-1.407787702976455,-1.4076921900713795,-1.4075757971867318,-1.407447163049305,-1.4073192592311379,-1.4072023102833202,-1.4071001882105687,-1.4070126070985123,-1.4069385013612627,-1.4068770240073365,-1.406826961201544,-1.4067864005573925,-1.406753095861168,-1.406725008811612,-1.4067006042805303,-1.4066788657869216,-1.4066591729370164,-1.4066411605232563,-1.4066246102608604,-1.4066093818409484,-1.4065953738429562,-1.40658250338655,-1.406570696266691,-1.4065598824626453,-1.4065499941978457,-1.4065409651372278,-1.4065327300893338,-1.4065252249674065,-1.4065183869265097,-1.4065121546423724,-1.4065064686983715,-1.4065012720359067,-1.406496510416723,-1.4064921328480817,-1.406488091931691,-1.4064843441113644,-1.406480849808921,-1.4064775734503654,-1.4064744833935734,-1.406471551774295,-1.4064687542897194,-1.4064660699387892,-1.406463480736764,-1.4064609714189207,-1.4064585291452856,-1.4064561432153373,-1.4064538047989479,-1.4064614481190165,-1.406398701004439,-1.4063420340933783,-1.4062735106456343,-1.406186736150865,-1.406080336586809,-1.4059591076748217,-1.4058325556645919,-1.4057105129219074,-1.405599482447901,-1.4055023331532641,-1.405419794711583,-1.4053514496318806,-1.405295960032485,-1.4052512548860177,-1.4052149583294462,-1.4051848495024841,-1.405159136240354,-1.4051365158035454,-1.405116107602581,-1.4050973450450102,-1.405079875142681,-1.4050634820354988,-1.4050480342344462,-1.4050334501238861,-1.405019676028612,-1.4050066724880925,-1.4049944058466153,-1.4049828433765876,-1.4049719508186784,-1.4049616915574534,-1.404952026824292,-1.4049429164507123,-1.4049343198254172,-1.4049261968311084,-1.4049185086377445,-1.4049112183010324,-1.4049042911607332,-1.4048976950589536,-1.4048914004102717,-1.4048853801586232,-1.4048796096539158,-1.404874066476934,-1.4048687302357334,-1.4048635823513893,-1.4048586058461388,-1.4048537851428828,-1.4048491058817227,-1.404844554756656,-1.4048401193736726,-1.4048438039703803,-1.4047908415080106,-1.4047441808612482,-1.4046921000028967,-1.404629201740369,-1.4045521335007827,-1.4044597725510635,-1.4043536500886427,-1.4042378253379937,-1.4041179042120862,-1.4039995690094784,-1.4038873387531083,-1.4037840305286278,-1.4036908822054026,-1.4036080033962863,-1.4035348450654785,-1.403470536890418,-1.4034140774027242,-1.4033644289670812,-1.403320575518269,-1.4032815723011915,-1.4032465875946947,-1.40321492653489,-1.4031860331900632,-1.4031594757374253,-1.4031349232572572,-1.4031121214396352,-1.4030908714314947,-1.4030710133504132,-1.4030524143621959,-1.4030349605145647,-1.403018551371766,-1.4030030966041243,-1.4029885138749028,-1.4029747275506965,-1.4029616679113464,-1.4029492706469657,-1.402937476508446,-1.402926231031321,-1.4029154842879734,-1.402905190645312,-1.4028953085183336,-1.4028858001174356,-1.4028766311910867,-1.4028677707669965,-1.402859190895225,-1.4028508663963428,-1.4028427746171892,-1.4028348951961236,-1.402827209839097,-1.4028284388750927,-1.4027573792832115,-1.4026892675962965,-1.4026068774501081,-1.4025009198536287,-1.4023659826969914,-1.4022024633419092,-1.4020171820758498,-1.4018211830733878,-1.4016263331176742,-1.4014426605335795,-1.40127686533046,-1.401131992802056,-1.4010081051365757,-1.4009034048916142,-1.4008152555975095,-1.4007408644567307,-1.4006776484831664,-1.4006233861465847,-1.4005762467076812,-1.4005347602495726,-1.4004977658479496,-1.4004643571597617,-1.4004338333111228,-1.4004056569047634,-1.4003794186545127,-1.4003548077820482,-1.4003315875446474,-1.4003095754974826,-1.4002886278948736,-1.4002686271378109,-1.4002494715557627,-1.4002310682034467,-1.4002133296750783,-1.4001961744412843,-1.4001795289293082,-1.400163329741445,-1.4001475252430349,-1.4001320763148266,-1.4001169562187126,-1.4001021495363941,-1.4000876502221373,-1.4000734589852128,-1.4000595803786076,-1.4000460200210736,-1.4000327823064405,-1.4000198688053773,-1.4000072774030874,-1.3999950020913257,-1.3999830332651775]
32x26 Array{Float64,2}:
 -0.51974     0.430243   -0.645721    0.34896    â€¦  -0.215836     -0.192404
 -0.135138    0.116955   -0.411651   -0.11967        0.000153303  -0.426888
  0.106442    0.214643    0.097374   -0.0367201      0.0337968     0.69002 
  0.218659   -0.0761457   0.1002      0.216131       0.00724504    0.488147
 -0.123777   -0.0873023   0.113424   -0.191886      -0.359414     -0.101275
 -0.39037    -0.410059   -0.435667   -0.323942   â€¦  -0.0703131    -0.313505
  0.445241   -0.165062   -0.113015    0.142168      -0.221557      0.385499
  0.587701    0.162713   -0.104668    0.393871       0.0593266     0.150096
 -0.174199   -0.0894617   0.0214199  -0.11427        0.0474242    -0.156219
 -0.396929    0.0409593   0.434177   -0.19947       -0.0127742     0.19038 
  â‹®                                              â‹±                 â‹®       
  0.311907   -0.124809   -0.247566    0.283194      -0.344323      0.559056
 -0.0391379  -0.43571     0.805397   -0.518174       0.344574     -0.112043
 -0.244424    0.545201   -0.35147    -0.121145   â€¦  -0.141836     -0.260128
 -0.162589   -0.179462    0.969223   -0.256899       0.156119      0.497777
  0.926945   -0.274819    0.188983    0.331477      -0.040842      0.391581
 -0.438138   -0.0395669   0.186622   -0.0533276     -0.251058     -0.240853
 -0.135826   -0.160624   -0.0372975  -0.241061       0.447157     -0.707562
 -0.226177   -0.509752    0.0157759  -0.392385   â€¦  -0.214166     -0.733441
  0.79807    -0.770036   -0.435541    0.12595        0.12239      -0.903195INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.399971
INFO: iteration 2, average log likelihood -1.399960
INFO: iteration 3, average log likelihood -1.399949
INFO: iteration 4, average log likelihood -1.399938
INFO: iteration 5, average log likelihood -1.399927
INFO: iteration 6, average log likelihood -1.399917
INFO: iteration 7, average log likelihood -1.399907
INFO: iteration 8, average log likelihood -1.399897
INFO: iteration 9, average log likelihood -1.399887
INFO: iteration 10, average log likelihood -1.399877
INFO: EM with 100000 data points 10 iterations avll -1.399877
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.025801e+05
      1       6.905336e+05      -2.120465e+05 |       32
      2       6.780330e+05      -1.250059e+04 |       32
      3       6.732869e+05      -4.746117e+03 |       32
      4       6.706531e+05      -2.633745e+03 |       32
      5       6.689000e+05      -1.753099e+03 |       32
      6       6.676160e+05      -1.283976e+03 |       32
      7       6.666475e+05      -9.685422e+02 |       32
      8       6.659099e+05      -7.375868e+02 |       32
      9       6.652516e+05      -6.583440e+02 |       32
     10       6.646809e+05      -5.706712e+02 |       32
     11       6.642127e+05      -4.681946e+02 |       32
     12       6.638222e+05      -3.905274e+02 |       32
     13       6.635339e+05      -2.883199e+02 |       32
     14       6.632901e+05      -2.438034e+02 |       32
     15       6.630761e+05      -2.139917e+02 |       32
     16       6.628787e+05      -1.973954e+02 |       32
     17       6.626946e+05      -1.840393e+02 |       32
     18       6.625262e+05      -1.683853e+02 |       32
     19       6.623566e+05      -1.696881e+02 |       32
     20       6.621832e+05      -1.734000e+02 |       32
     21       6.620211e+05      -1.620160e+02 |       32
     22       6.618795e+05      -1.416744e+02 |       32
     23       6.617531e+05      -1.264034e+02 |       32
     24       6.616396e+05      -1.134670e+02 |       32
     25       6.615230e+05      -1.165846e+02 |       32
     26       6.614085e+05      -1.144892e+02 |       32
     27       6.613112e+05      -9.729627e+01 |       32
     28       6.612266e+05      -8.458045e+01 |       32
     29       6.611427e+05      -8.389265e+01 |       32
     30       6.610574e+05      -8.532496e+01 |       32
     31       6.609724e+05      -8.498320e+01 |       32
     32       6.608911e+05      -8.136336e+01 |       32
     33       6.608177e+05      -7.333545e+01 |       32
     34       6.607507e+05      -6.708263e+01 |       32
     35       6.606873e+05      -6.336901e+01 |       32
     36       6.606236e+05      -6.370850e+01 |       32
     37       6.605620e+05      -6.156696e+01 |       32
     38       6.605016e+05      -6.038301e+01 |       32
     39       6.604358e+05      -6.579750e+01 |       32
     40       6.603685e+05      -6.732764e+01 |       32
     41       6.603109e+05      -5.761946e+01 |       32
     42       6.602580e+05      -5.289535e+01 |       32
     43       6.602074e+05      -5.059349e+01 |       32
     44       6.601642e+05      -4.316825e+01 |       32
     45       6.601223e+05      -4.188770e+01 |       32
     46       6.600819e+05      -4.044069e+01 |       32
     47       6.600443e+05      -3.759895e+01 |       32
     48       6.600096e+05      -3.467252e+01 |       32
     49       6.599748e+05      -3.482197e+01 |       32
     50       6.599386e+05      -3.622701e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 659938.5819265207)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.411347
INFO: iteration 2, average log likelihood -1.406540
INFO: iteration 3, average log likelihood -1.405327
INFO: iteration 4, average log likelihood -1.404467
INFO: iteration 5, average log likelihood -1.403523
INFO: iteration 6, average log likelihood -1.402550
INFO: iteration 7, average log likelihood -1.401787
INFO: iteration 8, average log likelihood -1.401324
INFO: iteration 9, average log likelihood -1.401066
INFO: iteration 10, average log likelihood -1.400908
INFO: iteration 11, average log likelihood -1.400798
INFO: iteration 12, average log likelihood -1.400713
INFO: iteration 13, average log likelihood -1.400642
INFO: iteration 14, average log likelihood -1.400582
INFO: iteration 15, average log likelihood -1.400529
INFO: iteration 16, average log likelihood -1.400482
INFO: iteration 17, average log likelihood -1.400440
INFO: iteration 18, average log likelihood -1.400401
INFO: iteration 19, average log likelihood -1.400364
INFO: iteration 20, average log likelihood -1.400331
INFO: iteration 21, average log likelihood -1.400299
INFO: iteration 22, average log likelihood -1.400269
INFO: iteration 23, average log likelihood -1.400240
INFO: iteration 24, average log likelihood -1.400213
INFO: iteration 25, average log likelihood -1.400187
INFO: iteration 26, average log likelihood -1.400162
INFO: iteration 27, average log likelihood -1.400137
INFO: iteration 28, average log likelihood -1.400114
INFO: iteration 29, average log likelihood -1.400091
INFO: iteration 30, average log likelihood -1.400070
INFO: iteration 31, average log likelihood -1.400048
INFO: iteration 32, average log likelihood -1.400028
INFO: iteration 33, average log likelihood -1.400008
INFO: iteration 34, average log likelihood -1.399989
INFO: iteration 35, average log likelihood -1.399970
INFO: iteration 36, average log likelihood -1.399952
INFO: iteration 37, average log likelihood -1.399935
INFO: iteration 38, average log likelihood -1.399918
INFO: iteration 39, average log likelihood -1.399902
INFO: iteration 40, average log likelihood -1.399886
INFO: iteration 41, average log likelihood -1.399871
INFO: iteration 42, average log likelihood -1.399856
INFO: iteration 43, average log likelihood -1.399842
INFO: iteration 44, average log likelihood -1.399829
INFO: iteration 45, average log likelihood -1.399816
INFO: iteration 46, average log likelihood -1.399804
INFO: iteration 47, average log likelihood -1.399792
INFO: iteration 48, average log likelihood -1.399780
INFO: iteration 49, average log likelihood -1.399769
INFO: iteration 50, average log likelihood -1.399758
INFO: EM with 100000 data points 50 iterations avll -1.399758
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.348821     0.284593    0.11863    â€¦  -0.154274   -0.43716     0.152372 
 -0.129723    -0.198649   -0.384935      -0.220038    0.156166   -0.522926 
 -0.181289    -0.443621    0.230093       0.123259    0.962102   -0.150321 
  0.100647     0.0918486   0.281325       0.585479   -0.225056    0.79246  
  0.249018    -0.216069    0.502344      -1.03076    -0.0694599   0.22587  
 -0.647633     0.600959   -0.507747   â€¦   0.0471727  -0.408944   -0.512473 
  0.529483     0.0991037   0.0777904      0.380404   -0.324601   -0.15087  
  0.0751382    0.0599522   0.0312562     -0.151633   -0.282065   -0.0807474
  0.549336     0.144654   -0.570435      -0.0305525  -0.407269    0.937198 
 -0.0324511    0.117566    0.0846627      0.169381    0.0903012   0.0938051
  â‹®                                   â‹±                           â‹®        
  0.518952    -0.498598    0.14183        0.300402    0.281347   -0.228289 
 -0.202121     0.35742    -0.355617      -0.796056   -0.0583157  -0.41287  
 -0.147784     0.711775   -0.063998   â€¦   0.34901     0.126408    0.43873  
  0.486204     0.247025    0.241765       0.346224    0.229191    0.207613 
 -0.171142     0.0779222   0.0471473      0.110314   -0.0781248  -0.194281 
  0.00512398  -0.116686   -0.137862      -0.130471    0.0062906  -0.0387994
 -0.109953    -0.62542     0.0648579     -0.220567   -0.27252    -0.309615 
  0.235903     0.0136896  -0.147257   â€¦   0.0534356  -0.044254    0.375423 
  0.299959    -0.137205    0.464641      -0.156068    0.107661    0.41181  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.399748
INFO: iteration 2, average log likelihood -1.399738
INFO: iteration 3, average log likelihood -1.399728
INFO: iteration 4, average log likelihood -1.399719
INFO: iteration 5, average log likelihood -1.399710
INFO: iteration 6, average log likelihood -1.399701
INFO: iteration 7, average log likelihood -1.399693
INFO: iteration 8, average log likelihood -1.399685
INFO: iteration 9, average log likelihood -1.399677
INFO: iteration 10, average log likelihood -1.399670
INFO: EM with 100000 data points 10 iterations avll -1.399670
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
