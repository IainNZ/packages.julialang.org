>>> 'Pkg.add("MachineLearning")' log
INFO: Installing ArrayViews v0.4.6
INFO: Installing Calculus v0.1.5
INFO: Installing Codecs v0.1.2
INFO: Installing Color v0.3.10
INFO: Installing Compat v0.0.2
INFO: Installing Compose v0.3.9
INFO: Installing Contour v0.0.5
INFO: Installing DataArrays v0.2.3
INFO: Installing DataFrames v0.5.10
INFO: Installing DataStructures v0.3.3
INFO: Installing Dates v0.4.4
INFO: Installing Devectorize v0.4.0
INFO: Installing Distances v0.1.1
INFO: Installing Distributions v0.5.4
INFO: Installing DualNumbers v0.1.0
INFO: Installing FixedPointNumbers v0.0.4
INFO: Installing GZip v0.2.13
INFO: Installing Gadfly v0.3.9
INFO: Installing Hexagons v0.0.2
INFO: Installing ImmutableArrays v0.0.6
INFO: Installing Iterators v0.1.6
INFO: Installing JSON v0.3.8
INFO: Installing KernelDensity v0.0.2
INFO: Installing Loess v0.0.3
INFO: Installing MachineLearning v0.0.3
INFO: Installing Optim v0.4.0
INFO: Installing PDMats v0.2.4
INFO: Installing RDatasets v0.1.1
INFO: Installing Reexport v0.0.1
INFO: Installing Showoff v0.0.2
INFO: Installing SortingAlgorithms v0.0.2
INFO: Installing StatsBase v0.6.8
INFO: Package database updated

>>> 'using MachineLearning' log

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Reexport/src/Reexport.jl:11.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Reexport/src/Reexport.jl:14.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a for a in b}" at /home/idunning/pkgtest/.julia/v0.4/Reexport/src/Reexport.jl:16.
Use "Any[a for a in b]" instead.

WARNING: deprecated syntax "{}" at /home/idunning/pkgtest/.julia/v0.4/DataArrays/src/linalg.jl:19.
Use "[]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/DataArrays/src/operators.jl:306.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a for a in b}" at /home/idunning/pkgtest/.julia/v0.4/DataArrays/src/operators.jl:315.
Use "Any[a for a in b]" instead.

WARNING: deprecated syntax "{a for a in b}" at /home/idunning/pkgtest/.julia/v0.4/DataArrays/src/operators.jl:344.
... truncated ...
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Calculus/src/differentiate.jl:58.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a=>b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Calculus/src/deparse.jl:1.
Use "Dict{Any,Any}(a=>b, ...)" instead.

WARNING: deprecated syntax "{a=>b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Optim/src/levenberg_marquardt.jl:41.
Use "Dict{Any,Any}(a=>b, ...)" instead.

WARNING: deprecated syntax "{a=>b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Optim/src/levenberg_marquardt.jl:90.
Use "Dict{Any,Any}(a=>b, ...)" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Optim/src/problems/unconstrained.jl:43.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Optim/src/problems/unconstrained.jl:81.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Optim/src/problems/unconstrained.jl:112.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Optim/src/problems/unconstrained.jl:141.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Optim/src/problems/unconstrained.jl:183.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Optim/src/problems/unconstrained.jl:223.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Optim/src/problems/unconstrained.jl:260.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Optim/src/problems/unconstrained.jl:306.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Optim/src/problems/unconstrained.jl:337.
Use "Any[a,b, ...]" instead.
Julia Version 0.4.0-dev+1077
Commit c3a406c (2014-10-14 05:44 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E5-2650 0 @ 2.00GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Sandybridge)
  LAPACK: libopenblas
  LIBM: libopenlibm
  LLVM: libLLVM-3.3

>>> test log

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Reexport/src/Reexport.jl:11.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/Reexport/src/Reexport.jl:14.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a for a in b}" at /home/idunning/pkgtest/.julia/v0.4/Reexport/src/Reexport.jl:16.
Use "Any[a for a in b]" instead.

WARNING: deprecated syntax "{}" at /home/idunning/pkgtest/.julia/v0.4/DataArrays/src/linalg.jl:19.
Use "[]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/idunning/pkgtest/.julia/v0.4/DataArrays/src/operators.jl:306.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a for a in b}" at /home/idunning/pkgtest/.julia/v0.4/DataArrays/src/operators.jl:315.
Use "Any[a for a in b]" instead.

WARNING: deprecated syntax "{a for a in b}" at /home/idunning/pkgtest/.julia/v0.4/DataArrays/src/operators.jl:344.
... truncated ...
	[1m[32mPASSED[0m: metrics.jl
Checking Gradients
Classification Tests
Linear Accuracy, Preset Stop: 0.968
Max Weight: 1.1048623057896996
Max Weight: 0.901713832916312
Linear Accuracy, Soph: 0.968
Number of Iterations: 1000
Linear Accuracy, Valid Stop: 0.956
Nonlinear Accuracy, 1 Hidden Layer : 0.972
Regression Neural Network
    2 Hidden Layers
Nonlinear Accuracy, 2 Hidden Layers: 0.9712
Nonlinear Accuracy, 0 Hidden Layers: 0.9176
Regression Tests
Regression Net Linear Pearson Correlation: 0.9843989933847114
	[1m[32mPASSED[0m: neural_net.jl
Linear Accuracy, Unnormalized: 0.5336
Linear Accuracy, Normalized: 0.9648
Linear Accuracy, Unnormalized: 0.5787569264722942
Linear Accuracy, Normalized: 0.9872761990781896
	[1m[32mPASSED[0m: pipeline.jl
- Dataset Prestige
Correlation: 0.928	BartOptions(10,200,1000,10,0.95,2.0,2.0,BartTreeTransformationProbabilies(0.5,0.4,0.1),0.001,false)
Correlation: 0.888	RegressionForestOptions(10,RegressionTreeOptions(0.5,5),false)
- Dataset quakes
Correlation: 0.882	BartOptions(10,200,1000,10,0.95,2.0,2.0,BartTreeTransformationProbabilies(0.5,0.4,0.1),0.001,false)
Correlation: 0.810	RegressionForestOptions(10,RegressionTreeOptions(0.5,5),false)
	[1m[32mPASSED[0m: regression.jl
Evaluate Train/Test Split Accuracy: 0.936
Evaluate Cross Validation Split Accuracy: 0.95
	[1m[32mPASSED[0m: split.jl
Tree 1	Nodes: 65	Depth: 9
Tree 2	Nodes: 75	Depth: 9
Tree 3	Nodes: 73	Depth: 8
Tree 4	Nodes: 81	Depth: 10
Tree 5	Nodes: 73	Depth: 12
Tree 6	Nodes: 73	Depth: 9
Tree 7	Nodes: 83	Depth: 10
Tree 8	Nodes: 79	Depth: 10
Tree 9	Nodes: 57	Depth: 8
Tree 10	Nodes: 71	Depth: 9
Linear Accuracy: 0.9488
Linear Pearson Correlation: 0.9989498610601949
	[1m[32mPASSED[0m: random_forest.jl
	[1m[32mPASSED[0m: transform/zmuv.jl
	[1m[32mPASSED[0m: tree.jl
INFO: Testing MachineLearning
INFO: MachineLearning tests passed
INFO: No packages to install, update or remove

>>> end of log
